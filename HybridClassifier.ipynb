{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-12-13T02:42:34.868026Z",
     "iopub.status.busy": "2022-12-13T02:42:34.867370Z",
     "iopub.status.idle": "2022-12-13T02:42:43.579576Z",
     "shell.execute_reply": "2022-12-13T02:42:43.578624Z",
     "shell.execute_reply.started": "2022-12-13T02:42:34.868002Z"
    },
    "id": "NIJGTIRqwShE",
    "outputId": "33cdf9b1-8b69-47e7-d574-9dbbe910ff23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchmetrics\n",
      "  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.4/512.4 kB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.10.0\n",
      "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.8.2-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from transformers) (4.64.1)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading regex-2022.10.31-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (769 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m770.0/770.0 kB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: requests in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: torch>=1.8.1 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from torchmetrics) (1.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from requests->transformers) (1.26.11)\n",
      "Installing collected packages: tokenizers, regex, filelock, torchmetrics, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.8.2 huggingface-hub-0.11.1 regex-2022.10.31 tokenizers-0.13.2 torchmetrics-0.11.0 transformers-4.25.1\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install transformers torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ngWuYXW8gTbz",
    "outputId": "52bd93cd-b025-4ea4-b95b-20dc0c5f4a55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.8/dist-packages (0.11.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (21.3)\n",
      "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.13.0+cu116)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.4.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.23.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->torchmetrics) (3.0.9)\n"
     ]
    }
   ],
   "source": [
    "# !python -m pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "execution": {
     "iopub.execute_input": "2022-12-13T02:42:57.757024Z",
     "iopub.status.busy": "2022-12-13T02:42:57.756521Z",
     "iopub.status.idle": "2022-12-13T02:42:57.760519Z",
     "shell.execute_reply": "2022-12-13T02:42:57.759853Z",
     "shell.execute_reply.started": "2022-12-13T02:42:57.756997Z"
    },
    "id": "oXiusUlFgdIi",
    "outputId": "d33ec039-28e2-4011-addb-4bd43102dabe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T02:43:11.709089Z",
     "iopub.status.busy": "2022-12-13T02:43:11.708688Z",
     "iopub.status.idle": "2022-12-13T02:43:11.712531Z",
     "shell.execute_reply": "2022-12-13T02:43:11.711771Z",
     "shell.execute_reply.started": "2022-12-13T02:43:11.709063Z"
    },
    "id": "w_pbAVyEgTb2"
   },
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T02:43:12.297459Z",
     "iopub.status.busy": "2022-12-13T02:43:12.297065Z",
     "iopub.status.idle": "2022-12-13T02:43:12.300768Z",
     "shell.execute_reply": "2022-12-13T02:43:12.300087Z",
     "shell.execute_reply.started": "2022-12-13T02:43:12.297434Z"
    },
    "id": "FkmRdIy2gTb4"
   },
   "outputs": [],
   "source": [
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T02:43:13.776955Z",
     "iopub.status.busy": "2022-12-13T02:43:13.776546Z",
     "iopub.status.idle": "2022-12-13T02:43:15.129195Z",
     "shell.execute_reply": "2022-12-13T02:43:15.128459Z",
     "shell.execute_reply.started": "2022-12-13T02:43:13.776929Z"
    },
    "id": "7SvCi2JuhC5P"
   },
   "outputs": [],
   "source": [
    "import traceback\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def write_tsv_dataframe(filepath, dataframe):\n",
    "    \"\"\"\n",
    "        Stores `DataFrame` as tsv file\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filepath : str\n",
    "            Path to tsv file\n",
    "        dataframe : pd.DataFrame\n",
    "            DataFrame to store\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        IOError\n",
    "            if the file can't be opened\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dataframe.to_csv(filepath, encoding='utf-8', sep='\\t', index=False, header=True, quoting=csv.QUOTE_NONE)\n",
    "    except IOError:\n",
    "        traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T02:43:58.549399Z",
     "iopub.status.busy": "2022-12-13T02:43:58.548907Z",
     "iopub.status.idle": "2022-12-13T02:43:58.553163Z",
     "shell.execute_reply": "2022-12-13T02:43:58.552471Z",
     "shell.execute_reply.started": "2022-12-13T02:43:58.549373Z"
    },
    "id": "Ve5zjHvhhIMT"
   },
   "outputs": [],
   "source": [
    "def combine_columns(df_arguments, df_labels):\n",
    "    \"\"\"Combines the two `DataFrames` on column `Argument ID`\"\"\"\n",
    "    return pd.merge(df_arguments, df_labels, on='Argument ID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T02:44:00.763898Z",
     "iopub.status.busy": "2022-12-13T02:44:00.763518Z",
     "iopub.status.idle": "2022-12-13T02:44:00.768856Z",
     "shell.execute_reply": "2022-12-13T02:44:00.768108Z",
     "shell.execute_reply.started": "2022-12-13T02:44:00.763871Z"
    },
    "id": "tnaaQHrnhYnh"
   },
   "outputs": [],
   "source": [
    "def split_arguments(df_arguments):\n",
    "    \"\"\"Splits `DataFrame` by column `Usage` into `train`-, `validation`-, and `test`-arguments\"\"\"\n",
    "    train_arguments = df_arguments.loc[df_arguments['Usage'] == 'train'].drop(['Usage'], axis=1).reset_index(drop=True)\n",
    "    valid_arguments = df_arguments.loc[df_arguments['Usage'] == 'validation'].drop(['Usage'], axis=1).reset_index(drop=True)\n",
    "    test_arguments = df_arguments.loc[df_arguments['Usage'] == 'test'].drop(['Usage'], axis=1).reset_index(drop=True)\n",
    "    \n",
    "    return train_arguments, valid_arguments, test_arguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T02:44:02.019019Z",
     "iopub.status.busy": "2022-12-13T02:44:02.018624Z",
     "iopub.status.idle": "2022-12-13T02:44:02.023586Z",
     "shell.execute_reply": "2022-12-13T02:44:02.022692Z",
     "shell.execute_reply.started": "2022-12-13T02:44:02.018995Z"
    },
    "id": "kpljNrsChbf1"
   },
   "outputs": [],
   "source": [
    "def create_dataframe_head(argument_ids, model_name):\n",
    "    \"\"\"\n",
    "        Creates `DataFrame` usable to append predictions to it\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        argument_ids : list[str]\n",
    "            First column of the resulting DataFrame\n",
    "        model_name : str\n",
    "            Second column of DataFrame will contain the given model name\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            prepared DataFrame\n",
    "    \"\"\"\n",
    "    df_model_head = pd.DataFrame(argument_ids, columns=['Argument ID'])\n",
    "    df_model_head['Method'] = [model_name] * len(argument_ids)\n",
    "\n",
    "    return df_model_head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T02:44:02.855102Z",
     "iopub.status.busy": "2022-12-13T02:44:02.854709Z",
     "iopub.status.idle": "2022-12-13T02:44:02.858640Z",
     "shell.execute_reply": "2022-12-13T02:44:02.857972Z",
     "shell.execute_reply.started": "2022-12-13T02:44:02.855079Z"
    },
    "id": "1MgX3B55hd9P"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "class MissingColumnError(AttributeError):\n",
    "    \"\"\"Error indicating that an imported DataFrame lacks necessary columns\"\"\"\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T02:44:03.596045Z",
     "iopub.status.busy": "2022-12-13T02:44:03.595659Z",
     "iopub.status.idle": "2022-12-13T02:44:03.599702Z",
     "shell.execute_reply": "2022-12-13T02:44:03.599035Z",
     "shell.execute_reply.started": "2022-12-13T02:44:03.596020Z"
    },
    "id": "Qe-7L7j3ho_X"
   },
   "outputs": [],
   "source": [
    "def load_json_file(filepath):\n",
    "    \"\"\"Load content of json-file from `filepath`\"\"\"\n",
    "    with open(filepath, 'r') as  json_file:\n",
    "        return json.load(json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T02:44:04.497082Z",
     "iopub.status.busy": "2022-12-13T02:44:04.496266Z",
     "iopub.status.idle": "2022-12-13T02:44:04.503370Z",
     "shell.execute_reply": "2022-12-13T02:44:04.502403Z",
     "shell.execute_reply.started": "2022-12-13T02:44:04.497050Z"
    },
    "id": "vWGzjs9lhq_s"
   },
   "outputs": [],
   "source": [
    "def load_values_from_json(filepath):\n",
    "    \"\"\"Load values per level from json-file from `filepath`\"\"\"\n",
    "    json_values = load_json_file(filepath)\n",
    "    values = { \"1\":set(), \"2\":set(), \"3\":set(), \"4a\":set(), \"4b\":set() }\n",
    "    for value in json_values[\"values\"]:\n",
    "        values[\"1\"].add(value[\"name\"])\n",
    "        values[\"2\"].add(value[\"level2\"])\n",
    "        for valueLevel3 in value[\"level3\"]:\n",
    "            values[\"3\"].add(valueLevel3)\n",
    "        for valueLevel4a in value[\"level4a\"]:\n",
    "            values[\"4a\"].add(valueLevel4a)\n",
    "        for valueLevel4b in value[\"level4b\"]:\n",
    "            values[\"4b\"].add(valueLevel4b)\n",
    "    values[\"1\"] = sorted(values[\"1\"])\n",
    "    values[\"2\"] = sorted(values[\"2\"])\n",
    "    values[\"3\"] = sorted(values[\"3\"])\n",
    "    values[\"4a\"] = sorted(values[\"4a\"])\n",
    "    values[\"4b\"] = sorted(values[\"4b\"])\n",
    "    return values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T02:44:05.473120Z",
     "iopub.status.busy": "2022-12-13T02:44:05.472724Z",
     "iopub.status.idle": "2022-12-13T02:44:05.478556Z",
     "shell.execute_reply": "2022-12-13T02:44:05.477772Z",
     "shell.execute_reply.started": "2022-12-13T02:44:05.473096Z"
    },
    "id": "HpBKjzIihtk0"
   },
   "outputs": [],
   "source": [
    "def load_arguments_from_tsv(filepath, default_usage='test'):\n",
    "    \"\"\"\n",
    "        Reads arguments from tsv file\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filepath : str\n",
    "            The path to the tsv file\n",
    "        default_usage : str, optional\n",
    "            The default value if the column \"Usage\" is missing\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            the DataFrame with all arguments\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        MissingColumnError\n",
    "            if the required columns \"Argument ID\" or \"Premise\" are missing in the read data\n",
    "        IOError\n",
    "            if the file can't be read\n",
    "        \"\"\"\n",
    "    try:\n",
    "        dataframe = pd.read_csv(filepath, encoding='utf-8', sep='\\t', header=0)\n",
    "        if not {'Argument ID', 'Premise'}.issubset(set(dataframe.columns.values)):\n",
    "            raise MissingColumnError('The argument \"%s\" file does not contain the minimum required columns [Argument ID, Premise].' % filepath)\n",
    "        if 'Usage' not in dataframe.columns.values:\n",
    "            dataframe['Usage'] = [default_usage] * len(dataframe)\n",
    "        return dataframe\n",
    "    except IOError:\n",
    "        traceback.print_exc()\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T02:44:06.949946Z",
     "iopub.status.busy": "2022-12-13T02:44:06.949560Z",
     "iopub.status.idle": "2022-12-13T02:44:06.954868Z",
     "shell.execute_reply": "2022-12-13T02:44:06.954107Z",
     "shell.execute_reply.started": "2022-12-13T02:44:06.949920Z"
    },
    "id": "lTFyn21VhwsY"
   },
   "outputs": [],
   "source": [
    "def load_labels_from_tsv(filepath, label_order):\n",
    "    \"\"\"\n",
    "        Reads label annotations from tsv file\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filepath : str\n",
    "            The path to the tsv file\n",
    "        label_order : list[str]\n",
    "            The listing and order of the labels to use from the read data\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            the DataFrame with the annotations\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        MissingColumnError\n",
    "            if the required columns \"Argument ID\" or names from `label_order` are missing in the read data\n",
    "        IOError\n",
    "            if the file can't be read\n",
    "        \"\"\"\n",
    "    try:\n",
    "        dataframe = pd.read_csv(filepath, encoding='utf-8', sep='\\t', header=0)\n",
    "        dataframe = dataframe[['Argument ID'] + label_order]\n",
    "        return dataframe\n",
    "    except IOError:\n",
    "        traceback.print_exc()\n",
    "        raise\n",
    "    except KeyError:\n",
    "        raise MissingColumnError('The file \"%s\" does not contain the required columns for its level.' % filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T02:44:07.921136Z",
     "iopub.status.busy": "2022-12-13T02:44:07.920719Z",
     "iopub.status.idle": "2022-12-13T02:44:07.924701Z",
     "shell.execute_reply": "2022-12-13T02:44:07.923936Z",
     "shell.execute_reply.started": "2022-12-13T02:44:07.921113Z"
    },
    "id": "yxSNyT8Why1g"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import getopt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T02:44:08.702694Z",
     "iopub.status.busy": "2022-12-13T02:44:08.702318Z",
     "iopub.status.idle": "2022-12-13T02:44:08.706365Z",
     "shell.execute_reply": "2022-12-13T02:44:08.705588Z",
     "shell.execute_reply.started": "2022-12-13T02:44:08.702669Z"
    },
    "id": "dQ_Eh4qMi6dA"
   },
   "outputs": [],
   "source": [
    "model_dir = 'models'\n",
    "data_dir = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T02:44:09.630782Z",
     "iopub.status.busy": "2022-12-13T02:44:09.630085Z",
     "iopub.status.idle": "2022-12-13T02:44:09.634319Z",
     "shell.execute_reply": "2022-12-13T02:44:09.633605Z",
     "shell.execute_reply.started": "2022-12-13T02:44:09.630752Z"
    },
    "id": "HHejuM1kh4i8"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T02:44:10.589236Z",
     "iopub.status.busy": "2022-12-13T02:44:10.588842Z",
     "iopub.status.idle": "2022-12-13T02:44:10.592952Z",
     "shell.execute_reply": "2022-12-13T02:44:10.592151Z",
     "shell.execute_reply.started": "2022-12-13T02:44:10.589212Z"
    },
    "id": "eyHY5YMAi5D9"
   },
   "outputs": [],
   "source": [
    "argument_filepath = os.path.join(data_dir, 'arguments.tsv')\n",
    "value_json_filepath = os.path.join(data_dir, 'values.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T02:44:11.859677Z",
     "iopub.status.busy": "2022-12-13T02:44:11.859307Z",
     "iopub.status.idle": "2022-12-13T02:44:11.880088Z",
     "shell.execute_reply": "2022-12-13T02:44:11.879454Z",
     "shell.execute_reply.started": "2022-12-13T02:44:11.859652Z"
    },
    "id": "cNk-VDCUjPh1"
   },
   "outputs": [],
   "source": [
    "df_arguments = load_arguments_from_tsv(argument_filepath, default_usage='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T02:44:13.060308Z",
     "iopub.status.busy": "2022-12-13T02:44:13.059920Z",
     "iopub.status.idle": "2022-12-13T02:44:13.066199Z",
     "shell.execute_reply": "2022-12-13T02:44:13.065385Z",
     "shell.execute_reply.started": "2022-12-13T02:44:13.060279Z"
    },
    "id": "cN1Ugt6xjUla"
   },
   "outputs": [],
   "source": [
    "values = load_values_from_json(value_json_filepath)\n",
    "num_labels_Lv2 = len(values['2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-12-13T02:44:14.485518Z",
     "iopub.status.busy": "2022-12-13T02:44:14.485117Z",
     "iopub.status.idle": "2022-12-13T02:44:14.495051Z",
     "shell.execute_reply": "2022-12-13T02:44:14.494247Z",
     "shell.execute_reply.started": "2022-12-13T02:44:14.485492Z"
    },
    "id": "-sZzSzdQmYi7",
    "outputId": "042cc346-7f43-48e8-b248-46c9c722acb9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Argument ID', 'Part', 'Usage', 'Conclusion', 'Stance', 'Premise'], dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_arguments.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-12-13T02:44:36.606535Z",
     "iopub.status.busy": "2022-12-13T02:44:36.606138Z",
     "iopub.status.idle": "2022-12-13T02:44:36.609867Z",
     "shell.execute_reply": "2022-12-13T02:44:36.609086Z",
     "shell.execute_reply.started": "2022-12-13T02:44:36.606511Z"
    },
    "id": "gRHUX8b_n9ve",
    "outputId": "8b52509e-214d-4f5e-f46b-cb813b9f5257",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for ip in df_arguments['Argument ID']:\n",
    "#   #print(df_arguments['Stance'][ip])\n",
    "  \n",
    "#   print(ip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FSWkx8gtkBbJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0rBc8dRchf5e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T02:44:40.797775Z",
     "iopub.status.busy": "2022-12-13T02:44:40.797366Z",
     "iopub.status.idle": "2022-12-13T02:44:40.818451Z",
     "shell.execute_reply": "2022-12-13T02:44:40.817831Z",
     "shell.execute_reply.started": "2022-12-13T02:44:40.797751Z"
    },
    "id": "b-L7fgEjnXGK"
   },
   "outputs": [],
   "source": [
    "level =2\n",
    "label_filepath = os.path.join(data_dir, 'labels-level{}.tsv'.format(str(level)))\n",
    "df_labels = load_labels_from_tsv(label_filepath, values[str(level)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-12-13T02:44:41.424036Z",
     "iopub.status.busy": "2022-12-13T02:44:41.423640Z",
     "iopub.status.idle": "2022-12-13T02:44:41.429435Z",
     "shell.execute_reply": "2022-12-13T02:44:41.428614Z",
     "shell.execute_reply.started": "2022-12-13T02:44:41.424011Z"
    },
    "id": "WIBMeZIfntMM",
    "outputId": "59c82c60-d08c-484d-f80e-694e9825abe4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5270 Argument ID\n",
      "5270 Achievement\n",
      "5270 Benevolence: caring\n",
      "5270 Benevolence: dependability\n",
      "5270 Conformity: interpersonal\n",
      "5270 Conformity: rules\n",
      "5270 Face\n",
      "5270 Hedonism\n",
      "5270 Humility\n",
      "5270 Power: dominance\n",
      "5270 Power: resources\n",
      "5270 Security: personal\n",
      "5270 Security: societal\n",
      "5270 Self-direction: action\n",
      "5270 Self-direction: thought\n",
      "5270 Stimulation\n",
      "5270 Tradition\n",
      "5270 Universalism: concern\n",
      "5270 Universalism: nature\n",
      "5270 Universalism: objectivity\n",
      "5270 Universalism: tolerance\n"
     ]
    }
   ],
   "source": [
    "a = df_labels.keys()\n",
    "for key in df_labels.keys():\n",
    "  print(len(df_labels[key]),key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h7ONfVdGtsQ5",
    "outputId": "4f4d4dd1-f9dc-4f3c-9948-04a246f8096c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_labels['Achievement'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T02:44:45.945060Z",
     "iopub.status.busy": "2022-12-13T02:44:45.944641Z",
     "iopub.status.idle": "2022-12-13T02:44:45.948609Z",
     "shell.execute_reply": "2022-12-13T02:44:45.947866Z",
     "shell.execute_reply.started": "2022-12-13T02:44:45.945029Z"
    },
    "id": "MurNX18XjWIw"
   },
   "outputs": [],
   "source": [
    "from typing import Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T02:44:46.606739Z",
     "iopub.status.busy": "2022-12-13T02:44:46.606357Z",
     "iopub.status.idle": "2022-12-13T02:44:46.613469Z",
     "shell.execute_reply": "2022-12-13T02:44:46.612723Z",
     "shell.execute_reply.started": "2022-12-13T02:44:46.606710Z"
    },
    "id": "PY77MuApiuUW"
   },
   "outputs": [],
   "source": [
    "def generate_pairwise_input(dataset, labels, datatype):\n",
    "    \"\"\"\n",
    "    TODO: group all premises and corresponding hypotheses and labels of the datapoints\n",
    "    a datapoint as seen earlier is a dict of premis, hypothesis and label\n",
    "    \"\"\"\n",
    "    #raise NotImplementedError\n",
    "    premise=[]\n",
    "    conclusion=[]\n",
    "    stance=[]\n",
    "    n_labels =labels.keys()\n",
    "    n_labels = n_labels[1:]\n",
    "    print(n_labels)\n",
    "    label=[]\n",
    "    \n",
    "    n = len(dataset['Argument ID'])\n",
    "    m = len(labels['Argument ID'])\n",
    "    arguments = []\n",
    "    print(n,m)\n",
    "    for i in range(n):\n",
    "        if dataset['Usage'][i]==datatype:\n",
    "          premise.append(dataset['Premise'][i])\n",
    "          conclusion.append(dataset['Conclusion'][i])\n",
    "          stance.append(dataset['Stance'][i])\n",
    "          arguments.append(dataset['Argument ID'][i])\n",
    "    for i in range(m):\n",
    "        if (labels['Argument ID'][i] in arguments):\n",
    "          sent_label = []\n",
    "          #print(i)\n",
    "          for l in range(len(n_labels)):\n",
    "              #print(n_labels[l])\n",
    "              sent_label.append(int(labels[n_labels[l]][i]))\n",
    "          label.append(sent_label)\n",
    "\n",
    "    return premise, conclusion, stance, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U6AANdaaoghx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-12-13T02:44:49.183127Z",
     "iopub.status.busy": "2022-12-13T02:44:49.182711Z",
     "iopub.status.idle": "2022-12-13T02:44:50.188227Z",
     "shell.execute_reply": "2022-12-13T02:44:50.187496Z",
     "shell.execute_reply.started": "2022-12-13T02:44:49.183099Z"
    },
    "id": "9WvikqGWln63",
    "outputId": "06e60c37-1072-4d6d-f4a5-9668567d4af1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Achievement', 'Benevolence: caring', 'Benevolence: dependability',\n",
      "       'Conformity: interpersonal', 'Conformity: rules', 'Face', 'Hedonism',\n",
      "       'Humility', 'Power: dominance', 'Power: resources',\n",
      "       'Security: personal', 'Security: societal', 'Self-direction: action',\n",
      "       'Self-direction: thought', 'Stimulation', 'Tradition',\n",
      "       'Universalism: concern', 'Universalism: nature',\n",
      "       'Universalism: objectivity', 'Universalism: tolerance'],\n",
      "      dtype='object')\n",
      "5270 5270\n",
      "Index(['Achievement', 'Benevolence: caring', 'Benevolence: dependability',\n",
      "       'Conformity: interpersonal', 'Conformity: rules', 'Face', 'Hedonism',\n",
      "       'Humility', 'Power: dominance', 'Power: resources',\n",
      "       'Security: personal', 'Security: societal', 'Self-direction: action',\n",
      "       'Self-direction: thought', 'Stimulation', 'Tradition',\n",
      "       'Universalism: concern', 'Universalism: nature',\n",
      "       'Universalism: objectivity', 'Universalism: tolerance'],\n",
      "      dtype='object')\n",
      "5270 5270\n",
      "Index(['Achievement', 'Benevolence: caring', 'Benevolence: dependability',\n",
      "       'Conformity: interpersonal', 'Conformity: rules', 'Face', 'Hedonism',\n",
      "       'Humility', 'Power: dominance', 'Power: resources',\n",
      "       'Security: personal', 'Security: societal', 'Self-direction: action',\n",
      "       'Self-direction: thought', 'Stimulation', 'Tradition',\n",
      "       'Universalism: concern', 'Universalism: nature',\n",
      "       'Universalism: objectivity', 'Universalism: tolerance'],\n",
      "      dtype='object')\n",
      "5270 5270\n"
     ]
    }
   ],
   "source": [
    "train_premises, train_conclusion, train_stance, train_labels = generate_pairwise_input(df_arguments, df_labels, 'train')\n",
    "val_premises, val_conclusion, val_stance, val_labels = generate_pairwise_input(df_arguments, df_labels, 'validation')\n",
    "test_premises, test_conclusion, test_stance, test_labels = generate_pairwise_input(df_arguments, df_labels, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "FBU9bpZwjvH9"
   },
   "outputs": [],
   "source": [
    "#Randomize them first\n",
    "# train_premises, train_conclusion, train_stance, train_labels = generate_pairwise_input(df_arguments, df_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "nKP166RxYrGw"
   },
   "outputs": [],
   "source": [
    "# import random \n",
    "# random.seed(42)\n",
    "# def randomize_data(premises, conclusion, stance, labels):\n",
    "#   n = len(premises)\n",
    "#   data = list(range(n))\n",
    "#   random.shuffle(data)\n",
    "#   train_premises = []\n",
    "#   train_conclusion = []\n",
    "#   train_stance = []\n",
    "#   train_labels = []\n",
    "#   for i in data:\n",
    "#     train_premises.append(premises[i])\n",
    "#     train_conclusion.append(conclusion[i])\n",
    "#     train_stance.append(stance[i])\n",
    "#     train_labels.append(labels[:][i])\n",
    "#   return train_premises, train_conclusion, train_stance, train_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "0Ye8wftgaawi"
   },
   "outputs": [],
   "source": [
    "# train_premises, train_conclusion, train_stance, train_labels = randomize_data(train_premises, train_conclusion, train_stance, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "o3ygsKZZzBhs"
   },
   "outputs": [],
   "source": [
    "# val_premises = train_premises[-500:]\n",
    "# val_conclusion = train_conclusion[-500:]\n",
    "# val_stance = train_stance[-500:]\n",
    "# val_labels = train_labels[:][-500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "KveGMjWxzpFF"
   },
   "outputs": [],
   "source": [
    "# train_premises = train_premises[:-500]\n",
    "# train_conclusion = train_conclusion[:-500]\n",
    "# train_stance = train_stance[:-500]\n",
    "# train_labels = train_labels[:][:-500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266,
     "referenced_widgets": [
      "256538012e7a4b38b7b3ac69b51ff941",
      "a1d7aec29ded41b393f2cb5c42fde010",
      "cadca92ef4524a4ba0d46c9518cdb4f0",
      "68384eae9d9c4dcd9a3f2fb6d659ba3c",
      "e0669bb1b79645b996d83b81a2a2df21",
      "ea7590ad5302420e96cbd4f844e1cd1e",
      "2ef6ac57065a4646a8ac646ba0a0092f",
      "928e5719d3d844778e28851dadf15dbb",
      "a40fae8ff5c64755ac56ce47da45aee2",
      "320c7492a5794e28809a17403446da22",
      "20a46cf22cb14596a0e17d536427be54",
      "d434d7bc611a49eea10ac8754452f958",
      "3d9ef44ea2c748028c3a4b35acbebd63",
      "18817eb31c11408681bfc10fd79c552e",
      "b72be35ae5ef433382398a8f0171f7aa",
      "f73c5af633c7461e886ba6bb955ea7bc",
      "a6336c1fa3d44b638401f46c5833ed2d",
      "501bbc487feb4c4e8ee2d0e1e69c7e64",
      "f51568078be64c7393c71901cff90e87",
      "8b86dc099d57423ea042785d18647534",
      "21c0b45558584fb59ec527adca6f8518",
      "e327b538ff384d7ea635a0a19fa8c466",
      "cc395cf0ce604d768b29ed37a85c3a75",
      "d92b09abe9024a9a8611ca6924a412f4",
      "62283bbf1bfc45a6a6a682fc0e3dce12",
      "e61e8e1ba35443609f658c89e1844ea6",
      "9331b69151ef41148d5c659b8d32d8f8",
      "016be63768c24b85ad49ebcc6bf8530c",
      "da4b5c83e2534ca48e8b8b941a0355ea",
      "ed5200fc756b458593015c4326352947",
      "b282c1b4420c4eb4a082cdeb442c156f",
      "f2c57abc7ba34a41a3f43507bc5d9561",
      "dbd5e6843716491baecf275a652359ef",
      "6801b124877349a8a98023c8eb5e815c",
      "b7d2773434d44e2a938f996f3529e440",
      "4a57a6d299c84c67a1eaccddd22333f7",
      "0731022940e34eeea4d31220521bc634",
      "5b9c47e409e1470c8c0b41c9eb0f64ba",
      "536259048b704e86a6029f500fa440e6",
      "9f58864f0565433398c9dde618cc399e",
      "af31b60f9817474985e11f21e6974bbe",
      "eda9f732b10b4a9887cc98a993beab6e",
      "ea568e71d4aa491ab98a583f43c26541",
      "0934dbfde784417eb416b2cb39c151b3"
     ]
    },
    "execution": {
     "iopub.execute_input": "2022-12-13T02:45:00.917945Z",
     "iopub.status.busy": "2022-12-13T02:45:00.917556Z",
     "iopub.status.idle": "2022-12-13T02:45:01.882554Z",
     "shell.execute_reply": "2022-12-13T02:45:01.881731Z",
     "shell.execute_reply.started": "2022-12-13T02:45:00.917920Z"
    },
    "id": "XhW38nWHv2tj",
    "outputId": "77e3f82e-00ed-427a-e9e5-4cfecee9eab6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9529b08ace314f8da0fcb8c66b55fdfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fb39250f9da4bffbd1e038831148c96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6deb391c976749c09b251f529b6249fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f42f90b1af64f0fae081367384359d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  2023,  2003,  1996, 18458,  1012,   102,  1999,  7927,  1997,\n",
      "          2023,  2003,  1996, 10744,   102],\n",
      "        [  101,  2023,  2003,  2036,  1037, 18458,   102,  2114,  2023,  2003,\n",
      "          1037,  2117, 10744,   102,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['[CLS] this is the premise. [SEP] in favour of this is the hypothesis [SEP]',\n",
       " '[CLS] this is also a premise [SEP] against this is a second hypothesis [SEP] [PAD]']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nothing to do for this class!\n",
    "import torch\n",
    "from transformers import BertModel\n",
    "from transformers import AutoTokenizer\n",
    "from typing import Dict, List\n",
    "\n",
    "class BatchTokenizer:\n",
    "    \"\"\"Tokenizes and pads a batch of input sentences.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initializes the tokenizer\n",
    "\n",
    "        Args:\n",
    "            pad_symbol (Optional[str], optional): The symbol for a pad. Defaults to \"<P>\".\n",
    "        \"\"\"\n",
    "        self.hf_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    \n",
    "    def get_sep_token(self,):\n",
    "        return self.hf_tokenizer.sep_token\n",
    "    \n",
    "    def __call__(self, prem_batch: List[str], hyp_batch: List[str], stance_batch: List[str]) -> List[List[str]]:\n",
    "        \"\"\"Uses the huggingface tokenizer to tokenize and pad a batch.\n",
    "\n",
    "        We return a dictionary of tensors per the huggingface model specification.\n",
    "\n",
    "        Args:\n",
    "            batch (List[str]): A List of sentence strings\n",
    "\n",
    "        Returns:\n",
    "            Dict: The dictionary of token specifications provided by HuggingFace\n",
    "        \"\"\"\n",
    "        # The HF tokenizer will PAD for us, and additionally combine \n",
    "        # The two sentences deimited by the [SEP] token.\n",
    "        batch_len = len(prem_batch)\n",
    "        #spaces = [\" \"]*batch_len\n",
    "        conc_batch = [stance_batch[i]+\" \"+hyp_batch[i] for i in range(batch_len)]\n",
    "        enc = self.hf_tokenizer(\n",
    "            prem_batch,\n",
    "            conc_batch,\n",
    "            padding=True,\n",
    "            return_token_type_ids=False,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return enc\n",
    "    \n",
    "\n",
    "# HERE IS AN EXAMPLE OF HOW TO USE THE BATCH TOKENIZER\n",
    "tokenizer = BatchTokenizer()\n",
    "a = [[\"this is the premise.\", \"This is also a premise\"], [\"this is the hypothesis\", \"This is a second hypothesis\"],[\"in favour of\", \"against\"]]\n",
    "x = tokenizer(*a)\n",
    "print(x)\n",
    "tokenizer.hf_tokenizer.batch_decode(x[\"input_ids\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T02:45:14.152341Z",
     "iopub.status.busy": "2022-12-13T02:45:14.151968Z",
     "iopub.status.idle": "2022-12-13T02:45:14.159088Z",
     "shell.execute_reply": "2022-12-13T02:45:14.158245Z",
     "shell.execute_reply.started": "2022-12-13T02:45:14.152315Z"
    },
    "id": "FQWwRKXgrYRY"
   },
   "outputs": [],
   "source": [
    "def chunk(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[:][i:i + n]\n",
    "\n",
    "def chunk_multi(lst1, lst2, lst3, n):\n",
    "    for i in range(0, len(lst1), n):\n",
    "        yield lst1[i: i + n], lst2[i: i + n], lst3[i: i + n]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-12-13T02:45:20.743432Z",
     "iopub.status.busy": "2022-12-13T02:45:20.743021Z",
     "iopub.status.idle": "2022-12-13T02:45:20.755493Z",
     "shell.execute_reply": "2022-12-13T02:45:20.754803Z",
     "shell.execute_reply.started": "2022-12-13T02:45:20.743405Z"
    },
    "id": "tCdddSnCwwmA",
    "outputId": "4d1bd1cd-5915-4110-ba12-22692d0168d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14675\n"
     ]
    }
   ],
   "source": [
    "sum=0\n",
    "import numpy as np\n",
    "# for i in range(5270):\n",
    "#   sum += np.sum(np.array(train_labels[:][i]))\n",
    "print(np.sum(np.array(train_labels)))\n",
    "#print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T02:45:21.743206Z",
     "iopub.status.busy": "2022-12-13T02:45:21.742789Z",
     "iopub.status.idle": "2022-12-13T02:45:21.746522Z",
     "shell.execute_reply": "2022-12-13T02:45:21.745713Z",
     "shell.execute_reply.started": "2022-12-13T02:45:21.743179Z"
    },
    "id": "nchPyT3yAtW3"
   },
   "outputs": [],
   "source": [
    "# against=0\n",
    "# infavour = 0\n",
    "# for i in range(4770):\n",
    "#   if(train_stance[i]=='against'):\n",
    "#     against +=1\n",
    "#   elif(train_stance[i]=='in favor of'):\n",
    "#     infavour += 1\n",
    "#   else:\n",
    "#     print(train_stance[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T02:45:29.573266Z",
     "iopub.status.busy": "2022-12-13T02:45:29.572874Z",
     "iopub.status.idle": "2022-12-13T02:45:29.996553Z",
     "shell.execute_reply": "2022-12-13T02:45:29.995852Z",
     "shell.execute_reply.started": "2022-12-13T02:45:29.573242Z"
    },
    "id": "v-COBdmXv1Gf"
   },
   "outputs": [],
   "source": [
    "# Notice that since we use huggingface, we tokenize and\n",
    "# encode in all at once!\n",
    "batch_size=64\n",
    "tokenizer = BatchTokenizer()\n",
    "train_input_batches = [b for b in chunk_multi(train_premises, train_conclusion, train_stance, batch_size)]\n",
    "# Tokenize + encode\n",
    "train_input_batches = [tokenizer(*batch) for batch in train_input_batches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "E-H-JWr6-snT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T02:45:33.570360Z",
     "iopub.status.busy": "2022-12-13T02:45:33.569967Z",
     "iopub.status.idle": "2022-12-13T02:45:33.594567Z",
     "shell.execute_reply": "2022-12-13T02:45:33.593930Z",
     "shell.execute_reply.started": "2022-12-13T02:45:33.570333Z"
    },
    "id": "W_ta_vSAx4oz"
   },
   "outputs": [],
   "source": [
    "val_input_batches = [b for b in chunk_multi(val_premises, val_conclusion, val_stance, batch_size)]\n",
    "# Tokenize + encode\n",
    "val_input_batches = [tokenizer(*batch) for batch in val_input_batches]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-12-13T02:45:34.355011Z",
     "iopub.status.busy": "2022-12-13T02:45:34.354621Z",
     "iopub.status.idle": "2022-12-13T02:45:34.359633Z",
     "shell.execute_reply": "2022-12-13T02:45:34.358932Z",
     "shell.execute_reply.started": "2022-12-13T02:45:34.354986Z"
    },
    "id": "3VwgQMkk1ZxW",
    "outputId": "f4212d30-26e6-40f7-8acb-2937967187f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "277"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T02:45:35.525532Z",
     "iopub.status.busy": "2022-12-13T02:45:35.525128Z",
     "iopub.status.idle": "2022-12-13T02:45:35.529805Z",
     "shell.execute_reply": "2022-12-13T02:45:35.529145Z",
     "shell.execute_reply.started": "2022-12-13T02:45:35.525507Z"
    },
    "id": "Dxc4DhACkRub"
   },
   "outputs": [],
   "source": [
    "label_ids = ['Achievement', 'Benevolence: caring', 'Benevolence: dependability',\n",
    "       'Conformity: interpersonal', 'Conformity: rules', 'Face', 'Hedonism',\n",
    "       'Humility', 'Power: dominance', 'Power: resources',\n",
    "       'Security: personal', 'Security: societal', 'Self-direction: action',\n",
    "       'Self-direction: thought', 'Stimulation', 'Tradition',\n",
    "       'Universalism: concern', 'Universalism: nature',\n",
    "       'Universalism: objectivity', 'Universalism: tolerance']\n",
    "l_ids = []\n",
    "for l in label_ids:\n",
    "    a =[l]\n",
    "    l_ids.append(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "id": "9bsKdbnIkuIm",
    "outputId": "8c2c0de9-1d22-41f4-c71d-f40410da91b0"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9730087c466c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-base-uncased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Check the dependencies satisfy the minimal versions required.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdependency_versions_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m from .utils import (\n\u001b[1;32m     32\u001b[0m     \u001b[0mOptionalDependencyNotAvailable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/dependency_versions_check.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdependency_versions_table\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequire_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_version_core\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mreplace_return_docstrings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m )\n\u001b[0;32m---> 34\u001b[0;31m from .generic import (\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mContextManagers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mExplicitEnum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_tf_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_flax_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_typing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunction_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcoordination_config_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mattr_value_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_attr__value__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnode_def_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_node__def__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mop_def_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_op__def__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/attr_value_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_tensor__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_shape_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_types__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/tensor_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresource_handle_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_resource__handle__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_shape_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_types__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/resource_handle_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_shape_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_types__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/tensor_shape_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0mcontaining_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m   fields=[\n\u001b[0;32m---> 36\u001b[0;31m     _descriptor.FieldDescriptor(\n\u001b[0m\u001b[1;32m     37\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tensorflow.TensorShapeProto.Dim.size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m       \u001b[0mnumber\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpp_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/protobuf/descriptor.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, name, full_name, index, number, type, cpp_type, label, default_value, message_type, enum_type, containing_type, is_extension, extension_scope, options, serialized_options, has_default_value, containing_oneof, json_name, file, create_key)\u001b[0m\n\u001b[1;32m    558\u001b[0m                 \u001b[0mhas_default_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontaining_oneof\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m                 file=None, create_key=None):  # pylint: disable=redefined-builtin\n\u001b[0;32m--> 560\u001b[0;31m       \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_CheckCalledFromGeneratedFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mis_extension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFindExtensionByName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Descriptors cannot not be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import numpy as np\n",
    "embeddings = []\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "for i in range(20):\n",
    "    input_ids = tokenizer(l_ids[i], return_tensors=\"pt\")\n",
    "    output = model(**input_ids)\n",
    "    final_layer = output.last_hidden_state[:,0,:]\n",
    "    #print(final_layer.shape)\n",
    "    #hidden_shape = final_layer.shape\n",
    "    #embed = torch.reshape(final_layer,(1,hidden_shape[1]) )\n",
    "    embed = final_layer[0]\n",
    "    embeddings.append(embed.detach().numpy())\n",
    "embeddings = np.array(embeddings)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rcpr79zBlkA4"
   },
   "outputs": [],
   "source": [
    "from nltk.cluster import KMeansClusterer\n",
    "import nltk\n",
    "\n",
    "def clustering_question(data,NUM_CLUSTERS = 5):\n",
    "    kclusterer = KMeansClusterer(\n",
    "        NUM_CLUSTERS, distance=nltk.cluster.util.cosine_distance,\n",
    "        repeats=1000,avoid_empty_clusters=True)\n",
    "\n",
    "    assigned_clusters = kclusterer.cluster(data, assign_clusters=True)\n",
    "\n",
    "    return assigned_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UTzmh5jllbgN",
    "outputId": "573cc32e-8a40-4a34-90aa-0daffdf3e269"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 0, 0, 3, 1, 2, 1, 4, 4, 1, 2, 3, 3, 1, 1, 2, 0, 0, 0]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters = clustering_question(embeddings)\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "R1_4wLaXlff-",
    "outputId": "ef8e9495-1a77-4ce6-8b0a-d622179c1f18"
   },
   "outputs": [],
   "source": [
    "cluster_labels =[[],[],[],[],[]]\n",
    "cluster_ids = [[],[],[],[],[]]\n",
    "for i in range(20):\n",
    "    cluster_labels[clusters[i]].append(label_ids[i])\n",
    "    cluster_ids[clusters[i]].append(i)\n",
    "cluster_ids, cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xF7TKu_Snw2Q",
    "outputId": "f4a573f2-fa84-4828-9b84-8ddbf7842269"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Achievement\n",
      "1 Benevolence: caring\n",
      "2 Benevolence: dependability\n",
      "3 Conformity: interpersonal\n",
      "4 Conformity: rules\n",
      "5 Face\n",
      "6 Hedonism\n",
      "7 Humility\n",
      "8 Power: dominance\n",
      "9 Power: resources\n",
      "10 Security: personal\n",
      "11 Security: societal\n",
      "12 Self-direction: action\n",
      "13 Self-direction: thought\n",
      "14 Stimulation\n",
      "15 Tradition\n",
      "16 Universalism: concern\n",
      "17 Universalism: nature\n",
      "18 Universalism: objectivity\n",
      "19 Universalism: tolerance\n",
      "(array([11]),) if entrapment can serve to more easily capture wanted criminals, then why shouldn't it be legal? [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "  print(i, label_ids[i])\n",
    "print(np.nonzero(train_labels[0]), train_premises[0], train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a3Iu_ZuV-frm"
   },
   "outputs": [],
   "source": [
    "# 0 Self-direction: thought\n",
    "# 1 Self-direction: action\t\n",
    "# 2 Stimulation\t\n",
    "# 3 Hedonism\t\n",
    "# 4 Achievement\t\n",
    "# 5 Power: dominance\t\n",
    "# 6 Power: resources\t\n",
    "# 7 Face\t\n",
    "# 8 Security: personal\t\n",
    "# 9 Security: societal\t\n",
    "# 10 Tradition\t\n",
    "# 11 Conformity: rules\t\n",
    "# 12 Conformity: interpersonal\t\n",
    "# 13 Humility\t\n",
    "# 14 Benevolence: caring\t\n",
    "# 15 Benevolence: dependability\t\n",
    "# 16 Universalism: concern\t\n",
    "# 17 Universalism: nature\t\n",
    "# 18 Universalism: tolerance\t\n",
    "# 19 Universalism: objectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "mJkxz-oO_MRQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T02:45:50.832297Z",
     "iopub.status.busy": "2022-12-13T02:45:50.831601Z",
     "iopub.status.idle": "2022-12-13T02:45:50.836567Z",
     "shell.execute_reply": "2022-12-13T02:45:50.835799Z",
     "shell.execute_reply.started": "2022-12-13T02:45:50.832266Z"
    },
    "id": "mU8iunXrrdbL"
   },
   "outputs": [],
   "source": [
    "# Achievement, Face, Power: dominance, Power: resources [0, 5, 8, 9]\n",
    "\n",
    "\n",
    "#Benevolence: caring, Benevolence: dependability, Humility, Universalism: concern [1,2,7, 16]\n",
    "\n",
    "\n",
    "# Stimulation, Tradition, Self-direction: action, Self-direction: thought [14, 15, 12, 13]\n",
    "\n",
    "\n",
    "# Conformity: interpersonal, Conformity: rules, Security: personal, Security: societal [3, 4, 10, 11]\n",
    "\n",
    "\n",
    "# Hedonism, Universalism: nature, Universalism: objectivity, Universalism: tolerance [6, 17,18, 19]\n",
    "# Note: This is just one possible way to group these elements. There may be other valid ways to do so.\n",
    "\n",
    "\n",
    "clusters = [\n",
    "    [0, 5, 8, 9],\n",
    "    [1,2,7, 16],\n",
    "    [14, 15, 12, 13],\n",
    "    [3, 4, 10, 11],\n",
    "    [6, 17,18, 19]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "tAPLWzNFx71C"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IqLlXo05x7Fo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VbvwzIAlx45h"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HMlX5V9uvxnb",
    "outputId": "f3a279f2-9d59-4673-8fc0-16a0378b3ee2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T02:45:55.443494Z",
     "iopub.status.busy": "2022-12-13T02:45:55.443061Z",
     "iopub.status.idle": "2022-12-13T02:45:55.448890Z",
     "shell.execute_reply": "2022-12-13T02:45:55.448085Z",
     "shell.execute_reply.started": "2022-12-13T02:45:55.443469Z"
    },
    "id": "XgY4RO1-05Tz"
   },
   "outputs": [],
   "source": [
    "def encode_labels(labels: List[List[int]]) -> torch.FloatTensor:\n",
    "    \"\"\"Turns the batch of labels into a tensor\n",
    "\n",
    "    Args:\n",
    "        labels (List[List[int]]): List of all labels in the batch\n",
    "\n",
    "    Returns:\n",
    "        torch.FloatTensor: Tensor of all labels in the batch\n",
    "    \"\"\"\n",
    "    \n",
    "    extended_labels = []\n",
    "    for i in range(len(labels)):\n",
    "      elabels = [p for p in labels[i]]\n",
    "      #Cluster 0\n",
    "      for j in range(len(clusters)):\n",
    "        clf = clusters[j]\n",
    "        l = 0\n",
    "        for k in clusters[j]:\n",
    "          if(elabels[k]==1):\n",
    "            l = 1\n",
    "            break\n",
    "        elabels.append(l)\n",
    "      extended_labels.append(elabels)\n",
    "    #print(len(extended_labels[0]), len(labels[0]))\n",
    "    return torch.LongTensor(extended_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-12-13T02:45:57.751567Z",
     "iopub.status.busy": "2022-12-13T02:45:57.751178Z",
     "iopub.status.idle": "2022-12-13T02:45:57.758490Z",
     "shell.execute_reply": "2022-12-13T02:45:57.757883Z",
     "shell.execute_reply.started": "2022-12-13T02:45:57.751540Z"
    },
    "id": "d8msMWSo23d1",
    "outputId": "06f55c7d-25d4-45e8-9a34-0d19edb143d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([12, 13, 15, 16]),),\n",
       " tensor([[12],\n",
       "         [13],\n",
       "         [15],\n",
       "         [16],\n",
       "         [21],\n",
       "         [22]]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_labels = encode_labels(train_labels[0:10])\n",
    "np.nonzero(train_labels[9]), np.nonzero(check_labels[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-12-13T02:46:01.765826Z",
     "iopub.status.busy": "2022-12-13T02:46:01.765431Z",
     "iopub.status.idle": "2022-12-13T02:46:01.827964Z",
     "shell.execute_reply": "2022-12-13T02:46:01.827109Z",
     "shell.execute_reply.started": "2022-12-13T02:46:01.765800Z"
    },
    "id": "MVvh4bZAgTcu",
    "outputId": "94b623a4-8d4c-4e77-9767-b90a646ce9bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-12-13T02:46:06.617376Z",
     "iopub.status.busy": "2022-12-13T02:46:06.616963Z",
     "iopub.status.idle": "2022-12-13T02:46:06.633908Z",
     "shell.execute_reply": "2022-12-13T02:46:06.633047Z",
     "shell.execute_reply.started": "2022-12-13T02:46:06.617351Z"
    },
    "id": "cw7wSXAk19YY",
    "outputId": "ed1c724d-ee29-4369-a7e6-ae3c7ff266bf"
   },
   "outputs": [],
   "source": [
    "train_label_batches = [b for b in chunk(train_labels, batch_size)]\n",
    "train_label_batches = [encode_labels(batch) for batch in train_label_batches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T02:46:08.245221Z",
     "iopub.status.busy": "2022-12-13T02:46:08.244828Z",
     "iopub.status.idle": "2022-12-13T02:46:08.250140Z",
     "shell.execute_reply": "2022-12-13T02:46:08.249278Z",
     "shell.execute_reply.started": "2022-12-13T02:46:08.245196Z"
    },
    "id": "s2Jl56Mg2HdF"
   },
   "outputs": [],
   "source": [
    "val_label_batches = [b for b in chunk(val_labels, batch_size)]\n",
    "val_label_batches = [encode_labels(batch) for batch in val_label_batches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a9i5nn1qT244",
    "outputId": "35c768c0-57f8-4171-cce9-088020aa7b8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "        1])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_label_batches[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T06:07:41.438953Z",
     "iopub.status.busy": "2022-12-13T06:07:41.438557Z",
     "iopub.status.idle": "2022-12-13T06:07:41.695765Z",
     "shell.execute_reply": "2022-12-13T06:07:41.694828Z",
     "shell.execute_reply.started": "2022-12-13T06:07:41.438928Z"
    },
    "id": "qsgi7io72ewY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GroupedClassifier(torch.nn.Module):\n",
    "    def __init__(self, output_size: int, hidden_size: int):\n",
    "        super().__init__()\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        # Initialize BERT, which we use instead of a single embedding layer.\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        # TODO [OPTIONAL]: Updating all BERT parameters can be slow and memory intensive. \n",
    "        # Freeze them if training is too slow. Notice that the learning\n",
    "        # rate should probably be smaller in this case.\n",
    "        # Uncommenting out the below 2 lines means only our classification layer will be updated.\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.bert_hidden_dimension = self.bert.config.hidden_size\n",
    "        print(self.bert_hidden_dimension)\n",
    "        # TODO: Add an extra hidden layer in the classifier, projecting\n",
    "        #      from the BERT hidden dimension to hidden size.\n",
    "        # TODO: Add a relu nonlinearity to be used in the forward method\n",
    "        #      https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html\n",
    "        self.hidden_layer = torch.nn.Linear(self.bert_hidden_dimension, 512)\n",
    "        self.middle_layer1 = torch.nn.Linear(512, 64)\n",
    "        self.middle_layer2 = torch.nn.Linear(512, 64)\n",
    "        self.middle_layer3 = torch.nn.Linear(512, 64)\n",
    "        self.middle_layer4 = torch.nn.Linear(512, 64)\n",
    "        self.middle_layer5 = torch.nn.Linear(512, 64)\n",
    "        #self.middle_layer6 = torch.nn.Linear(self.bert_hidden_dimension, 64)\n",
    "        \n",
    "        \n",
    "        self.hidden_layer1 = torch.nn.Linear(64, 32)\n",
    "        self.hidden_layer2 = torch.nn.Linear(64, 32)\n",
    "        self.hidden_layer3 = torch.nn.Linear(64, 32)\n",
    "        self.hidden_layer4 = torch.nn.Linear(64, 32)\n",
    "        self.hidden_layer5 = torch.nn.Linear(64, 32)\n",
    "        self.hidden_layer6 = torch.nn.Linear(64, 32)\n",
    "        self.hidden_layer7 = torch.nn.Linear(64, 32)\n",
    "        self.hidden_layer8 = torch.nn.Linear(64, 32)\n",
    "        self.hidden_layer9 = torch.nn.Linear(64, 32)\n",
    "        self.hidden_layer10 = torch.nn.Linear(64, 32)\n",
    "        self.hidden_layer11 = torch.nn.Linear(64, 32)\n",
    "        self.hidden_layer12 = torch.nn.Linear(64, 32)\n",
    "        self.hidden_layer13 = torch.nn.Linear(64, 32)\n",
    "        self.hidden_layer14 = torch.nn.Linear(64, 32)\n",
    "        self.hidden_layer15 = torch.nn.Linear(64, 32)\n",
    "        self.hidden_layer16 = torch.nn.Linear(64, 32)\n",
    "        self.hidden_layer17 = torch.nn.Linear(64, 32)\n",
    "        self.hidden_layer18 = torch.nn.Linear(64, 32)\n",
    "        self.hidden_layer19 = torch.nn.Linear(64, 32)\n",
    "        self.hidden_layer20 = torch.nn.Linear(64, 32)\n",
    "        #self.hidden_layer2 = torch.nn.Linear(self.hidden_size, 32)\n",
    "        #self.hidden_layer3 = torch.nn.Linear(128, 32)\n",
    "        #self.hidden_layer4 = torch.nn.Linear(32, 8)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.classifier1 = torch.nn.Linear(32, 1)\n",
    "        self.classifier2 = torch.nn.Linear(32, 1)\n",
    "        self.classifier3 = torch.nn.Linear(32, 1)\n",
    "        self.classifier4 = torch.nn.Linear(32, 1)\n",
    "        self.classifier5 = torch.nn.Linear(32, 1)\n",
    "        self.classifier6 = torch.nn.Linear(32, 1)\n",
    "        self.classifier7 = torch.nn.Linear(32, 1)\n",
    "        self.classifier8 = torch.nn.Linear(32, 1)\n",
    "        self.classifier9 = torch.nn.Linear(32, 1)\n",
    "        self.classifier10 = torch.nn.Linear(32, 1)\n",
    "        self.classifier11 = torch.nn.Linear(32, 1)\n",
    "        self.classifier12 = torch.nn.Linear(32, 1)\n",
    "        self.classifier13 = torch.nn.Linear(32, 1)\n",
    "        self.classifier14 = torch.nn.Linear(32, 1)\n",
    "        self.classifier15 = torch.nn.Linear(32, 1)\n",
    "        self.classifier16 = torch.nn.Linear(32, 1)\n",
    "        self.classifier17 = torch.nn.Linear(32, 1)\n",
    "        self.classifier18 = torch.nn.Linear(32, 1)\n",
    "        self.classifier19 = torch.nn.Linear(32, 1)\n",
    "        self.classifier20 = torch.nn.Linear(32, 1)\n",
    "        \n",
    "        self.classifier_middle1 = torch.nn.Linear(64, 1)\n",
    "        self.classifier_middle2 = torch.nn.Linear(64, 1)\n",
    "        self.classifier_middle3 = torch.nn.Linear(64, 1)\n",
    "        self.classifier_middle4 = torch.nn.Linear(64, 1)\n",
    "        self.classifier_middle5 = torch.nn.Linear(64, 1)\n",
    "        #self.classifier = torch.nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.log_softmax = torch.nn.LogSoftmax(dim=2)\n",
    "\n",
    "    def encode_text(\n",
    "        self,\n",
    "        symbols: Dict\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Encode the (batch of) sequence(s) of token symbols with an LSTM.\n",
    "            Then, get the last (non-padded) hidden state for each symbol and return that.\n",
    "\n",
    "        Args:\n",
    "            symbols (Dict): The Dict of token specifications provided by the HuggingFace tokenizer\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The final hiddens tate of the LSTM, which represents an encoding of\n",
    "                the entire sentence\n",
    "        \"\"\"\n",
    "        # First we get the contextualized embedding for each input symbol\n",
    "        # We no longer need an LSTM, since BERT encodes context and \n",
    "        # gives us a single vector describing the sequence in the form of the [CLS] token.\n",
    "        embedded = self.bert(**symbols)\n",
    "        #print(embedded)\n",
    "        #print(\"Embedded\", embedded.pooler_output.shape, embedded.last_hidden_state.shape)\n",
    "        # TODO: Get the [CLS] token using the `pooler_output` from \n",
    "        #      The BertModel output. See here: https://huggingface.co/docs/transformers/model_doc/bert#transformers.BertModel\n",
    "        #      and check the returns for the forward method.\n",
    "        # We want to return a tensor of the form batch_size x 1 x bert_hidden_dimension\n",
    "        #raise NotImplementedError\n",
    "        \n",
    "        #pool_output_shape = embedded.pooler_output.shape\n",
    "        #return torch.reshape(embedded.pooler_output,(pool_output_shape[0],1,pool_output_shape[1]) )\n",
    "        last_hidden_state = embedded.last_hidden_state[:,0,:]\n",
    "        hidden_shape = last_hidden_state.shape\n",
    "        return torch.reshape(last_hidden_state,(hidden_shape[0],1,hidden_shape[1]) )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        symbols: Dict,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            symbols (Dict): The Dict of token specifications provided by the HuggingFace tokenizer\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: _description_\n",
    "        \"\"\"\n",
    "        encoded_sents = self.encode_text(symbols)\n",
    "        #output = self.hidden_layer1(encoded_sents)\n",
    "        #output = self.relu(output)\n",
    "        #outputs = [self.hidden_layers[i](encoded_sents) for i in range(self.output_size)]\n",
    "        #outputs = [self.relu(outputs[i].to(device)) for i in range(self.output_size)]\n",
    "        #outputs = [self.classifiers[i](outputs[i].to(device)) for i in range(self.output_size)]\n",
    "        # outputs = []\n",
    "        # for i in range(self.output_size):\n",
    "        #     output = self.hidden_layers[i](encoded_sents)\n",
    "        #     output = self.relu(output)\n",
    "        #     output = self.classifiers[i](output)\n",
    "        #     output = torch.nn.Sigmoid()(output)\n",
    "        #     outputs.append(output)\n",
    "        enc = self.hidden_layer(encoded_sents)\n",
    "        middle1 = self.middle_layer1(enc)\n",
    "        middle1 = self.relu(middle1)\n",
    "        middle_output1 = self.classifier_middle1(middle1)\n",
    "        middle_output1 = torch.nn.Sigmoid()(middle_output1)\n",
    "        \n",
    "        middle2 = self.middle_layer2(enc)\n",
    "        middle2 = self.relu(middle2)\n",
    "        middle_output2 = self.classifier_middle2(middle2)\n",
    "        middle_output2 = torch.nn.Sigmoid()(middle_output2)\n",
    "        \n",
    "        middle3 = self.middle_layer3(enc)\n",
    "        middle3 = self.relu(middle3)\n",
    "        middle_output3 = self.classifier_middle3(middle3)\n",
    "        middle_output3 = torch.nn.Sigmoid()(middle_output3)\n",
    "        \n",
    "        middle4 = self.middle_layer4(enc)\n",
    "        middle4 = self.relu(middle4)\n",
    "        middle_output4 = self.classifier_middle4(middle4)\n",
    "        middle_output4 = torch.nn.Sigmoid()(middle_output4)\n",
    "        \n",
    "        middle5 = self.middle_layer5(enc)\n",
    "        middle5 = self.relu(middle5)\n",
    "        middle_output5 = self.classifier_middle5(middle5)\n",
    "        middle_output5 = torch.nn.Sigmoid()(middle_output5)\n",
    "        \n",
    "        output1 = self.hidden_layer1(middle1)\n",
    "        output1 = self.relu(output1)\n",
    "        output1 = self.classifier1(output1)\n",
    "        output1 = torch.nn.Sigmoid()(output1)\n",
    "        \n",
    "        output2 = self.hidden_layer2(middle2)\n",
    "        output2 = self.relu(output2)\n",
    "        output2 = self.classifier2(output2)\n",
    "        output2 = torch.nn.Sigmoid()(output2)\n",
    "        \n",
    "        output3 = self.hidden_layer3(middle2)\n",
    "        output3 = self.relu(output3)\n",
    "        output3 = self.classifier3(output3)\n",
    "        output3 = torch.nn.Sigmoid()(output3)\n",
    "        \n",
    "        output4 = self.hidden_layer4(middle4)\n",
    "        output4 = self.relu(output4)\n",
    "        output4 = self.classifier4(output4)\n",
    "        output4 = torch.nn.Sigmoid()(output4)\n",
    "        \n",
    "        output5 = self.hidden_layer5(middle4)\n",
    "        output5 = self.relu(output5)\n",
    "        output5 = self.classifier5(output5)\n",
    "        output5 = torch.nn.Sigmoid()(output5)\n",
    "        \n",
    "        \n",
    "        output6 = self.hidden_layer6(middle1)\n",
    "        output6 = self.relu(output6)\n",
    "        output6 = self.classifier6(output6)\n",
    "        output6 = torch.nn.Sigmoid()(output6)\n",
    "        \n",
    "        \n",
    "        output7 = self.hidden_layer7(middle5)\n",
    "        output7 = self.relu(output7)\n",
    "        output7 = self.classifier7(output7)\n",
    "        output7 = torch.nn.Sigmoid()(output7)\n",
    "        \n",
    "        \n",
    "        output8 = self.hidden_layer8(middle2)\n",
    "        output8 = self.relu(output8)\n",
    "        output8 = self.classifier8(output8)\n",
    "        output8 = torch.nn.Sigmoid()(output8)\n",
    "        \n",
    "        output9 = self.hidden_layer9(middle1)\n",
    "        output9 = self.relu(output9)\n",
    "        output9 = self.classifier9(output9)\n",
    "        output9 = torch.nn.Sigmoid()(output9)\n",
    "        \n",
    "        output10 = self.hidden_layer10(middle1)\n",
    "        output10 = self.relu(output10)\n",
    "        output10 = self.classifier10(output10)\n",
    "        output10 = torch.nn.Sigmoid()(output10)\n",
    "        \n",
    "        output11 = self.hidden_layer11(middle4)\n",
    "        output11 = self.relu(output11)\n",
    "        output11 = self.classifier11(output11)\n",
    "        output11 = torch.nn.Sigmoid()(output11)\n",
    "        \n",
    "        output12 = self.hidden_layer12(middle4)\n",
    "        output12 = self.relu(output12)\n",
    "        output12 = self.classifier12(output12)\n",
    "        output12 = torch.nn.Sigmoid()(output12)\n",
    "        \n",
    "        output13 = self.hidden_layer13(middle3)\n",
    "        output13 = self.relu(output13)\n",
    "        output13 = self.classifier13(output13)\n",
    "        output13 = torch.nn.Sigmoid()(output13)\n",
    "        \n",
    "        output14 = self.hidden_layer14(middle3)\n",
    "        output14 = self.relu(output14)\n",
    "        output14 = self.classifier14(output14)\n",
    "        output14 = torch.nn.Sigmoid()(output14)\n",
    "        \n",
    "        output15 = self.hidden_layer15(middle3)\n",
    "        output15 = self.relu(output15)\n",
    "        output15 = self.classifier15(output15)\n",
    "        output15 = torch.nn.Sigmoid()(output15)\n",
    "        \n",
    "        output16 = self.hidden_layer16(middle3)\n",
    "        output16 = self.relu(output16)\n",
    "        output16 = self.classifier16(output16)\n",
    "        output16 = torch.nn.Sigmoid()(output16)\n",
    "        \n",
    "        output17 = self.hidden_layer17(middle2)\n",
    "        output17 = self.relu(output17)\n",
    "        output17 = self.classifier17(output17)\n",
    "        output17 = torch.nn.Sigmoid()(output17)\n",
    "        \n",
    "        output18 = self.hidden_layer18(middle5)\n",
    "        output18 = self.relu(output18)\n",
    "        output18 = self.classifier18(output18)\n",
    "        output18 = torch.nn.Sigmoid()(output18)\n",
    "        \n",
    "        output19 = self.hidden_layer19(middle5)\n",
    "        output19 = self.relu(output19)\n",
    "        output19 = self.classifier19(output19)\n",
    "        output19 = torch.nn.Sigmoid()(output19)\n",
    "        \n",
    "        output20 = self.hidden_layer20(middle5)\n",
    "        output20 = self.relu(output20)\n",
    "        output20 = self.classifier20(output20)\n",
    "        output20 = torch.nn.Sigmoid()(output20)\n",
    "        outputs = torch.cat((output1, output2, output3, output4, output5, output6, output7, output8, output9, output10, output11, output12, output13, output14, output15, output16, output17, output18, output19, output20),2)\n",
    "        group_outputs = torch.cat((middle_output1, middle_output2, middle_output3, middle_output4, middle_output5),2)\n",
    "        return outputs, group_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T06:07:42.180209Z",
     "iopub.status.busy": "2022-12-13T06:07:42.179832Z",
     "iopub.status.idle": "2022-12-13T06:07:42.185016Z",
     "shell.execute_reply": "2022-12-13T06:07:42.184310Z",
     "shell.execute_reply.started": "2022-12-13T06:07:42.180184Z"
    },
    "id": "w56Kynj22y80",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model: torch.nn.Module, sents: torch.Tensor) -> List:\n",
    "    sents = sents.to(device)\n",
    "    logits = model(sents)[0]\n",
    "    res = []\n",
    "    logitslen = len(logits)\n",
    "    #print(logits[0].shape)\n",
    "    for i in range(logitslen):\n",
    "        datares = []\n",
    "        for j in range(20):\n",
    "            datares.append(logits[i][0][j] > 0.5)\n",
    "        res.append(datares)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T02:46:58.921612Z",
     "iopub.status.busy": "2022-12-13T02:46:58.921213Z",
     "iopub.status.idle": "2022-12-13T02:46:58.930015Z",
     "shell.execute_reply": "2022-12-13T02:46:58.929209Z",
     "shell.execute_reply.started": "2022-12-13T02:46:58.921586Z"
    },
    "id": "cnSswFRd3WzN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from numpy import logical_and, sum as t_sum\n",
    "def precision(predicted_labels, true_labels, which_label=1):\n",
    "    \"\"\"\n",
    "    Precision is True Positives / All Positives Predictions\n",
    "    \"\"\"\n",
    "    pred_which = np.array([pred == which_label for pred in predicted_labels])\n",
    "    true_which = np.array([lab == which_label for lab in true_labels])\n",
    "    denominator = t_sum(pred_which)\n",
    "    if denominator:\n",
    "        return t_sum(logical_and(pred_which, true_which))/denominator\n",
    "    else:\n",
    "        return 0.\n",
    "\n",
    "\n",
    "def recall(predicted_labels, true_labels, which_label=1):\n",
    "    \"\"\"\n",
    "    Recall is True Positives / All Positive Labels\n",
    "    \"\"\"\n",
    "    pred_which = np.array([pred == which_label for pred in predicted_labels])\n",
    "    true_which = np.array([lab == which_label for lab in true_labels])\n",
    "    denominator = t_sum(true_which)\n",
    "    if denominator:\n",
    "        return t_sum(logical_and(pred_which, true_which))/denominator\n",
    "    else:\n",
    "        return 0.\n",
    "\n",
    "\n",
    "def f1_score(\n",
    "    predicted_labels: List[int],\n",
    "    true_labels: List[int],\n",
    "    which_label: int\n",
    "):\n",
    "    \"\"\"\n",
    "    F1 score is the harmonic mean of precision and recall\n",
    "    \"\"\"\n",
    "    P = precision(predicted_labels, true_labels, which_label=which_label)\n",
    "    R = recall(predicted_labels, true_labels, which_label=which_label)\n",
    "    if P and R:\n",
    "        return 2*P*R/(P+R)\n",
    "    else:\n",
    "        return 0.\n",
    "\n",
    "\n",
    "def macro_f1(\n",
    "    predicted_labels: List[int],\n",
    "    true_labels: List[int],\n",
    "    possible_labels: List[int]\n",
    "):\n",
    "    scores = [f1_score(predicted_labels, true_labels, l) for l in possible_labels]\n",
    "    # Macro, so we take the uniform avg.\n",
    "    print(scores)\n",
    "    return sum(scores) / len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T02:46:59.980689Z",
     "iopub.status.busy": "2022-12-13T02:46:59.980303Z",
     "iopub.status.idle": "2022-12-13T02:46:59.989158Z",
     "shell.execute_reply": "2022-12-13T02:46:59.988494Z",
     "shell.execute_reply.started": "2022-12-13T02:46:59.980666Z"
    },
    "id": "lVZr4mEb81_f"
   },
   "outputs": [],
   "source": [
    "def f1Score_multiLabel(preds, labels):\n",
    "    nLabels = 20\n",
    "    relevants = [0]*20\n",
    "    positives = [0]*20\n",
    "    truePositives = [0]*20\n",
    "    correct = [0]*20\n",
    "    for i in range(len(preds)):\n",
    "        for j in range(nLabels):\n",
    "            if(preds[i][j]==1):\n",
    "                positives[j] += 1\n",
    "                if(labels[i][j]==1):\n",
    "                    truePositives[j] += 1\n",
    "    for i in range(len(preds)):\n",
    "        for j in range(nLabels):\n",
    "            if(preds[i][j]==labels[i][j]):\n",
    "                correct[j] += 1\n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "        for j in range(nLabels):\n",
    "            if(labels[i][j]==1):\n",
    "                relevants[j] += 1\n",
    "    \n",
    "    precisions = []*nLabels\n",
    "    recalls = []*nLabels\n",
    "    f1Scores = []*nLabels\n",
    "    accuracies = []*nLabels\n",
    "    \n",
    "    precision =0\n",
    "    recall = 0\n",
    "    f1 = 0\n",
    "    #print(truePositives, positives, relevants)\n",
    "    for i in range(nLabels):\n",
    "        if(positives[i]>0):\n",
    "            precision = truePositives[i]/positives[i]\n",
    "        precisions.append(precision)\n",
    "        if(relevants[i]>0):\n",
    "            recall = truePositives[i]/relevants[i]\n",
    "        recalls.append(recall)\n",
    "        #print(precision,recall,i)\n",
    "        if(precision>0 and recall>0):\n",
    "            f1 = 2 * precision * recall / (precision + recall)\n",
    "        f1Scores.append(f1)\n",
    "        accuracies.append(correct[i]/len(preds))\n",
    "    precision_mean = np.mean(precisions)\n",
    "    recall_mean = np.mean(recalls)\n",
    "    f1_mean = np.mean(f1Scores)\n",
    "    accuracy = np.mean(accuracies)\n",
    "    return f1_mean, precision_mean, recall_mean, accuracy, f1Scores, precisions, recalls, accuracies\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "IyE6cJhM3i9M"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torchmetrics.classification import MultilabelHammingDistance\n",
    "def training_loop(\n",
    "    num_epochs,\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    dev_sents,\n",
    "    dev_labels,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    model,\n",
    "):\n",
    "    print(\"Training...\")\n",
    "    all_f1 = []\n",
    "    all_P = []\n",
    "    all_R = []\n",
    "    all_L = []\n",
    "    all_CELoss = []\n",
    "    all_HMLoss = []\n",
    "    all_acc = []\n",
    "    loss_func = torch.nn.CrossEntropyLoss()\n",
    "    hammingLoss20 = MultilabelHammingDistance(num_labels=20)\n",
    "    batches = list(zip(train_features, train_labels))\n",
    "    random.shuffle(batches)\n",
    "    for i in range(num_epochs):\n",
    "        losses = []\n",
    "        #CELosses = []\n",
    "        #HMLosses = []\n",
    "        for features, labels in tqdm(batches):\n",
    "            # Empty the dynamic computation graph\n",
    "            features = features.to(device)\n",
    "            labels = labels.float()\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(features)\n",
    "            local_loss = loss_func(preds[0].squeeze(1),labels[:,:20])\n",
    "            group_loss = loss_func(preds[1].squeeze(1),labels[:,20:25])\n",
    "            loss = local_loss + 4*group_loss\n",
    "            #print(\"Preds \",preds.shape)\n",
    "            #print(\"Labels \", labels.shape)\n",
    "            #loss = loss_func(preds, labels)\n",
    "            #loss2 = 20*hammingLoss(preds, labels)\n",
    "            \n",
    "            #loss = loss1 + loss2\n",
    "            # Backpropogate the loss through our model\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #CELosses.append(loss1.item())\n",
    "            #HMLosses.append(loss2.item())\n",
    "            losses.append(loss.item())\n",
    "        \n",
    "        #print(f\"epoch {i}, loss: {np.sum(losses)/len(losses)}, HM loss: {np.sum(HMLosses)/len(HMLosses)}, CE loss: {np.sum(CELosses)/len(CELosses)}\")\n",
    "        print(f\"epoch {i}, loss: {np.sum(losses)/len(losses)}\")\n",
    "        # Estimate the f1 score for the development set\n",
    "        print(\"Evaluating dev...\")\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        for sents, labels in tqdm(zip(dev_sents, dev_labels), total=len(dev_sents)):\n",
    "            sents = sents.to(device)\n",
    "            pred = predict(model, sents)\n",
    "            all_preds.extend(pred)\n",
    "            all_labels.extend(list(labels))\n",
    "        # #print(range(len(set(train_labels))))\n",
    "\n",
    "        dev_f1, dev_P, dev_R, dev_acc, dev_all_f1, dev_all_P, dev_all_R, dev_all_acc = f1Score_multiLabel(all_preds, all_labels)\n",
    "        print(f\"Dev F1 {dev_f1},  Dev Precision {dev_P}, Dev Recall {dev_R}, Dev Accuracy {dev_acc}\")\n",
    "        all_f1.append(dev_all_f1)\n",
    "        all_P.append(dev_all_P)\n",
    "        all_R.append(dev_all_R)\n",
    "        all_L.append(losses)\n",
    "        #all_CELoss.append(CELosses)\n",
    "        #all_HMLoss.append(HMLosses)\n",
    "        all_acc.append(dev_all_acc)\n",
    "        scheduler.step()\n",
    "        #print(optimizer)\n",
    "    # Return the trained model\n",
    "    with open(\"all_f1_base.csv\", 'ab') as abc:\n",
    "        np.savetxt(abc, \n",
    "               all_f1,\n",
    "               delimiter =\", \", \n",
    "               fmt ='%s')\n",
    "    with open(\"all_P_base.csv\", 'ab') as abc:\n",
    "        np.savetxt(abc, \n",
    "               all_P,\n",
    "               delimiter =\", \", \n",
    "               fmt ='%s')\n",
    "    with open(\"all_R_base.csv\", 'ab') as abc:\n",
    "        np.savetxt(abc, \n",
    "               all_R,\n",
    "               delimiter =\", \", \n",
    "               fmt ='%s')\n",
    "    with open(\"all_acc_base.csv\", 'ab') as abc:\n",
    "        np.savetxt(abc, \n",
    "               all_acc,\n",
    "               delimiter =\", \", \n",
    "               fmt ='%s')\n",
    "    with open(\"all_L_base.csv\", 'ab') as abc:\n",
    "        np.savetxt(abc, \n",
    "               all_L,\n",
    "               delimiter =\", \", \n",
    "               fmt ='%s')\n",
    "    \"\"\"\n",
    "    with open(\"all_CELoss_base.csv\", 'ab') as abc:\n",
    "        np.savetxt(abc, \n",
    "               all_CELoss,\n",
    "               delimiter =\", \", \n",
    "               fmt ='%s')\n",
    "    with open(\"all_HMLoss_base.csv\", 'ab') as abc:\n",
    "        np.savetxt(abc, \n",
    "               all_CELoss,\n",
    "               delimiter =\", \", \n",
    "               fmt ='%s')\n",
    "    \"\"\"\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "liqb8oDn4fNx",
    "outputId": "a32247ac-b0a6-4da9-cd1f-6f0da244c27c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "from transformers.optimization import get_linear_schedule_with_warmup\n",
    "epochs = 200\n",
    "epoch_warmup = 40\n",
    "# TODO: Find a good learning rate\n",
    "LR = 1e-4\n",
    "\n",
    "possible_labels = 20\n",
    "model = GroupedClassifier(output_size=possible_labels, hidden_size=512)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), LR)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, epoch_warmup,epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118,
     "referenced_widgets": [
      "61ea633e05a349c5be3d43f312479d41",
      "de2dd812a7b64e13bec4016b014f20b3",
      "b1f754a0a407465aa36641f48fa6a3db",
      "5f15f99f1fba444a86d53f1debc6023d",
      "fd96316483e641d68cdfb37dcd76376c",
      "49041743e83646ffba06cc4cd30d42c6",
      "a0956344476d48099cdcc28d8c40d9b9",
      "fe03fd2cd82145c8b4232fa3b8a3089a",
      "716e6dd6f01242e8a43fcfc4af14928e",
      "9657ec4ec82742da8d159dcd8f57dd99",
      "8792e60cc5054c7194bcc8ac017d455a"
     ]
    },
    "id": "Y0ThGzo64w64",
    "outputId": "aba407bd-223e-4c3b-f89d-80ae4eedfdeb"
   },
   "outputs": [],
   "source": [
    "\n",
    "model =training_loop(\n",
    "    epochs,\n",
    "    train_input_batches,\n",
    "    train_label_batches,\n",
    "    val_input_batches,\n",
    "    val_label_batches,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ygX87QGbgTc9"
   },
   "outputs": [],
   "source": [
    "torch.save(model, 'GroupClassifiers_CE.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520,
     "referenced_widgets": [
      "ee66bd0ea5e44abe8547960d2b953dfd",
      "6794b7344ca74ea79e27d62cc2b731e7",
      "46e9ef759c5a4076af228ca215de5f8a",
      "cab1a59fad4042279965587e565d316a",
      "be051014d67743fbb9d84f7079ef0cd2",
      "7e9aaae0e19745f2ac45d9d45bdf21c0",
      "ab3d4f183f6443e88b4a4b78e5bbe1e2",
      "ad16b7f28a1a45e689ec8389b1713bd4",
      "d775d856f78f429fb3235667a49d23e2",
      "3d49b2fe098646e6b8dd092a1e254e4f",
      "9ba695ce3a904eb2a3e602c5cf5e538a"
     ]
    },
    "id": "_4203j4811Mw",
    "outputId": "2e954a67-aa63-41c2-8880-0f849bb20b35"
   },
   "outputs": [],
   "source": [
    "print(\"Evaluating Test...\")\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "test_input_batches = [b for b in chunk_multi(test_premises, test_conclusion, test_stance, batch_size)]\n",
    "# Tokenize + encode\n",
    "test_input_batches = [tokenizer(*batch) for batch in test_input_batches]\n",
    "\n",
    "\n",
    "test_label_batches = [b for b in chunk(test_labels, batch_size)]\n",
    "test_label_batches = [encode_labels(batch) for batch in test_label_batches]\n",
    "for sents, labels in tqdm(zip(test_input_batches, test_label_batches), total=len(test_input_batches)):\n",
    "    pred = predict(model, sents)\n",
    "    all_preds.extend(pred)\n",
    "    all_labels.extend(list(labels.numpy()))\n",
    "# #print(range(len(set(train_labels))))\n",
    "\n",
    "test_f1, test_P, test_R, test_acc, test_all_f1, test_all_P, test_all_R, test_all_acc = f1Score_multiLabel(all_preds, all_labels)\n",
    "print(f\"test F1 {test_f1},  test Precision {test_P}, test Recall {test_R}, test Accuracy {test_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JNtkjU5-49vL",
    "outputId": "48a3cf8c-a04f-4a12-8343-2362f1c02844"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GeRlExU2w8Lp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sxPeUYO6xlip",
    "outputId": "796fcdcf-7394-4e6c-9b2c-8c0950de84b2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0B57iw_741yk",
    "outputId": "726f5863-c97b-44c5-9989-332b11604f5b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uXnrg3Ph5QRW",
    "outputId": "ef76dc5e-6fa3-4ea0-afcc-b2c3751faf9b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dRrI3eptcFJd",
    "outputId": "a949b623-97ad-43b1-892f-e8be417181c6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nWA-g2dDch-j",
    "outputId": "f6767fcf-20c9-4d59-96f3-bdd7e0ba8d61"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mMUDSzOFctdG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-12-13T04:08:38.778826Z",
     "iopub.status.busy": "2022-12-13T04:08:38.778425Z",
     "iopub.status.idle": "2022-12-13T04:08:38.791062Z",
     "shell.execute_reply": "2022-12-13T04:08:38.790226Z",
     "shell.execute_reply.started": "2022-12-13T04:08:38.778800Z"
    },
    "id": "BwDuG-5pWVVs",
    "outputId": "142e8a75-a001-4973-978f-0e8444b5bd35",
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T04:11:51.135875Z",
     "iopub.status.busy": "2022-12-13T04:11:51.135477Z",
     "iopub.status.idle": "2022-12-13T04:11:51.148320Z",
     "shell.execute_reply": "2022-12-13T04:11:51.147460Z",
     "shell.execute_reply.started": "2022-12-13T04:11:51.135847Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T04:11:14.844361Z",
     "iopub.status.busy": "2022-12-13T04:11:14.843975Z",
     "iopub.status.idle": "2022-12-13T04:11:16.363077Z",
     "shell.execute_reply": "2022-12-13T04:11:16.362208Z",
     "shell.execute_reply.started": "2022-12-13T04:11:14.844334Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-12-13T04:11:56.692303Z",
     "iopub.status.busy": "2022-12-13T04:11:56.691904Z",
     "iopub.status.idle": "2022-12-13T04:11:56.939422Z",
     "shell.execute_reply": "2022-12-13T04:11:56.938381Z",
     "shell.execute_reply.started": "2022-12-13T04:11:56.692276Z"
    },
    "id": "-4XKS621WmjX",
    "outputId": "6326ce58-1ee0-4e31-f68f-2c3793ab7e34",
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DIzpG6eFW6pb",
    "outputId": "399968fe-b790-4094-c9ac-efe21a044665"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WDPOLhR_XAdC",
    "outputId": "d78a4783-975c-4be4-d51f-c4de5bde54c2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qcxiw5ssUEP3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bZ8qHyzOUESt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T06:07:58.719814Z",
     "iopub.status.busy": "2022-12-13T06:07:58.719421Z",
     "iopub.status.idle": "2022-12-13T06:07:58.734675Z",
     "shell.execute_reply": "2022-12-13T06:07:58.733927Z",
     "shell.execute_reply.started": "2022-12-13T06:07:58.719789Z"
    },
    "id": "r9PUZx4LUEWH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Trainining with CrossEnropy loss + Hamming loss\n",
    "import random\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torchmetrics.classification import MultilabelHammingDistance\n",
    "def training_loop(\n",
    "    num_epochs,\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    dev_sents,\n",
    "    dev_labels,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    model,\n",
    "):\n",
    "    print(\"Training...\")\n",
    "    all_f1 = []\n",
    "    all_P = []\n",
    "    all_R = []\n",
    "    all_L = []\n",
    "    all_CELoss = []\n",
    "    all_HMLoss = []\n",
    "    all_acc = []\n",
    "    loss_func = torch.nn.CrossEntropyLoss()\n",
    "    hammingLoss20 = MultilabelHammingDistance(num_labels=20).to(device)\n",
    "    hammingLoss5 = MultilabelHammingDistance(num_labels=5).to(device)\n",
    "    batches = list(zip(train_features, train_labels))\n",
    "    random.shuffle(batches)\n",
    "    for i in range(num_epochs):\n",
    "        losses = []\n",
    "        CELosses = []\n",
    "        HMLosses = []\n",
    "        for features, labels in tqdm(batches):\n",
    "            # Empty the dynamic computation graph\n",
    "            features = features.to(device)\n",
    "            labels = labels.float()\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds0, preds1 = model(features)\n",
    "            local_loss1 = loss_func(preds0.squeeze(1),labels[:,:20])\n",
    "            group_loss1 = loss_func(preds1.squeeze(1),labels[:,20:25])\n",
    "            loss1 = local_loss1 + 4*group_loss1\n",
    "\n",
    "            # preds0 = preds[0].to(device)\n",
    "            # preds1 = preds[1].to(device)\n",
    "            local_loss2 = hammingLoss20(preds0.squeeze(1),labels[:,:20])\n",
    "            # print(preds1.shape)\n",
    "            group_loss2 = hammingLoss5(preds1.squeeze(1),labels[:,20:25])\n",
    "            loss2 = local_loss2 + 4*group_loss2\n",
    "\n",
    "            loss = loss1 + 20*loss2\n",
    "            #print(\"Preds \",preds.shape)\n",
    "            #print(\"Labels \", labels.shape)\n",
    "            #loss = loss_func(preds, labels)\n",
    "            #loss2 = 20*hammingLoss(preds, labels)\n",
    "            \n",
    "            #loss = loss1 + loss2\n",
    "            # Backpropogate the loss through our model\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            CELosses.append(loss1.item())\n",
    "            HMLosses.append(loss2.item())\n",
    "            losses.append(loss.item())\n",
    "        \n",
    "        print(f\"epoch {i}, loss: {np.sum(losses)/len(losses)}, HM loss: {np.sum(HMLosses)/len(HMLosses)}, CE loss: {np.sum(CELosses)/len(CELosses)}\")\n",
    "        #print(f\"epoch {i}, HM loss: {np.sum(losses)/len(losses)}\")\n",
    "        # Estimate the f1 score for the development set\n",
    "        print(\"Evaluating dev...\")\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        for sents, labels in tqdm(zip(dev_sents, dev_labels), total=len(dev_sents)):\n",
    "            sents = sents.to(device)\n",
    "            pred = predict(model, sents)\n",
    "            all_preds.extend(pred)\n",
    "            all_labels.extend(list(labels))\n",
    "        # #print(range(len(set(train_labels))))\n",
    "\n",
    "        dev_f1, dev_P, dev_R, dev_acc, dev_all_f1, dev_all_P, dev_all_R, dev_all_acc = f1Score_multiLabel(all_preds, all_labels)\n",
    "        print(f\"Dev F1 {dev_f1},  Dev Precision {dev_P}, Dev Recall {dev_R}, Dev Accuracy {dev_acc}\")\n",
    "        all_f1.append(dev_all_f1)\n",
    "        all_P.append(dev_all_P)\n",
    "        all_R.append(dev_all_R)\n",
    "        all_L.append(losses)\n",
    "        all_CELoss.append(CELosses)\n",
    "        all_HMLoss.append(HMLosses)\n",
    "        all_acc.append(dev_all_acc)\n",
    "        scheduler.step()\n",
    "        #print(optimizer)\n",
    "    # Return the trained model\n",
    "    with open(\"all_f1_base.csv\", 'ab') as abc:\n",
    "        np.savetxt(abc, \n",
    "               all_f1,\n",
    "               delimiter =\", \", \n",
    "               fmt ='%s')\n",
    "    with open(\"all_P_base.csv\", 'ab') as abc:\n",
    "        np.savetxt(abc, \n",
    "               all_P,\n",
    "               delimiter =\", \", \n",
    "               fmt ='%s')\n",
    "    with open(\"all_R_base.csv\", 'ab') as abc:\n",
    "        np.savetxt(abc, \n",
    "               all_R,\n",
    "               delimiter =\", \", \n",
    "               fmt ='%s')\n",
    "    with open(\"all_acc_base.csv\", 'ab') as abc:\n",
    "        np.savetxt(abc, \n",
    "               all_acc,\n",
    "               delimiter =\", \", \n",
    "               fmt ='%s')\n",
    "    with open(\"all_L_base.csv\", 'ab') as abc:\n",
    "        np.savetxt(abc, \n",
    "               all_L,\n",
    "               delimiter =\", \", \n",
    "               fmt ='%s')\n",
    "    \n",
    "    with open(\"all_CELoss_base.csv\", 'ab') as abc:\n",
    "        np.savetxt(abc, \n",
    "               all_CELoss,\n",
    "               delimiter =\", \", \n",
    "               fmt ='%s')\n",
    "    with open(\"all_HMLoss_base.csv\", 'ab') as abc:\n",
    "        np.savetxt(abc, \n",
    "               all_CELoss,\n",
    "               delimiter =\", \", \n",
    "               fmt ='%s')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T06:07:59.855072Z",
     "iopub.status.busy": "2022-12-13T06:07:59.854663Z",
     "iopub.status.idle": "2022-12-13T06:08:01.228906Z",
     "shell.execute_reply": "2022-12-13T06:08:01.227865Z",
     "shell.execute_reply.started": "2022-12-13T06:07:59.855046Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "from transformers.optimization import get_linear_schedule_with_warmup\n",
    "epochs = 200\n",
    "epoch_warmup = 40\n",
    "# TODO: Find a good learning rate\n",
    "LR = 1e-5\n",
    "\n",
    "possible_labels = 20\n",
    "model = GroupedClassifier(output_size=possible_labels, hidden_size=512)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), LR)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, epoch_warmup,epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T06:08:01.399904Z",
     "iopub.status.busy": "2022-12-13T06:08:01.399225Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_457/3952115150.py:31: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for features, labels in tqdm(batches):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5b94cf1acf1462787d8fb0b1a9edb8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss: 67.1073558294951, HM loss: 2.021245333685804, CE loss: 26.682449383522147\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_457/3952115150.py:69: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for sents, labels in tqdm(zip(dev_sents, dev_labels), total=len(dev_sents)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba259ff855e44dc1ae9c5d8825467870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.0,  Dev Precision 0.0, Dev Recall 0.0, Dev Accuracy 0.8272563176895307\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c9e1b9e1a54c1f9004b1dd7e55d88c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss: 62.956442932584395, HM loss: 1.8260027899670956, CE loss: 26.436387119008533\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83aed28d6cc84b20a0287734266bb594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.0,  Dev Precision 0.0, Dev Recall 0.0, Dev Accuracy 0.8272563176895307\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04fac2e52ffa45adadd67bd2f3b80f35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, loss: 61.39683640892826, HM loss: 1.754617522011942, CE loss: 26.30448574806327\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e13299bdaa437e9c82df067f009efb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.0,  Dev Precision 0.0, Dev Recall 0.0, Dev Accuracy 0.8272563176895307\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aad7c8cb405942ffa5cc66cef9eb76ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, loss: 60.18780887660696, HM loss: 1.7008278921468933, CE loss: 26.171251311231014\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe5f6724928849d68fc0c58b78e4da0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.0,  Dev Precision 0.0, Dev Recall 0.0, Dev Accuracy 0.8272563176895307\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bbfe13fea9e408e9caa22c71a6fc002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, loss: 59.13507296434089, HM loss: 1.6549440141934066, CE loss: 26.036192395793858\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29dc3edc7adc407c824b409dd1d9c648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.0,  Dev Precision 0.0, Dev Recall 0.0, Dev Accuracy 0.8272563176895307\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "808b838117874c72b590fba9a4527c4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, loss: 58.15761435209815, HM loss: 1.6127215517101003, CE loss: 25.903183581224127\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65c3f9ef99fc4f449e05ca2d174526d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.0,  Dev Precision 0.0, Dev Recall 0.0, Dev Accuracy 0.8272563176895307\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4769fd845ad4187bec06f69c7b32b95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, loss: 57.61987025702177, HM loss: 1.5920592439708425, CE loss: 25.778685327786118\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d3ce687dd9b4d01a50bc456ab950854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.21777943090942906,  Dev Precision 0.19069264069264072, Dev Recall 0.05592674805771365, Dev Accuracy 0.8135379061371841\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e1ac68b16eb47fd8b07d4c2c91c4334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, loss: 57.62811136957425, HM loss: 1.598087679094343, CE loss: 25.66635756706124\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63bf21ad92654c5fa3b0a9732d0258b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.178961021371632,  Dev Precision 0.2259739159891599, Dev Recall 0.11346150606469003, Dev Accuracy 0.7971119133574007\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623c799585a747439346aa4845b7cd78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, loss: 57.5292680085595, HM loss: 1.5979127670401958, CE loss: 25.57101272469136\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bed73baffb04fb3b49c1dff000458af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.3747498380388324,  Dev Precision 0.3184906320472392, Dev Recall 0.1762560366127583, Dev Accuracy 0.7837545126353791\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e341cef1f9941de838857b81a148d6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, loss: 57.37166692249811, HM loss: 1.5939598759608482, CE loss: 25.492469246707746\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f6ef30a6ce9474c8755ef7da8322d75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.36202048490190036,  Dev Precision 0.258654231761533, Dev Recall 0.20209526617250675, Dev Accuracy 0.7608303249097472\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8065c257ff084a7d8cf59bd825cfb105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, loss: 57.162667288709045, HM loss: 1.5867886988084707, CE loss: 25.42689326272082\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67bd0c90594e48cf95117feec4c9da5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.37729661455735564,  Dev Precision 0.2548894475195729, Dev Recall 0.22122767857142858, Dev Accuracy 0.7505415162454874\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe594f5e1e63490581991a0624605b4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, loss: 57.00743535739272, HM loss: 1.5818680026637975, CE loss: 25.370075211596134\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fdf4d8e0c4240e6a7c70951f93ccf67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.3827892957165121,  Dev Precision 0.25441367944510435, Dev Recall 0.22951636904761905, Dev Accuracy 0.7465703971119134\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "272122561fd94713ba3f816bdfd74515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, loss: 57.04962420107714, HM loss: 1.586508855890872, CE loss: 25.319447474693185\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "182af8273c484579aa1ac9ff8a238308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.37889101219038057,  Dev Precision 0.2502060577608296, Dev Recall 0.23029761904761906, Dev Accuracy 0.744043321299639\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d691967663408b99733fa4b0973877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, loss: 57.056197892374065, HM loss: 1.5891907588759464, CE loss: 25.272382707738164\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19d4ac20443045488598d0de71fc88b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.38174417615126643,  Dev Precision 0.30109075573518834, Dev Recall 0.2323455559408229, Dev Accuracy 0.744043321299639\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e79922c0409840acbdd501f15604ba33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, loss: 57.055559072921525, HM loss: 1.5913596010919828, CE loss: 25.228367164953433\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ce39c2812c45a7ae07d0455d0f6edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.3918326681497938,  Dev Precision 0.2977995069752829, Dev Recall 0.2380873641932501, Dev Accuracy 0.7454873646209387\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e64faa245ee4c3f8de357855d5c615e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, loss: 56.95435133976723, HM loss: 1.5883512069929893, CE loss: 25.18732738494873\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2483fbfe1ee44b06bf2cad23fced8112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.4058480986841483,  Dev Precision 0.2999818564251299, Dev Recall 0.24663560448451224, Dev Accuracy 0.7487364620938628\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f996d33cfaab490b9fa0a293f6c871bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, loss: 56.92149848368631, HM loss: 1.5886077453841025, CE loss: 25.149343647173982\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e80d02d98d74954b13d591ace7c4538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.4105158119232901,  Dev Precision 0.29417377561704916, Dev Recall 0.2514899734165511, Dev Accuracy 0.7492779783393502\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6fa53b86d7a4a47ba58539a2c5de057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, loss: 56.93377947451464, HM loss: 1.5910214399223896, CE loss: 25.113351224073725\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "298cf66bbc1742fc93b37886e90baa81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.41509604626537727,  Dev Precision 0.2941199520747631, Dev Recall 0.25585890545538603, Dev Accuracy 0.7505415162454874\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "145b35ce507447f89920fe60687345dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, loss: 56.866413230326636, HM loss: 1.5893656549169057, CE loss: 25.079099925596324\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fa8aafb3d4b4cba8e15e20fd41b7119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.41374827156042704,  Dev Precision 0.2915508696657763, Dev Recall 0.2565247197179843, Dev Accuracy 0.7501805054151625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff401cd977924faf90ec5c02fa3b287e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, loss: 56.76543711192572, HM loss: 1.5859375035584862, CE loss: 25.046687254265173\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bd974f944614fa8b083a7eedb39cf3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.3363257904768665,  Dev Precision 0.3873676022483943, Dev Recall 0.2598039470642626, Dev Accuracy 0.7503610108303249\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2865ba9c558415b984324f01363831b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, loss: 56.72074223988092, HM loss: 1.5852611954532452, CE loss: 25.015518643962803\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9397885f3b8d4b09977f837d7f5caf73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.34809824351974655,  Dev Precision 0.3377625933135846, Dev Recall 0.2627873613037448, Dev Accuracy 0.7507220216606498\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7d5470567554e2080d77feb019b58fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, loss: 56.62800421643613, HM loss: 1.5821245250417226, CE loss: 24.98551371560168\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "112afcaef4484405b19cdcaeb32cf4da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.34420804314094616,  Dev Precision 0.278187631690198, Dev Recall 0.2632727981969487, Dev Accuracy 0.7485559566787003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fe8683dc41244cfa8b5a8828f7293da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22, loss: 56.48980001193374, HM loss: 1.576655779311906, CE loss: 24.956684169484607\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b4c5b8216ce49a4b3c5fc239d2e9a4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.3527945735320136,  Dev Precision 0.27905305605894376, Dev Recall 0.2662562124364309, Dev Accuracy 0.7485559566787003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55719d8b0da47bba25a28c5573c2fee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23, loss: 56.41149953585952, HM loss: 1.574137121883791, CE loss: 24.928757268991042\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1193d1528ca84ba69224125f41f594f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.3632366967336183,  Dev Precision 0.28686235466040444, Dev Recall 0.2697158171521036, Dev Accuracy 0.7507220216606498\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0be38c7a9244fd8962b9bfeca43c5fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, loss: 56.31102040988296, HM loss: 1.5704407514031253, CE loss: 24.902205424522286\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "773f3113aa654885b06bd41095ffd1f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.38669153566500014,  Dev Precision 0.31444237019560944, Dev Recall 0.27333550046232086, Dev Accuracy 0.7516245487364621\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6209e77a8f24e6d99af807eabeebb58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, loss: 56.22275799423901, HM loss: 1.5672924394038186, CE loss: 24.876909142109884\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09d71be5521b4e23883139bf0fbbd686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.391168761467517,  Dev Precision 0.31216869381538387, Dev Recall 0.2748718504392048, Dev Accuracy 0.7514440433212997\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8327a706edb34211b7e2cb669be46d4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26, loss: 56.13927459716797, HM loss: 1.564330691721902, CE loss: 24.852660663092315\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f8c78e220644561876a448c750b5335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.40437299144093364,  Dev Precision 0.32347608891236235, Dev Recall 0.27695518377253814, Dev Accuracy 0.7527075812274369\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "842c8d85fc284829ad2feaf1fc85d847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, loss: 56.07579063301656, HM loss: 1.5623367580015268, CE loss: 24.829055430284185\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "589f1fadf0674bb0984c6d78b53bef06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.40349435310546633,  Dev Precision 0.3184367813379225, Dev Recall 0.27744986708275543, Dev Accuracy 0.7539711191335741\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6fc36c83928401abfa7076e54988415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28, loss: 55.95957462823213, HM loss: 1.5576725717800766, CE loss: 24.80612337767188\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6160ce8daa640c9a4bc6b1f3ab66df9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.4022029527524748,  Dev Precision 0.31598620021855733, Dev Recall 0.2764974861303745, Dev Accuracy 0.7541516245487365\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b715d254a034dc4adc319a33828dbaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29, loss: 55.81236045040301, HM loss: 1.5514342393448104, CE loss: 24.783675478465522\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c6786b27cf946f0ba2d7f05a1e111a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.40458991005462713,  Dev Precision 0.3219801963092329, Dev Recall 0.276021295654184, Dev Accuracy 0.7550541516245487\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37523f65bc6e4091aa6b36d5e35e5d06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model =training_loop(\n",
    "    epochs,\n",
    "    train_input_batches,\n",
    "    train_label_batches,\n",
    "    val_input_batches,\n",
    "    val_label_batches,\n",
    "    optimizer,\n",
    "    #scheduler,\n",
    "    model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T06:07:00.807699Z",
     "iopub.status.busy": "2022-12-13T06:07:00.807400Z",
     "iopub.status.idle": "2022-12-13T06:07:04.938356Z",
     "shell.execute_reply": "2022-12-13T06:07:04.937499Z",
     "shell.execute_reply.started": "2022-12-13T06:07:00.807677Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Evaluating Test...\")\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "test_input_batches = [b for b in chunk_multi(test_premises, test_conclusion, test_stance, batch_size)]\n",
    "# Tokenize + encode\n",
    "test_input_batches = [tokenizer(*batch) for batch in test_input_batches]\n",
    "\n",
    "\n",
    "test_label_batches = [b for b in chunk(test_labels, batch_size)]\n",
    "test_label_batches = [encode_labels(batch) for batch in test_label_batches]\n",
    "for sents, labels in tqdm(zip(test_input_batches, test_label_batches), total=len(test_input_batches)):\n",
    "    pred = predict(model, sents)\n",
    "    all_preds.extend(pred)\n",
    "    all_labels.extend(list(labels.numpy()))\n",
    "# #print(range(len(set(train_labels))))\n",
    "\n",
    "test_f1, test_P, test_R, test_acc, test_all_f1, test_all_P, test_all_R, test_all_acc = f1Score_multiLabel(all_preds, all_labels)\n",
    "print(f\"test F1 {test_f1},  test Precision {test_P}, test Recall {test_R}, test Accuracy {test_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T04:38:49.407595Z",
     "iopub.status.busy": "2022-12-13T04:38:49.407189Z",
     "iopub.status.idle": "2022-12-13T04:38:49.413077Z",
     "shell.execute_reply": "2022-12-13T04:38:49.412240Z",
     "shell.execute_reply.started": "2022-12-13T04:38:49.407570Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T04:04:45.324336Z",
     "iopub.status.busy": "2022-12-13T04:04:45.323935Z",
     "iopub.status.idle": "2022-12-13T04:04:45.947407Z",
     "shell.execute_reply": "2022-12-13T04:04:45.946749Z",
     "shell.execute_reply.started": "2022-12-13T04:04:45.324311Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model,\"Grouping_Hybrid_loss.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "016be63768c24b85ad49ebcc6bf8530c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0731022940e34eeea4d31220521bc634": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea568e71d4aa491ab98a583f43c26541",
      "placeholder": "​",
      "style": "IPY_MODEL_0934dbfde784417eb416b2cb39c151b3",
      "value": " 466k/466k [00:00&lt;00:00, 10.0MB/s]"
     }
    },
    "0934dbfde784417eb416b2cb39c151b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "18817eb31c11408681bfc10fd79c552e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f51568078be64c7393c71901cff90e87",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8b86dc099d57423ea042785d18647534",
      "value": 570
     }
    },
    "20a46cf22cb14596a0e17d536427be54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "21c0b45558584fb59ec527adca6f8518": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "256538012e7a4b38b7b3ac69b51ff941": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a1d7aec29ded41b393f2cb5c42fde010",
       "IPY_MODEL_cadca92ef4524a4ba0d46c9518cdb4f0",
       "IPY_MODEL_68384eae9d9c4dcd9a3f2fb6d659ba3c"
      ],
      "layout": "IPY_MODEL_e0669bb1b79645b996d83b81a2a2df21"
     }
    },
    "2ef6ac57065a4646a8ac646ba0a0092f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "320c7492a5794e28809a17403446da22": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d49b2fe098646e6b8dd092a1e254e4f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d9ef44ea2c748028c3a4b35acbebd63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a6336c1fa3d44b638401f46c5833ed2d",
      "placeholder": "​",
      "style": "IPY_MODEL_501bbc487feb4c4e8ee2d0e1e69c7e64",
      "value": "Downloading: 100%"
     }
    },
    "46e9ef759c5a4076af228ca215de5f8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ad16b7f28a1a45e689ec8389b1713bd4",
      "max": 8,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d775d856f78f429fb3235667a49d23e2",
      "value": 8
     }
    },
    "49041743e83646ffba06cc4cd30d42c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a57a6d299c84c67a1eaccddd22333f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_af31b60f9817474985e11f21e6974bbe",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_eda9f732b10b4a9887cc98a993beab6e",
      "value": 466062
     }
    },
    "501bbc487feb4c4e8ee2d0e1e69c7e64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "536259048b704e86a6029f500fa440e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b9c47e409e1470c8c0b41c9eb0f64ba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f15f99f1fba444a86d53f1debc6023d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9657ec4ec82742da8d159dcd8f57dd99",
      "placeholder": "​",
      "style": "IPY_MODEL_8792e60cc5054c7194bcc8ac017d455a",
      "value": " 27/67 [11:37&lt;15:42, 23.55s/it]"
     }
    },
    "61ea633e05a349c5be3d43f312479d41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_de2dd812a7b64e13bec4016b014f20b3",
       "IPY_MODEL_b1f754a0a407465aa36641f48fa6a3db",
       "IPY_MODEL_5f15f99f1fba444a86d53f1debc6023d"
      ],
      "layout": "IPY_MODEL_fd96316483e641d68cdfb37dcd76376c"
     }
    },
    "62283bbf1bfc45a6a6a682fc0e3dce12": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ed5200fc756b458593015c4326352947",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b282c1b4420c4eb4a082cdeb442c156f",
      "value": 231508
     }
    },
    "6794b7344ca74ea79e27d62cc2b731e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e9aaae0e19745f2ac45d9d45bdf21c0",
      "placeholder": "​",
      "style": "IPY_MODEL_ab3d4f183f6443e88b4a4b78e5bbe1e2",
      "value": "100%"
     }
    },
    "6801b124877349a8a98023c8eb5e815c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b7d2773434d44e2a938f996f3529e440",
       "IPY_MODEL_4a57a6d299c84c67a1eaccddd22333f7",
       "IPY_MODEL_0731022940e34eeea4d31220521bc634"
      ],
      "layout": "IPY_MODEL_5b9c47e409e1470c8c0b41c9eb0f64ba"
     }
    },
    "68384eae9d9c4dcd9a3f2fb6d659ba3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_320c7492a5794e28809a17403446da22",
      "placeholder": "​",
      "style": "IPY_MODEL_20a46cf22cb14596a0e17d536427be54",
      "value": " 28.0/28.0 [00:00&lt;00:00, 1.09kB/s]"
     }
    },
    "716e6dd6f01242e8a43fcfc4af14928e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7e9aaae0e19745f2ac45d9d45bdf21c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8792e60cc5054c7194bcc8ac017d455a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8b86dc099d57423ea042785d18647534": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "928e5719d3d844778e28851dadf15dbb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9331b69151ef41148d5c659b8d32d8f8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9657ec4ec82742da8d159dcd8f57dd99": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ba695ce3a904eb2a3e602c5cf5e538a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9f58864f0565433398c9dde618cc399e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a0956344476d48099cdcc28d8c40d9b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a1d7aec29ded41b393f2cb5c42fde010": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea7590ad5302420e96cbd4f844e1cd1e",
      "placeholder": "​",
      "style": "IPY_MODEL_2ef6ac57065a4646a8ac646ba0a0092f",
      "value": "Downloading: 100%"
     }
    },
    "a40fae8ff5c64755ac56ce47da45aee2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a6336c1fa3d44b638401f46c5833ed2d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ab3d4f183f6443e88b4a4b78e5bbe1e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ad16b7f28a1a45e689ec8389b1713bd4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af31b60f9817474985e11f21e6974bbe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b1f754a0a407465aa36641f48fa6a3db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe03fd2cd82145c8b4232fa3b8a3089a",
      "max": 67,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_716e6dd6f01242e8a43fcfc4af14928e",
      "value": 27
     }
    },
    "b282c1b4420c4eb4a082cdeb442c156f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b72be35ae5ef433382398a8f0171f7aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_21c0b45558584fb59ec527adca6f8518",
      "placeholder": "​",
      "style": "IPY_MODEL_e327b538ff384d7ea635a0a19fa8c466",
      "value": " 570/570 [00:00&lt;00:00, 21.9kB/s]"
     }
    },
    "b7d2773434d44e2a938f996f3529e440": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_536259048b704e86a6029f500fa440e6",
      "placeholder": "​",
      "style": "IPY_MODEL_9f58864f0565433398c9dde618cc399e",
      "value": "Downloading: 100%"
     }
    },
    "be051014d67743fbb9d84f7079ef0cd2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cab1a59fad4042279965587e565d316a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d49b2fe098646e6b8dd092a1e254e4f",
      "placeholder": "​",
      "style": "IPY_MODEL_9ba695ce3a904eb2a3e602c5cf5e538a",
      "value": " 8/8 [02:22&lt;00:00, 22.09s/it]"
     }
    },
    "cadca92ef4524a4ba0d46c9518cdb4f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_928e5719d3d844778e28851dadf15dbb",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a40fae8ff5c64755ac56ce47da45aee2",
      "value": 28
     }
    },
    "cc395cf0ce604d768b29ed37a85c3a75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d92b09abe9024a9a8611ca6924a412f4",
       "IPY_MODEL_62283bbf1bfc45a6a6a682fc0e3dce12",
       "IPY_MODEL_e61e8e1ba35443609f658c89e1844ea6"
      ],
      "layout": "IPY_MODEL_9331b69151ef41148d5c659b8d32d8f8"
     }
    },
    "d434d7bc611a49eea10ac8754452f958": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3d9ef44ea2c748028c3a4b35acbebd63",
       "IPY_MODEL_18817eb31c11408681bfc10fd79c552e",
       "IPY_MODEL_b72be35ae5ef433382398a8f0171f7aa"
      ],
      "layout": "IPY_MODEL_f73c5af633c7461e886ba6bb955ea7bc"
     }
    },
    "d775d856f78f429fb3235667a49d23e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d92b09abe9024a9a8611ca6924a412f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_016be63768c24b85ad49ebcc6bf8530c",
      "placeholder": "​",
      "style": "IPY_MODEL_da4b5c83e2534ca48e8b8b941a0355ea",
      "value": "Downloading: 100%"
     }
    },
    "da4b5c83e2534ca48e8b8b941a0355ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dbd5e6843716491baecf275a652359ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "de2dd812a7b64e13bec4016b014f20b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49041743e83646ffba06cc4cd30d42c6",
      "placeholder": "​",
      "style": "IPY_MODEL_a0956344476d48099cdcc28d8c40d9b9",
      "value": " 40%"
     }
    },
    "e0669bb1b79645b996d83b81a2a2df21": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e327b538ff384d7ea635a0a19fa8c466": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e61e8e1ba35443609f658c89e1844ea6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f2c57abc7ba34a41a3f43507bc5d9561",
      "placeholder": "​",
      "style": "IPY_MODEL_dbd5e6843716491baecf275a652359ef",
      "value": " 232k/232k [00:00&lt;00:00, 4.83MB/s]"
     }
    },
    "ea568e71d4aa491ab98a583f43c26541": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea7590ad5302420e96cbd4f844e1cd1e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed5200fc756b458593015c4326352947": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eda9f732b10b4a9887cc98a993beab6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ee66bd0ea5e44abe8547960d2b953dfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6794b7344ca74ea79e27d62cc2b731e7",
       "IPY_MODEL_46e9ef759c5a4076af228ca215de5f8a",
       "IPY_MODEL_cab1a59fad4042279965587e565d316a"
      ],
      "layout": "IPY_MODEL_be051014d67743fbb9d84f7079ef0cd2"
     }
    },
    "f2c57abc7ba34a41a3f43507bc5d9561": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f51568078be64c7393c71901cff90e87": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f73c5af633c7461e886ba6bb955ea7bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fd96316483e641d68cdfb37dcd76376c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe03fd2cd82145c8b4232fa3b8a3089a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
