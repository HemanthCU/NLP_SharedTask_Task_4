{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NIJGTIRqwShE",
    "outputId": "ba12ab0a-40b4-4754-e6b6-528537558ca2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 7.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
      "Collecting huggingface-hub<1.0,>=0.10.0\n",
      "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
      "\u001b[K     |████████████████████████████████| 182 kB 66.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.6 MB 44.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7SvCi2JuhC5P"
   },
   "outputs": [],
   "source": [
    "import traceback\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def write_tsv_dataframe(filepath, dataframe):\n",
    "    \"\"\"\n",
    "        Stores `DataFrame` as tsv file\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filepath : str\n",
    "            Path to tsv file\n",
    "        dataframe : pd.DataFrame\n",
    "            DataFrame to store\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        IOError\n",
    "            if the file can't be opened\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dataframe.to_csv(filepath, encoding='utf-8', sep='\\t', index=False, header=True, quoting=csv.QUOTE_NONE)\n",
    "    except IOError:\n",
    "        traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Ve5zjHvhhIMT"
   },
   "outputs": [],
   "source": [
    "def combine_columns(df_arguments, df_labels):\n",
    "    \"\"\"Combines the two `DataFrames` on column `Argument ID`\"\"\"\n",
    "    return pd.merge(df_arguments, df_labels, on='Argument ID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "tnaaQHrnhYnh"
   },
   "outputs": [],
   "source": [
    "def split_arguments(df_arguments):\n",
    "    \"\"\"Splits `DataFrame` by column `Usage` into `train`-, `validation`-, and `test`-arguments\"\"\"\n",
    "    train_arguments = df_arguments.loc[df_arguments['Usage'] == 'train'].drop(['Usage'], axis=1).reset_index(drop=True)\n",
    "    valid_arguments = df_arguments.loc[df_arguments['Usage'] == 'validation'].drop(['Usage'], axis=1).reset_index(drop=True)\n",
    "    test_arguments = df_arguments.loc[df_arguments['Usage'] == 'test'].drop(['Usage'], axis=1).reset_index(drop=True)\n",
    "    \n",
    "    return train_arguments, valid_arguments, test_arguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "kpljNrsChbf1"
   },
   "outputs": [],
   "source": [
    "def create_dataframe_head(argument_ids, model_name):\n",
    "    \"\"\"\n",
    "        Creates `DataFrame` usable to append predictions to it\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        argument_ids : list[str]\n",
    "            First column of the resulting DataFrame\n",
    "        model_name : str\n",
    "            Second column of DataFrame will contain the given model name\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            prepared DataFrame\n",
    "    \"\"\"\n",
    "    df_model_head = pd.DataFrame(argument_ids, columns=['Argument ID'])\n",
    "    df_model_head['Method'] = [model_name] * len(argument_ids)\n",
    "\n",
    "    return df_model_head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1MgX3B55hd9P"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "class MissingColumnError(AttributeError):\n",
    "    \"\"\"Error indicating that an imported DataFrame lacks necessary columns\"\"\"\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Qe-7L7j3ho_X"
   },
   "outputs": [],
   "source": [
    "def load_json_file(filepath):\n",
    "    \"\"\"Load content of json-file from `filepath`\"\"\"\n",
    "    with open(filepath, 'r') as  json_file:\n",
    "        return json.load(json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "vWGzjs9lhq_s"
   },
   "outputs": [],
   "source": [
    "def load_values_from_json(filepath):\n",
    "    \"\"\"Load values per level from json-file from `filepath`\"\"\"\n",
    "    json_values = load_json_file(filepath)\n",
    "    values = { \"1\":set(), \"2\":set(), \"3\":set(), \"4a\":set(), \"4b\":set() }\n",
    "    for value in json_values[\"values\"]:\n",
    "        values[\"1\"].add(value[\"name\"])\n",
    "        values[\"2\"].add(value[\"level2\"])\n",
    "        for valueLevel3 in value[\"level3\"]:\n",
    "            values[\"3\"].add(valueLevel3)\n",
    "        for valueLevel4a in value[\"level4a\"]:\n",
    "            values[\"4a\"].add(valueLevel4a)\n",
    "        for valueLevel4b in value[\"level4b\"]:\n",
    "            values[\"4b\"].add(valueLevel4b)\n",
    "    values[\"1\"] = sorted(values[\"1\"])\n",
    "    values[\"2\"] = sorted(values[\"2\"])\n",
    "    values[\"3\"] = sorted(values[\"3\"])\n",
    "    values[\"4a\"] = sorted(values[\"4a\"])\n",
    "    values[\"4b\"] = sorted(values[\"4b\"])\n",
    "    return values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "HpBKjzIihtk0"
   },
   "outputs": [],
   "source": [
    "def load_arguments_from_tsv(filepath, default_usage='test'):\n",
    "    \"\"\"\n",
    "        Reads arguments from tsv file\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filepath : str\n",
    "            The path to the tsv file\n",
    "        default_usage : str, optional\n",
    "            The default value if the column \"Usage\" is missing\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            the DataFrame with all arguments\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        MissingColumnError\n",
    "            if the required columns \"Argument ID\" or \"Premise\" are missing in the read data\n",
    "        IOError\n",
    "            if the file can't be read\n",
    "        \"\"\"\n",
    "    try:\n",
    "        dataframe = pd.read_csv(filepath, encoding='utf-8', sep='\\t', header=0)\n",
    "        if not {'Argument ID', 'Premise'}.issubset(set(dataframe.columns.values)):\n",
    "            raise MissingColumnError('The argument \"%s\" file does not contain the minimum required columns [Argument ID, Premise].' % filepath)\n",
    "        if 'Usage' not in dataframe.columns.values:\n",
    "            dataframe['Usage'] = [default_usage] * len(dataframe)\n",
    "        return dataframe\n",
    "    except IOError:\n",
    "        traceback.print_exc()\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "lTFyn21VhwsY"
   },
   "outputs": [],
   "source": [
    "def load_labels_from_tsv(filepath, label_order):\n",
    "    \"\"\"\n",
    "        Reads label annotations from tsv file\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filepath : str\n",
    "            The path to the tsv file\n",
    "        label_order : list[str]\n",
    "            The listing and order of the labels to use from the read data\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            the DataFrame with the annotations\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        MissingColumnError\n",
    "            if the required columns \"Argument ID\" or names from `label_order` are missing in the read data\n",
    "        IOError\n",
    "            if the file can't be read\n",
    "        \"\"\"\n",
    "    try:\n",
    "        dataframe = pd.read_csv(filepath, encoding='utf-8', sep='\\t', header=0)\n",
    "        dataframe = dataframe[['Argument ID'] + label_order]\n",
    "        return dataframe\n",
    "    except IOError:\n",
    "        traceback.print_exc()\n",
    "        raise\n",
    "    except KeyError:\n",
    "        raise MissingColumnError('The file \"%s\" does not contain the required columns for its level.' % filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "yxSNyT8Why1g"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import getopt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "dQ_Eh4qMi6dA"
   },
   "outputs": [],
   "source": [
    "model_dir = 'models'\n",
    "data_dir = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "HHejuM1kh4i8"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "eyHY5YMAi5D9"
   },
   "outputs": [],
   "source": [
    "argument_filepath = os.path.join(data_dir, 'arguments.tsv')\n",
    "value_json_filepath = os.path.join(data_dir, 'values.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "cNk-VDCUjPh1"
   },
   "outputs": [],
   "source": [
    "df_arguments = load_arguments_from_tsv(argument_filepath, default_usage='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "cN1Ugt6xjUla"
   },
   "outputs": [],
   "source": [
    "values = load_values_from_json(value_json_filepath)\n",
    "num_labels_Lv2 = len(values['2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-sZzSzdQmYi7",
    "outputId": "c8740d15-06e7-462d-f0a8-3c63a65f261e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Argument ID', 'Part', 'Usage', 'Conclusion', 'Stance', 'Premise'], dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_arguments.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gRHUX8b_n9ve",
    "outputId": "43e36633-dc05-4f02-c155-b4d61e9dbb23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A01001\n",
      "A01002\n",
      "A01003\n",
      "A01004\n",
      "A01005\n",
      "A01006\n",
      "A01007\n",
      "A01008\n",
      "A01009\n",
      "A01010\n",
      "A01011\n",
      "A01012\n",
      "A01013\n",
      "A01014\n",
      "A01015\n",
      "A01016\n",
      "A01017\n",
      "A01018\n",
      "A01019\n",
      "A01020\n",
      "A02001\n",
      "A02002\n",
      "A02003\n",
      "A02004\n",
      "A02005\n",
      "A02006\n",
      "A02007\n",
      "A02008\n",
      "A02009\n",
      "A02010\n",
      "A02011\n",
      "A02012\n",
      "A02013\n",
      "A02014\n",
      "A02015\n",
      "A02016\n",
      "A02017\n",
      "A02018\n",
      "A02019\n",
      "A02020\n",
      "A03001\n",
      "A03002\n",
      "A03003\n",
      "A03004\n",
      "A03005\n",
      "A03006\n",
      "A03007\n",
      "A03008\n",
      "A03009\n",
      "A03010\n",
      "A03011\n",
      "A03012\n",
      "A03013\n",
      "A03014\n",
      "A03015\n",
      "A03016\n",
      "A03017\n",
      "A03018\n",
      "A03019\n",
      "A03020\n",
      "A04001\n",
      "A04002\n",
      "A04003\n",
      "A04004\n",
      "A04005\n",
      "A04006\n",
      "A04007\n",
      "A04008\n",
      "A04009\n",
      "A04010\n",
      "A04011\n",
      "A04012\n",
      "A04013\n",
      "A04014\n",
      "A04015\n",
      "A04016\n",
      "A04017\n",
      "A04018\n",
      "A04019\n",
      "A04020\n",
      "A05001\n",
      "A05002\n",
      "A05003\n",
      "A05004\n",
      "A05005\n",
      "A05006\n",
      "A05007\n",
      "A05008\n",
      "A05009\n",
      "A05010\n",
      "A05011\n",
      "A05012\n",
      "A05013\n",
      "A05014\n",
      "A05015\n",
      "A05016\n",
      "A05017\n",
      "A05018\n",
      "A05019\n",
      "A05020\n",
      "A05021\n",
      "A05022\n",
      "A05023\n",
      "A05024\n",
      "A05025\n",
      "A05026\n",
      "A05027\n",
      "A05028\n",
      "A05029\n",
      "A05030\n",
      "A05031\n",
      "A05032\n",
      "A05033\n",
      "A05034\n",
      "A05035\n",
      "A05036\n",
      "A05037\n",
      "A05038\n",
      "A05043\n",
      "A05045\n",
      "A05048\n",
      "A05049\n",
      "A05050\n",
      "A05052\n",
      "A05053\n",
      "A05054\n",
      "A05055\n",
      "A05056\n",
      "A05057\n",
      "A05058\n",
      "A05059\n",
      "A05062\n",
      "A05063\n",
      "A05064\n",
      "A05065\n",
      "A05066\n",
      "A05067\n",
      "A05069\n",
      "A05071\n",
      "A05072\n",
      "A05073\n",
      "A05074\n",
      "A05075\n",
      "A05076\n",
      "A05077\n",
      "A05078\n",
      "A05079\n",
      "A05080\n",
      "A05081\n",
      "A05082\n",
      "A05083\n",
      "A05084\n",
      "A05086\n",
      "A05087\n",
      "A05088\n",
      "A05090\n",
      "A05091\n",
      "A05092\n",
      "A05093\n",
      "A05095\n",
      "A05096\n",
      "A05097\n",
      "A05098\n",
      "A05099\n",
      "A05100\n",
      "A06001\n",
      "A06002\n",
      "A06003\n",
      "A06004\n",
      "A06005\n",
      "A06006\n",
      "A06007\n",
      "A06008\n",
      "A06010\n",
      "A06011\n",
      "A06012\n",
      "A06013\n",
      "A06014\n",
      "A06015\n",
      "A06016\n",
      "A06019\n",
      "A06020\n",
      "A07001\n",
      "A07002\n",
      "A07003\n",
      "A07004\n",
      "A07008\n",
      "A07009\n",
      "A07010\n",
      "A07011\n",
      "A07012\n",
      "A07013\n",
      "A07014\n",
      "A07015\n",
      "A07016\n",
      "A07018\n",
      "A07019\n",
      "A07020\n",
      "A07021\n",
      "A07022\n",
      "A07023\n",
      "A07024\n",
      "A07025\n",
      "A07026\n",
      "A07027\n",
      "A07028\n",
      "A07029\n",
      "A07030\n",
      "A07031\n",
      "A07032\n",
      "A07033\n",
      "A07034\n",
      "A07035\n",
      "A07037\n",
      "A07038\n",
      "A07040\n",
      "A07042\n",
      "A07043\n",
      "A07044\n",
      "A07045\n",
      "A07046\n",
      "A07048\n",
      "A07049\n",
      "A07050\n",
      "A07051\n",
      "A07052\n",
      "A07053\n",
      "A07054\n",
      "A07055\n",
      "A07056\n",
      "A07058\n",
      "A07059\n",
      "A07060\n",
      "A07061\n",
      "A07062\n",
      "A07063\n",
      "A07065\n",
      "A07066\n",
      "A07068\n",
      "A07069\n",
      "A07070\n",
      "A07071\n",
      "A07073\n",
      "A07074\n",
      "A07075\n",
      "A07076\n",
      "A07077\n",
      "A07078\n",
      "A07079\n",
      "A07080\n",
      "A07081\n",
      "A07082\n",
      "A07084\n",
      "A07085\n",
      "A07086\n",
      "A07087\n",
      "A07088\n",
      "A07089\n",
      "A07090\n",
      "A07092\n",
      "A07093\n",
      "A07094\n",
      "A07096\n",
      "A07097\n",
      "A07098\n",
      "A07099\n",
      "A07100\n",
      "A08001\n",
      "A08002\n",
      "A08003\n",
      "A08004\n",
      "A08005\n",
      "A08007\n",
      "A08008\n",
      "A08009\n",
      "A08011\n",
      "A08012\n",
      "A08013\n",
      "A08014\n",
      "A08016\n",
      "A08018\n",
      "A08019\n",
      "A08020\n",
      "A09001\n",
      "A09002\n",
      "A09003\n",
      "A09004\n",
      "A09005\n",
      "A09006\n",
      "A09007\n",
      "A09008\n",
      "A09009\n",
      "A09011\n",
      "A09012\n",
      "A09013\n",
      "A09015\n",
      "A09016\n",
      "A09017\n",
      "A09019\n",
      "A09020\n",
      "A09021\n",
      "A09022\n",
      "A09023\n",
      "A09024\n",
      "A09026\n",
      "A09027\n",
      "A09028\n",
      "A09029\n",
      "A09030\n",
      "A09031\n",
      "A09032\n",
      "A09035\n",
      "A09036\n",
      "A09037\n",
      "A09038\n",
      "A09040\n",
      "A09041\n",
      "A09042\n",
      "A09043\n",
      "A09044\n",
      "A09045\n",
      "A09046\n",
      "A09047\n",
      "A09048\n",
      "A09049\n",
      "A09050\n",
      "A09051\n",
      "A09052\n",
      "A09053\n",
      "A09054\n",
      "A09055\n",
      "A09056\n",
      "A09057\n",
      "A09058\n",
      "A09059\n",
      "A09060\n",
      "A09063\n",
      "A09064\n",
      "A09065\n",
      "A09066\n",
      "A09067\n",
      "A09068\n",
      "A09070\n",
      "A09071\n",
      "A09072\n",
      "A09073\n",
      "A09074\n",
      "A09075\n",
      "A09076\n",
      "A09078\n",
      "A09079\n",
      "A09080\n",
      "A09082\n",
      "A09083\n",
      "A09084\n",
      "A09085\n",
      "A09086\n",
      "A09087\n",
      "A09089\n",
      "A09090\n",
      "A09091\n",
      "A09092\n",
      "A09093\n",
      "A09094\n",
      "A09095\n",
      "A09096\n",
      "A09097\n",
      "A10001\n",
      "A10002\n",
      "A10003\n",
      "A10004\n",
      "A10005\n",
      "A10006\n",
      "A10007\n",
      "A10008\n",
      "A10009\n",
      "A10010\n",
      "A10012\n",
      "A10013\n",
      "A10014\n",
      "A10015\n",
      "A10017\n",
      "A10018\n",
      "A10019\n",
      "A10020\n",
      "A12002\n",
      "A12004\n",
      "A12005\n",
      "A12006\n",
      "A12007\n",
      "A12008\n",
      "A12009\n",
      "A12010\n",
      "A12011\n",
      "A12013\n",
      "A12014\n",
      "A12015\n",
      "A12016\n",
      "A12017\n",
      "A12019\n",
      "A12020\n",
      "A12021\n",
      "A12024\n",
      "A12025\n",
      "A12026\n",
      "A12027\n",
      "A12028\n",
      "A12029\n",
      "A12030\n",
      "A12031\n",
      "A12032\n",
      "A12033\n",
      "A12034\n",
      "A12035\n",
      "A12036\n",
      "A12037\n",
      "A12038\n",
      "A12039\n",
      "A12041\n",
      "A12042\n",
      "A12043\n",
      "A12045\n",
      "A12046\n",
      "A12047\n",
      "A12048\n",
      "A12049\n",
      "A12050\n",
      "A12051\n",
      "A12053\n",
      "A12054\n",
      "A12055\n",
      "A12056\n",
      "A12057\n",
      "A12058\n",
      "A12059\n",
      "A12060\n",
      "A12062\n",
      "A12063\n",
      "A12064\n",
      "A12065\n",
      "A12066\n",
      "A12067\n",
      "A12070\n",
      "A12071\n",
      "A12072\n",
      "A12073\n",
      "A12074\n",
      "A12075\n",
      "A12076\n",
      "A12078\n",
      "A12080\n",
      "A12081\n",
      "A12082\n",
      "A12083\n",
      "A12084\n",
      "A12086\n",
      "A12087\n",
      "A12088\n",
      "A12089\n",
      "A12091\n",
      "A12092\n",
      "A12093\n",
      "A12094\n",
      "A12095\n",
      "A12096\n",
      "A12097\n",
      "A12098\n",
      "A12099\n",
      "A12100\n",
      "A12101\n",
      "A12102\n",
      "A12103\n",
      "A12104\n",
      "A12105\n",
      "A12106\n",
      "A12107\n",
      "A12109\n",
      "A12110\n",
      "A12111\n",
      "A12112\n",
      "A12113\n",
      "A12114\n",
      "A12116\n",
      "A12117\n",
      "A12118\n",
      "A12119\n",
      "A12120\n",
      "A12122\n",
      "A12123\n",
      "A12124\n",
      "A12125\n",
      "A12126\n",
      "A12127\n",
      "A12128\n",
      "A12129\n",
      "A12130\n",
      "A12131\n",
      "A12132\n",
      "A12133\n",
      "A12134\n",
      "A12135\n",
      "A12136\n",
      "A12137\n",
      "A12139\n",
      "A12140\n",
      "A12141\n",
      "A12142\n",
      "A12144\n",
      "A12146\n",
      "A12147\n",
      "A12148\n",
      "A12153\n",
      "A12155\n",
      "A12156\n",
      "A12157\n",
      "A12158\n",
      "A12159\n",
      "A12160\n",
      "A12161\n",
      "A12162\n",
      "A12163\n",
      "A12164\n",
      "A12165\n",
      "A12166\n",
      "A12167\n",
      "A12168\n",
      "A12170\n",
      "A12171\n",
      "A12173\n",
      "A12174\n",
      "A12175\n",
      "A12176\n",
      "A12177\n",
      "A12178\n",
      "A12179\n",
      "A12180\n",
      "A12181\n",
      "A12182\n",
      "A12184\n",
      "A12185\n",
      "A12187\n",
      "A12188\n",
      "A12190\n",
      "A12191\n",
      "A12192\n",
      "A12193\n",
      "A12194\n",
      "A12195\n",
      "A12197\n",
      "A12198\n",
      "A12201\n",
      "A12202\n",
      "A12204\n",
      "A12205\n",
      "A12206\n",
      "A12208\n",
      "A12209\n",
      "A12210\n",
      "A12211\n",
      "A12212\n",
      "A12214\n",
      "A12215\n",
      "A12217\n",
      "A12218\n",
      "A12219\n",
      "A12220\n",
      "A12221\n",
      "A12222\n",
      "A12223\n",
      "A12224\n",
      "A12225\n",
      "A12226\n",
      "A12228\n",
      "A12229\n",
      "A12230\n",
      "A12231\n",
      "A12232\n",
      "A12236\n",
      "A12237\n",
      "A12238\n",
      "A12239\n",
      "A12240\n",
      "A12241\n",
      "A12243\n",
      "A12244\n",
      "A12246\n",
      "A12247\n",
      "A12248\n",
      "A12249\n",
      "A12251\n",
      "A12252\n",
      "A12253\n",
      "A12254\n",
      "A12255\n",
      "A12256\n",
      "A12257\n",
      "A12258\n",
      "A12259\n",
      "A12260\n",
      "A12261\n",
      "A12262\n",
      "A12263\n",
      "A12265\n",
      "A12266\n",
      "A12267\n",
      "A12268\n",
      "A12269\n",
      "A12270\n",
      "A12271\n",
      "A12273\n",
      "A12274\n",
      "A12275\n",
      "A12276\n",
      "A12277\n",
      "A12278\n",
      "A12279\n",
      "A12280\n",
      "A12281\n",
      "A12282\n",
      "A12283\n",
      "A12284\n",
      "A12286\n",
      "A12287\n",
      "A12288\n",
      "A12289\n",
      "A12290\n",
      "A12292\n",
      "A12293\n",
      "A12295\n",
      "A12296\n",
      "A12297\n",
      "A12298\n",
      "A12299\n",
      "A12300\n",
      "A12301\n",
      "A12302\n",
      "A12303\n",
      "A12304\n",
      "A12305\n",
      "A12306\n",
      "A12307\n",
      "A12308\n",
      "A12309\n",
      "A12310\n",
      "A12311\n",
      "A12313\n",
      "A12315\n",
      "A12316\n",
      "A12317\n",
      "A12318\n",
      "A12319\n",
      "A12320\n",
      "A12321\n",
      "A12322\n",
      "A12323\n",
      "A12324\n",
      "A12325\n",
      "A12326\n",
      "A12327\n",
      "A12328\n",
      "A12329\n",
      "A12330\n",
      "A12332\n",
      "A12333\n",
      "A12334\n",
      "A12335\n",
      "A12336\n",
      "A12337\n",
      "A12338\n",
      "A12340\n",
      "A12341\n",
      "A12343\n",
      "A12344\n",
      "A12345\n",
      "A12347\n",
      "A12348\n",
      "A12349\n",
      "A12351\n",
      "A12352\n",
      "A12353\n",
      "A12354\n",
      "A12355\n",
      "A12356\n",
      "A12357\n",
      "A12358\n",
      "A12359\n",
      "A12360\n",
      "A12363\n",
      "A12364\n",
      "A12365\n",
      "A12366\n",
      "A12367\n",
      "A12368\n",
      "A12369\n",
      "A12370\n",
      "A12372\n",
      "A12374\n",
      "A12376\n",
      "A12377\n",
      "A12379\n",
      "A12380\n",
      "A12381\n",
      "A12385\n",
      "A12386\n",
      "A12387\n",
      "A12388\n",
      "A12389\n",
      "A12390\n",
      "A12391\n",
      "A12392\n",
      "A12393\n",
      "A12394\n",
      "A12396\n",
      "A12397\n",
      "A12398\n",
      "A12400\n",
      "A12402\n",
      "A12403\n",
      "A12404\n",
      "A12405\n",
      "A12406\n",
      "A12407\n",
      "A12408\n",
      "A12409\n",
      "A12410\n",
      "A12411\n",
      "A12412\n",
      "A12413\n",
      "A12414\n",
      "A12415\n",
      "A12416\n",
      "A12417\n",
      "A12418\n",
      "A12419\n",
      "A12420\n",
      "A12421\n",
      "A12422\n",
      "A12423\n",
      "A12424\n",
      "A12425\n",
      "A12426\n",
      "A12427\n",
      "A12428\n",
      "A12429\n",
      "A12431\n",
      "A12432\n",
      "A12433\n",
      "A12434\n",
      "A12435\n",
      "A12436\n",
      "A12437\n",
      "A12438\n",
      "A12439\n",
      "A12440\n",
      "A12441\n",
      "A12442\n",
      "A12443\n",
      "A12444\n",
      "A12445\n",
      "A12446\n",
      "A12447\n",
      "A12448\n",
      "A12450\n",
      "A12451\n",
      "A12452\n",
      "A12453\n",
      "A12454\n",
      "A12456\n",
      "A12457\n",
      "A12458\n",
      "A12459\n",
      "A12460\n",
      "A12461\n",
      "A12462\n",
      "A12464\n",
      "A12465\n",
      "A12466\n",
      "A12467\n",
      "A12468\n",
      "A12469\n",
      "A12470\n",
      "A12472\n",
      "A12473\n",
      "A12474\n",
      "A12475\n",
      "A12476\n",
      "A12477\n",
      "A12478\n",
      "A12479\n",
      "A12481\n",
      "A12484\n",
      "A12485\n",
      "A12487\n",
      "A12488\n",
      "A12489\n",
      "A12490\n",
      "A12491\n",
      "A12492\n",
      "A12494\n",
      "A12496\n",
      "A12497\n",
      "A12498\n",
      "A12499\n",
      "A12500\n",
      "A13001\n",
      "A13002\n",
      "A13003\n",
      "A13004\n",
      "A13005\n",
      "A13006\n",
      "A13007\n",
      "A13008\n",
      "A13009\n",
      "A13011\n",
      "A13012\n",
      "A13013\n",
      "A13014\n",
      "A13017\n",
      "A13018\n",
      "A13019\n",
      "A13020\n",
      "A14001\n",
      "A14002\n",
      "A14003\n",
      "A14005\n",
      "A14006\n",
      "A14007\n",
      "A14008\n",
      "A14010\n",
      "A14011\n",
      "A14013\n",
      "A14014\n",
      "A14015\n",
      "A14017\n",
      "A14018\n",
      "A14019\n",
      "A14020\n",
      "A15001\n",
      "A15002\n",
      "A15003\n",
      "A15004\n",
      "A15006\n",
      "A15007\n",
      "A15008\n",
      "A15009\n",
      "A15010\n",
      "A15011\n",
      "A15013\n",
      "A15014\n",
      "A15015\n",
      "A15017\n",
      "A15019\n",
      "A15020\n",
      "A17002\n",
      "A17003\n",
      "A17004\n",
      "A17006\n",
      "A17007\n",
      "A17008\n",
      "A17009\n",
      "A17011\n",
      "A17013\n",
      "A17014\n",
      "A17015\n",
      "A17016\n",
      "A17017\n",
      "A17018\n",
      "A17019\n",
      "A18001\n",
      "A18002\n",
      "A18003\n",
      "A18004\n",
      "A18005\n",
      "A18006\n",
      "A18007\n",
      "A18008\n",
      "A18009\n",
      "A18010\n",
      "A18011\n",
      "A18012\n",
      "A18013\n",
      "A18014\n",
      "A18015\n",
      "A18016\n",
      "A18017\n",
      "A18018\n",
      "A18019\n",
      "A18020\n",
      "A18021\n",
      "A18022\n",
      "A18023\n",
      "A18024\n",
      "A18025\n",
      "A18026\n",
      "A18027\n",
      "A18028\n",
      "A18029\n",
      "A18030\n",
      "A18032\n",
      "A18033\n",
      "A18034\n",
      "A18036\n",
      "A18037\n",
      "A18039\n",
      "A18040\n",
      "A18041\n",
      "A18042\n",
      "A18043\n",
      "A18044\n",
      "A18045\n",
      "A18046\n",
      "A18047\n",
      "A18049\n",
      "A18050\n",
      "A18051\n",
      "A18052\n",
      "A18053\n",
      "A18054\n",
      "A18056\n",
      "A18057\n",
      "A18058\n",
      "A18059\n",
      "A18060\n",
      "A18061\n",
      "A18062\n",
      "A18064\n",
      "A18065\n",
      "A18066\n",
      "A18067\n",
      "A18069\n",
      "A18070\n",
      "A18071\n",
      "A18072\n",
      "A18073\n",
      "A18074\n",
      "A18075\n",
      "A18076\n",
      "A18077\n",
      "A18078\n",
      "A18079\n",
      "A18080\n",
      "A18081\n",
      "A18082\n",
      "A18083\n",
      "A18085\n",
      "A18086\n",
      "A18087\n",
      "A18088\n",
      "A18089\n",
      "A18090\n",
      "A18091\n",
      "A18092\n",
      "A18093\n",
      "A18094\n",
      "A18095\n",
      "A18096\n",
      "A18097\n",
      "A18098\n",
      "A18099\n",
      "A18101\n",
      "A18102\n",
      "A18103\n",
      "A18104\n",
      "A18105\n",
      "A18106\n",
      "A18107\n",
      "A18108\n",
      "A18109\n",
      "A18110\n",
      "A18111\n",
      "A18112\n",
      "A18113\n",
      "A18116\n",
      "A18117\n",
      "A18118\n",
      "A18120\n",
      "A18122\n",
      "A18124\n",
      "A18125\n",
      "A18126\n",
      "A18127\n",
      "A18128\n",
      "A18129\n",
      "A18130\n",
      "A18131\n",
      "A18132\n",
      "A18133\n",
      "A18134\n",
      "A18135\n",
      "A18136\n",
      "A18137\n",
      "A18138\n",
      "A18139\n",
      "A18140\n",
      "A18141\n",
      "A18142\n",
      "A18143\n",
      "A18144\n",
      "A18146\n",
      "A18147\n",
      "A18148\n",
      "A18149\n",
      "A18150\n",
      "A18151\n",
      "A18152\n",
      "A18153\n",
      "A18155\n",
      "A18156\n",
      "A18157\n",
      "A18160\n",
      "A18162\n",
      "A18163\n",
      "A18164\n",
      "A18165\n",
      "A18166\n",
      "A18167\n",
      "A18168\n",
      "A18169\n",
      "A18170\n",
      "A18171\n",
      "A18172\n",
      "A18173\n",
      "A18174\n",
      "A18175\n",
      "A18176\n",
      "A18177\n",
      "A18178\n",
      "A18179\n",
      "A18180\n",
      "A18181\n",
      "A18182\n",
      "A18184\n",
      "A18185\n",
      "A18187\n",
      "A18188\n",
      "A18189\n",
      "A18190\n",
      "A18191\n",
      "A18192\n",
      "A18194\n",
      "A18195\n",
      "A18196\n",
      "A18197\n",
      "A18198\n",
      "A18200\n",
      "A18201\n",
      "A18202\n",
      "A18204\n",
      "A18205\n",
      "A18207\n",
      "A18208\n",
      "A18210\n",
      "A18211\n",
      "A18212\n",
      "A18214\n",
      "A18216\n",
      "A18217\n",
      "A18218\n",
      "A18219\n",
      "A18220\n",
      "A18221\n",
      "A18222\n",
      "A18223\n",
      "A18224\n",
      "A18225\n",
      "A18226\n",
      "A18229\n",
      "A18230\n",
      "A18232\n",
      "A18233\n",
      "A18234\n",
      "A18235\n",
      "A18236\n",
      "A18237\n",
      "A18238\n",
      "A18239\n",
      "A18240\n",
      "A18241\n",
      "A18242\n",
      "A18243\n",
      "A18245\n",
      "A18246\n",
      "A18247\n",
      "A18248\n",
      "A18249\n",
      "A18250\n",
      "A18251\n",
      "A18252\n",
      "A18255\n",
      "A18257\n",
      "A18259\n",
      "A18260\n",
      "A18262\n",
      "A18265\n",
      "A18266\n",
      "A18267\n",
      "A18268\n",
      "A18269\n",
      "A18270\n",
      "A18272\n",
      "A18273\n",
      "A18274\n",
      "A18276\n",
      "A18277\n",
      "A18278\n",
      "A18279\n",
      "A18280\n",
      "A18281\n",
      "A18282\n",
      "A18284\n",
      "A18285\n",
      "A18286\n",
      "A18287\n",
      "A18288\n",
      "A18289\n",
      "A18290\n",
      "A18291\n",
      "A18292\n",
      "A18293\n",
      "A18294\n",
      "A18295\n",
      "A18296\n",
      "A18297\n",
      "A18298\n",
      "A18299\n",
      "A18300\n",
      "A18301\n",
      "A18302\n",
      "A18304\n",
      "A18305\n",
      "A18306\n",
      "A18308\n",
      "A18309\n",
      "A18310\n",
      "A18311\n",
      "A18313\n",
      "A18314\n",
      "A18315\n",
      "A18316\n",
      "A18317\n",
      "A18318\n",
      "A18320\n",
      "A18321\n",
      "A18322\n",
      "A18324\n",
      "A18325\n",
      "A18326\n",
      "A18327\n",
      "A18328\n",
      "A18329\n",
      "A18330\n",
      "A18331\n",
      "A18334\n",
      "A18335\n",
      "A18336\n",
      "A18337\n",
      "A18339\n",
      "A18340\n",
      "A18341\n",
      "A18343\n",
      "A18344\n",
      "A18345\n",
      "A18346\n",
      "A18348\n",
      "A18349\n",
      "A18350\n",
      "A18351\n",
      "A18353\n",
      "A18354\n",
      "A18355\n",
      "A18356\n",
      "A18357\n",
      "A18358\n",
      "A18359\n",
      "A18360\n",
      "A18361\n",
      "A18362\n",
      "A18364\n",
      "A18365\n",
      "A18367\n",
      "A18368\n",
      "A18369\n",
      "A18370\n",
      "A18371\n",
      "A18372\n",
      "A18373\n",
      "A18374\n",
      "A18376\n",
      "A18377\n",
      "A18378\n",
      "A18379\n",
      "A18380\n",
      "A18381\n",
      "A18382\n",
      "A18383\n",
      "A18385\n",
      "A18386\n",
      "A18387\n",
      "A18388\n",
      "A18389\n",
      "A18390\n",
      "A18391\n",
      "A18393\n",
      "A18394\n",
      "A18395\n",
      "A18396\n",
      "A18397\n",
      "A18398\n",
      "A18399\n",
      "A18400\n",
      "A18401\n",
      "A18402\n",
      "A18403\n",
      "A18404\n",
      "A18405\n",
      "A18407\n",
      "A18408\n",
      "A18410\n",
      "A18412\n",
      "A18414\n",
      "A18415\n",
      "A18416\n",
      "A18417\n",
      "A18418\n",
      "A18419\n",
      "A18420\n",
      "A18421\n",
      "A18422\n",
      "A18423\n",
      "A18424\n",
      "A18425\n",
      "A18426\n",
      "A18427\n",
      "A18428\n",
      "A18429\n",
      "A18430\n",
      "A18431\n",
      "A18432\n",
      "A18433\n",
      "A18435\n",
      "A18436\n",
      "A18437\n",
      "A18439\n",
      "A18440\n",
      "A18441\n",
      "A18442\n",
      "A18443\n",
      "A18444\n",
      "A18445\n",
      "A18448\n",
      "A18449\n",
      "A18450\n",
      "A18451\n",
      "A18452\n",
      "A18453\n",
      "A18454\n",
      "A18455\n",
      "A18456\n",
      "A18458\n",
      "A18460\n",
      "A18461\n",
      "A18462\n",
      "A18463\n",
      "A18465\n",
      "A18466\n",
      "A18467\n",
      "A18468\n",
      "A18469\n",
      "A18470\n",
      "A18471\n",
      "A18472\n",
      "A18473\n",
      "A18474\n",
      "A18477\n",
      "A18478\n",
      "A18479\n",
      "A18481\n",
      "A18483\n",
      "A18484\n",
      "A18485\n",
      "A18486\n",
      "A18487\n",
      "A18489\n",
      "A18490\n",
      "A18491\n",
      "A18492\n",
      "A18493\n",
      "A18496\n",
      "A18497\n",
      "A18498\n",
      "A18499\n",
      "A18500\n",
      "A19001\n",
      "A19003\n",
      "A19007\n",
      "A19008\n",
      "A19009\n",
      "A19010\n",
      "A19011\n",
      "A19013\n",
      "A19014\n",
      "A19015\n",
      "A19016\n",
      "A19018\n",
      "A19019\n",
      "A19020\n",
      "A19021\n",
      "A19022\n",
      "A19023\n",
      "A19024\n",
      "A19025\n",
      "A19026\n",
      "A19027\n",
      "A19028\n",
      "A19031\n",
      "A19032\n",
      "A19033\n",
      "A19034\n",
      "A19035\n",
      "A19036\n",
      "A19037\n",
      "A19038\n",
      "A19039\n",
      "A19040\n",
      "A19041\n",
      "A19042\n",
      "A19043\n",
      "A19045\n",
      "A19046\n",
      "A19047\n",
      "A19048\n",
      "A19050\n",
      "A19052\n",
      "A19054\n",
      "A19055\n",
      "A19056\n",
      "A19057\n",
      "A19058\n",
      "A19059\n",
      "A19060\n",
      "A19061\n",
      "A19062\n",
      "A19063\n",
      "A19064\n",
      "A19065\n",
      "A19066\n",
      "A19067\n",
      "A19068\n",
      "A19069\n",
      "A19071\n",
      "A19072\n",
      "A19074\n",
      "A19075\n",
      "A19076\n",
      "A19077\n",
      "A19078\n",
      "A19080\n",
      "A19081\n",
      "A19083\n",
      "A19084\n",
      "A19085\n",
      "A19086\n",
      "A19088\n",
      "A19089\n",
      "A19090\n",
      "A19091\n",
      "A19092\n",
      "A19093\n",
      "A19094\n",
      "A19095\n",
      "A19097\n",
      "A19098\n",
      "A19099\n",
      "A19100\n",
      "A19101\n",
      "A19102\n",
      "A19103\n",
      "A19104\n",
      "A19105\n",
      "A19106\n",
      "A19107\n",
      "A19108\n",
      "A19109\n",
      "A19110\n",
      "A19111\n",
      "A19113\n",
      "A19114\n",
      "A19115\n",
      "A19116\n",
      "A19117\n",
      "A19118\n",
      "A19120\n",
      "A19121\n",
      "A19122\n",
      "A19123\n",
      "A19124\n",
      "A19126\n",
      "A19127\n",
      "A19128\n",
      "A19129\n",
      "A19131\n",
      "A19132\n",
      "A19133\n",
      "A19134\n",
      "A19135\n",
      "A19137\n",
      "A19138\n",
      "A19139\n",
      "A19140\n",
      "A19141\n",
      "A19143\n",
      "A19145\n",
      "A19148\n",
      "A19149\n",
      "A19150\n",
      "A19151\n",
      "A19153\n",
      "A19154\n",
      "A19155\n",
      "A19156\n",
      "A19157\n",
      "A19158\n",
      "A19159\n",
      "A19160\n",
      "A19161\n",
      "A19162\n",
      "A19163\n",
      "A19164\n",
      "A19165\n",
      "A19166\n",
      "A19167\n",
      "A19168\n",
      "A19169\n",
      "A19170\n",
      "A19171\n",
      "A19173\n",
      "A19174\n",
      "A19176\n",
      "A19178\n",
      "A19179\n",
      "A19180\n",
      "A19181\n",
      "A19182\n",
      "A19183\n",
      "A19185\n",
      "A19186\n",
      "A19187\n",
      "A19188\n",
      "A19190\n",
      "A19192\n",
      "A19194\n",
      "A19195\n",
      "A19196\n",
      "A19197\n",
      "A19198\n",
      "A19199\n",
      "A19200\n",
      "A19201\n",
      "A19202\n",
      "A19203\n",
      "A19204\n",
      "A19206\n",
      "A19207\n",
      "A19208\n",
      "A19209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A19210\n",
      "A19211\n",
      "A19212\n",
      "A19213\n",
      "A19214\n",
      "A19215\n",
      "A19216\n",
      "A19217\n",
      "A19218\n",
      "A19219\n",
      "A19220\n",
      "A19221\n",
      "A19222\n",
      "A19225\n",
      "A19228\n",
      "A19229\n",
      "A19230\n",
      "A19231\n",
      "A19232\n",
      "A19233\n",
      "A19234\n",
      "A19235\n",
      "A19236\n",
      "A19238\n",
      "A19239\n",
      "A19241\n",
      "A19242\n",
      "A19243\n",
      "A19244\n",
      "A19245\n",
      "A19246\n",
      "A19247\n",
      "A19248\n",
      "A19250\n",
      "A19252\n",
      "A19253\n",
      "A19254\n",
      "A19255\n",
      "A19256\n",
      "A19258\n",
      "A19259\n",
      "A19261\n",
      "A19262\n",
      "A19263\n",
      "A19264\n",
      "A19265\n",
      "A19266\n",
      "A19267\n",
      "A19268\n",
      "A19269\n",
      "A19270\n",
      "A19271\n",
      "A19272\n",
      "A19273\n",
      "A19274\n",
      "A19276\n",
      "A19277\n",
      "A19278\n",
      "A19279\n",
      "A19280\n",
      "A19281\n",
      "A19282\n",
      "A19284\n",
      "A19285\n",
      "A19287\n",
      "A19288\n",
      "A19289\n",
      "A19290\n",
      "A19291\n",
      "A19292\n",
      "A19293\n",
      "A19294\n",
      "A19295\n",
      "A19296\n",
      "A19297\n",
      "A19298\n",
      "A19299\n",
      "A19301\n",
      "A19302\n",
      "A19303\n",
      "A19304\n",
      "A19305\n",
      "A19306\n",
      "A19307\n",
      "A19308\n",
      "A19309\n",
      "A19310\n",
      "A19311\n",
      "A19312\n",
      "A19313\n",
      "A19314\n",
      "A19315\n",
      "A19316\n",
      "A19317\n",
      "A19318\n",
      "A19319\n",
      "A19320\n",
      "A19321\n",
      "A19322\n",
      "A19323\n",
      "A19324\n",
      "A19325\n",
      "A19326\n",
      "A19328\n",
      "A19331\n",
      "A19332\n",
      "A19333\n",
      "A19334\n",
      "A19335\n",
      "A19336\n",
      "A19338\n",
      "A19339\n",
      "A19342\n",
      "A19343\n",
      "A19344\n",
      "A19345\n",
      "A19346\n",
      "A19347\n",
      "A19348\n",
      "A19349\n",
      "A19350\n",
      "A19351\n",
      "A19352\n",
      "A19353\n",
      "A19355\n",
      "A19356\n",
      "A19358\n",
      "A19359\n",
      "A19362\n",
      "A19363\n",
      "A19365\n",
      "A19366\n",
      "A19367\n",
      "A19369\n",
      "A19370\n",
      "A19371\n",
      "A19372\n",
      "A19373\n",
      "A19375\n",
      "A19376\n",
      "A19378\n",
      "A19379\n",
      "A19383\n",
      "A19384\n",
      "A19385\n",
      "A19386\n",
      "A19387\n",
      "A19388\n",
      "A19389\n",
      "A19390\n",
      "A19391\n",
      "A19392\n",
      "A19393\n",
      "A19394\n",
      "A19395\n",
      "A19396\n",
      "A19397\n",
      "A19398\n",
      "A19399\n",
      "A19400\n",
      "A19401\n",
      "A19403\n",
      "A19405\n",
      "A19406\n",
      "A19408\n",
      "A19409\n",
      "A19410\n",
      "A19411\n",
      "A19413\n",
      "A19414\n",
      "A19415\n",
      "A19416\n",
      "A19417\n",
      "A19418\n",
      "A19419\n",
      "A19421\n",
      "A19422\n",
      "A19423\n",
      "A19424\n",
      "A19425\n",
      "A19426\n",
      "A19427\n",
      "A19428\n",
      "A19429\n",
      "A19430\n",
      "A19431\n",
      "A19432\n",
      "A19433\n",
      "A19434\n",
      "A19435\n",
      "A19436\n",
      "A19437\n",
      "A19438\n",
      "A19439\n",
      "A19440\n",
      "A19441\n",
      "A19442\n",
      "A19443\n",
      "A19444\n",
      "A19445\n",
      "A19446\n",
      "A19447\n",
      "A19448\n",
      "A19449\n",
      "A19451\n",
      "A19452\n",
      "A19453\n",
      "A19454\n",
      "A19455\n",
      "A19456\n",
      "A19457\n",
      "A19458\n",
      "A19460\n",
      "A19462\n",
      "A19463\n",
      "A19464\n",
      "A19465\n",
      "A19467\n",
      "A19468\n",
      "A19469\n",
      "A19470\n",
      "A19471\n",
      "A19472\n",
      "A19473\n",
      "A19474\n",
      "A19475\n",
      "A19476\n",
      "A19478\n",
      "A19480\n",
      "A19481\n",
      "A19482\n",
      "A19483\n",
      "A19484\n",
      "A19485\n",
      "A19486\n",
      "A19487\n",
      "A19488\n",
      "A19489\n",
      "A19490\n",
      "A19491\n",
      "A19492\n",
      "A19493\n",
      "A19494\n",
      "A19495\n",
      "A19496\n",
      "A19497\n",
      "A19498\n",
      "A19499\n",
      "A19500\n",
      "A20001\n",
      "A20002\n",
      "A20003\n",
      "A20004\n",
      "A20005\n",
      "A20006\n",
      "A20007\n",
      "A20008\n",
      "A20009\n",
      "A20010\n",
      "A20011\n",
      "A20012\n",
      "A20013\n",
      "A20014\n",
      "A20015\n",
      "A20016\n",
      "A20018\n",
      "A20019\n",
      "A20021\n",
      "A20022\n",
      "A20023\n",
      "A20024\n",
      "A20025\n",
      "A20029\n",
      "A20030\n",
      "A20031\n",
      "A20032\n",
      "A20033\n",
      "A20034\n",
      "A20035\n",
      "A20036\n",
      "A20037\n",
      "A20038\n",
      "A20039\n",
      "A20040\n",
      "A20041\n",
      "A20042\n",
      "A20043\n",
      "A20045\n",
      "A20046\n",
      "A20048\n",
      "A20051\n",
      "A20052\n",
      "A20053\n",
      "A20054\n",
      "A20055\n",
      "A20056\n",
      "A20057\n",
      "A20058\n",
      "A20059\n",
      "A20060\n",
      "A20061\n",
      "A20062\n",
      "A20063\n",
      "A20064\n",
      "A20065\n",
      "A20066\n",
      "A20067\n",
      "A20068\n",
      "A20069\n",
      "A20070\n",
      "A20072\n",
      "A20073\n",
      "A20075\n",
      "A20076\n",
      "A20077\n",
      "A20078\n",
      "A20080\n",
      "A20081\n",
      "A20082\n",
      "A20083\n",
      "A20085\n",
      "A20086\n",
      "A20087\n",
      "A20088\n",
      "A20089\n",
      "A20090\n",
      "A20091\n",
      "A20092\n",
      "A20093\n",
      "A20095\n",
      "A20096\n",
      "A20097\n",
      "A20098\n",
      "A20099\n",
      "A20100\n",
      "A20101\n",
      "A20102\n",
      "A20104\n",
      "A20105\n",
      "A20106\n",
      "A20109\n",
      "A20110\n",
      "A20111\n",
      "A20112\n",
      "A20113\n",
      "A20114\n",
      "A20115\n",
      "A20116\n",
      "A20117\n",
      "A20118\n",
      "A20119\n",
      "A20120\n",
      "A20121\n",
      "A20122\n",
      "A20123\n",
      "A20124\n",
      "A20125\n",
      "A20126\n",
      "A20127\n",
      "A20129\n",
      "A20131\n",
      "A20132\n",
      "A20133\n",
      "A20134\n",
      "A20135\n",
      "A20137\n",
      "A20138\n",
      "A20139\n",
      "A20140\n",
      "A20142\n",
      "A20143\n",
      "A20144\n",
      "A20145\n",
      "A20146\n",
      "A20147\n",
      "A20148\n",
      "A20149\n",
      "A20150\n",
      "A20151\n",
      "A20152\n",
      "A20153\n",
      "A20154\n",
      "A20155\n",
      "A20156\n",
      "A20157\n",
      "A20158\n",
      "A20160\n",
      "A20161\n",
      "A20162\n",
      "A20163\n",
      "A20164\n",
      "A20165\n",
      "A20166\n",
      "A20167\n",
      "A20169\n",
      "A20170\n",
      "A20171\n",
      "A20172\n",
      "A20173\n",
      "A20174\n",
      "A20175\n",
      "A20177\n",
      "A20178\n",
      "A20179\n",
      "A20180\n",
      "A20182\n",
      "A20183\n",
      "A20186\n",
      "A20187\n",
      "A20188\n",
      "A20189\n",
      "A20190\n",
      "A20191\n",
      "A20192\n",
      "A20193\n",
      "A20196\n",
      "A20197\n",
      "A20198\n",
      "A20199\n",
      "A20200\n",
      "A20202\n",
      "A20204\n",
      "A20205\n",
      "A20207\n",
      "A20208\n",
      "A20209\n",
      "A20210\n",
      "A20211\n",
      "A20212\n",
      "A20213\n",
      "A20214\n",
      "A20215\n",
      "A20216\n",
      "A20217\n",
      "A20218\n",
      "A20220\n",
      "A20221\n",
      "A20223\n",
      "A20225\n",
      "A20227\n",
      "A20228\n",
      "A20229\n",
      "A20231\n",
      "A20232\n",
      "A20233\n",
      "A20234\n",
      "A20235\n",
      "A20236\n",
      "A20238\n",
      "A20239\n",
      "A20240\n",
      "A20241\n",
      "A20242\n",
      "A20243\n",
      "A20244\n",
      "A20245\n",
      "A20246\n",
      "A20247\n",
      "A20248\n",
      "A20249\n",
      "A20251\n",
      "A20252\n",
      "A20254\n",
      "A20255\n",
      "A20256\n",
      "A20257\n",
      "A20258\n",
      "A20259\n",
      "A20260\n",
      "A20261\n",
      "A20262\n",
      "A20264\n",
      "A20265\n",
      "A20266\n",
      "A20267\n",
      "A20269\n",
      "A20270\n",
      "A20272\n",
      "A20273\n",
      "A20274\n",
      "A20275\n",
      "A20276\n",
      "A20277\n",
      "A20278\n",
      "A20280\n",
      "A20281\n",
      "A20282\n",
      "A20283\n",
      "A20285\n",
      "A20287\n",
      "A20288\n",
      "A20289\n",
      "A20290\n",
      "A20291\n",
      "A20292\n",
      "A20293\n",
      "A20294\n",
      "A20296\n",
      "A20297\n",
      "A20298\n",
      "A20299\n",
      "A20300\n",
      "A20301\n",
      "A20302\n",
      "A20303\n",
      "A20304\n",
      "A20305\n",
      "A20306\n",
      "A20307\n",
      "A20308\n",
      "A20309\n",
      "A20310\n",
      "A20311\n",
      "A20312\n",
      "A20313\n",
      "A20314\n",
      "A20316\n",
      "A20317\n",
      "A20318\n",
      "A20319\n",
      "A20320\n",
      "A20321\n",
      "A20322\n",
      "A20323\n",
      "A20324\n",
      "A20325\n",
      "A20326\n",
      "A20327\n",
      "A20328\n",
      "A20329\n",
      "A20332\n",
      "A20333\n",
      "A20334\n",
      "A20335\n",
      "A20336\n",
      "A20337\n",
      "A20340\n",
      "A20341\n",
      "A20343\n",
      "A20344\n",
      "A20345\n",
      "A20346\n",
      "A20347\n",
      "A20351\n",
      "A20353\n",
      "A20354\n",
      "A20355\n",
      "A20356\n",
      "A20357\n",
      "A20358\n",
      "A20359\n",
      "A20360\n",
      "A20361\n",
      "A20363\n",
      "A20364\n",
      "A20365\n",
      "A20366\n",
      "A20367\n",
      "A20368\n",
      "A20369\n",
      "A20370\n",
      "A20371\n",
      "A20372\n",
      "A20373\n",
      "A20375\n",
      "A20376\n",
      "A20377\n",
      "A20378\n",
      "A20379\n",
      "A20380\n",
      "A20381\n",
      "A20382\n",
      "A20383\n",
      "A20384\n",
      "A20385\n",
      "A20388\n",
      "A20389\n",
      "A20391\n",
      "A20394\n",
      "A20395\n",
      "A20396\n",
      "A20397\n",
      "A20398\n",
      "A20400\n",
      "A20401\n",
      "A20402\n",
      "A20403\n",
      "A20404\n",
      "A20405\n",
      "A20406\n",
      "A20407\n",
      "A20408\n",
      "A20409\n",
      "A20410\n",
      "A20411\n",
      "A20412\n",
      "A20413\n",
      "A20414\n",
      "A20415\n",
      "A20416\n",
      "A20417\n",
      "A20419\n",
      "A20420\n",
      "A20422\n",
      "A20423\n",
      "A20424\n",
      "A20425\n",
      "A20426\n",
      "A20428\n",
      "A20429\n",
      "A20430\n",
      "A20431\n",
      "A20432\n",
      "A20433\n",
      "A20434\n",
      "A20436\n",
      "A20437\n",
      "A20438\n",
      "A20440\n",
      "A20442\n",
      "A20445\n",
      "A20446\n",
      "A20448\n",
      "A20449\n",
      "A20450\n",
      "A20451\n",
      "A20454\n",
      "A20455\n",
      "A20456\n",
      "A20457\n",
      "A20458\n",
      "A20459\n",
      "A20460\n",
      "A20463\n",
      "A20464\n",
      "A20465\n",
      "A20466\n",
      "A20468\n",
      "A20469\n",
      "A20470\n",
      "A20471\n",
      "A20472\n",
      "A20473\n",
      "A20474\n",
      "A20475\n",
      "A20476\n",
      "A20477\n",
      "A20478\n",
      "A20479\n",
      "A20482\n",
      "A20484\n",
      "A20485\n",
      "A20486\n",
      "A20487\n",
      "A20489\n",
      "A20491\n",
      "A20492\n",
      "A20493\n",
      "A20494\n",
      "A20495\n",
      "A20496\n",
      "A20497\n",
      "A20498\n",
      "A20499\n",
      "A20500\n",
      "A21001\n",
      "A21002\n",
      "A21003\n",
      "A21004\n",
      "A21005\n",
      "A21006\n",
      "A21008\n",
      "A21010\n",
      "A21011\n",
      "A21012\n",
      "A21015\n",
      "A21016\n",
      "A21017\n",
      "A21018\n",
      "A21020\n",
      "A21021\n",
      "A21022\n",
      "A21023\n",
      "A21025\n",
      "A21026\n",
      "A21027\n",
      "A21028\n",
      "A21029\n",
      "A21030\n",
      "A21031\n",
      "A21032\n",
      "A21033\n",
      "A21034\n",
      "A21036\n",
      "A21037\n",
      "A21038\n",
      "A21041\n",
      "A21042\n",
      "A21043\n",
      "A21044\n",
      "A21045\n",
      "A21046\n",
      "A21047\n",
      "A21048\n",
      "A21049\n",
      "A21050\n",
      "A21051\n",
      "A21052\n",
      "A21053\n",
      "A21054\n",
      "A21055\n",
      "A21057\n",
      "A21059\n",
      "A21060\n",
      "A21061\n",
      "A21062\n",
      "A21063\n",
      "A21064\n",
      "A21065\n",
      "A21066\n",
      "A21067\n",
      "A21068\n",
      "A21069\n",
      "A21070\n",
      "A21071\n",
      "A21072\n",
      "A21076\n",
      "A21077\n",
      "A21078\n",
      "A21079\n",
      "A21080\n",
      "A21081\n",
      "A21082\n",
      "A21083\n",
      "A21085\n",
      "A21086\n",
      "A21087\n",
      "A21089\n",
      "A21090\n",
      "A21092\n",
      "A21093\n",
      "A21095\n",
      "A21096\n",
      "A21097\n",
      "A21098\n",
      "A21099\n",
      "A21100\n",
      "A21101\n",
      "A21102\n",
      "A21103\n",
      "A21104\n",
      "A21105\n",
      "A21106\n",
      "A21107\n",
      "A21108\n",
      "A21109\n",
      "A21110\n",
      "A21111\n",
      "A21112\n",
      "A21113\n",
      "A21114\n",
      "A21115\n",
      "A21116\n",
      "A21117\n",
      "A21118\n",
      "A21120\n",
      "A21121\n",
      "A21122\n",
      "A21123\n",
      "A21124\n",
      "A21125\n",
      "A21126\n",
      "A21128\n",
      "A21129\n",
      "A21130\n",
      "A21131\n",
      "A21132\n",
      "A21133\n",
      "A21134\n",
      "A21136\n",
      "A21137\n",
      "A21138\n",
      "A21139\n",
      "A21140\n",
      "A21141\n",
      "A21142\n",
      "A21143\n",
      "A21144\n",
      "A21145\n",
      "A21146\n",
      "A21149\n",
      "A21151\n",
      "A21152\n",
      "A21153\n",
      "A21154\n",
      "A21155\n",
      "A21157\n",
      "A21158\n",
      "A21161\n",
      "A21162\n",
      "A21164\n",
      "A21165\n",
      "A21166\n",
      "A21167\n",
      "A21168\n",
      "A21169\n",
      "A21170\n",
      "A21171\n",
      "A21173\n",
      "A21174\n",
      "A21176\n",
      "A21179\n",
      "A21180\n",
      "A21181\n",
      "A21182\n",
      "A21183\n",
      "A21184\n",
      "A21185\n",
      "A21186\n",
      "A21187\n",
      "A21188\n",
      "A21189\n",
      "A21190\n",
      "A21192\n",
      "A21193\n",
      "A21194\n",
      "A21195\n",
      "A21197\n",
      "A21199\n",
      "A21200\n",
      "A21202\n",
      "A21203\n",
      "A21204\n",
      "A21205\n",
      "A21206\n",
      "A21207\n",
      "A21208\n",
      "A21209\n",
      "A21210\n",
      "A21211\n",
      "A21212\n",
      "A21213\n",
      "A21214\n",
      "A21215\n",
      "A21216\n",
      "A21218\n",
      "A21219\n",
      "A21220\n",
      "A21221\n",
      "A21222\n",
      "A21223\n",
      "A21224\n",
      "A21225\n",
      "A21226\n",
      "A21227\n",
      "A21228\n",
      "A21229\n",
      "A21230\n",
      "A21231\n",
      "A21233\n",
      "A21234\n",
      "A21235\n",
      "A21236\n",
      "A21237\n",
      "A21238\n",
      "A21239\n",
      "A21240\n",
      "A21241\n",
      "A21242\n",
      "A21244\n",
      "A21246\n",
      "A21247\n",
      "A21248\n",
      "A21249\n",
      "A21250\n",
      "A21251\n",
      "A21252\n",
      "A21253\n",
      "A21254\n",
      "A21255\n",
      "A21256\n",
      "A21257\n",
      "A21258\n",
      "A21259\n",
      "A21260\n",
      "A21261\n",
      "A21262\n",
      "A21263\n",
      "A21264\n",
      "A21265\n",
      "A21266\n",
      "A21267\n",
      "A21268\n",
      "A21271\n",
      "A21272\n",
      "A21273\n",
      "A21275\n",
      "A21276\n",
      "A21277\n",
      "A21278\n",
      "A21279\n",
      "A21280\n",
      "A21281\n",
      "A21283\n",
      "A21284\n",
      "A21285\n",
      "A21286\n",
      "A21287\n",
      "A21288\n",
      "A21289\n",
      "A21290\n",
      "A21291\n",
      "A21292\n",
      "A21294\n",
      "A21295\n",
      "A21296\n",
      "A21297\n",
      "A21299\n",
      "A21301\n",
      "A21302\n",
      "A21303\n",
      "A21306\n",
      "A21307\n",
      "A21308\n",
      "A21309\n",
      "A21310\n",
      "A21311\n",
      "A21312\n",
      "A21313\n",
      "A21316\n",
      "A21317\n",
      "A21318\n",
      "A21319\n",
      "A21320\n",
      "A21321\n",
      "A21322\n",
      "A21323\n",
      "A21324\n",
      "A21326\n",
      "A21327\n",
      "A21328\n",
      "A21329\n",
      "A21330\n",
      "A21331\n",
      "A21335\n",
      "A21336\n",
      "A21337\n",
      "A21338\n",
      "A21339\n",
      "A21340\n",
      "A21341\n",
      "A21342\n",
      "A21343\n",
      "A21344\n",
      "A21345\n",
      "A21347\n",
      "A21348\n",
      "A21349\n",
      "A21350\n",
      "A21351\n",
      "A21352\n",
      "A21353\n",
      "A21354\n",
      "A21356\n",
      "A21357\n",
      "A21358\n",
      "A21359\n",
      "A21360\n",
      "A21361\n",
      "A21362\n",
      "A21363\n",
      "A21365\n",
      "A21367\n",
      "A21368\n",
      "A21369\n",
      "A21370\n",
      "A21371\n",
      "A21372\n",
      "A21373\n",
      "A21374\n",
      "A21375\n",
      "A21377\n",
      "A21378\n",
      "A21379\n",
      "A21382\n",
      "A21383\n",
      "A21385\n",
      "A21386\n",
      "A21388\n",
      "A21389\n",
      "A21390\n",
      "A21391\n",
      "A21392\n",
      "A21393\n",
      "A21394\n",
      "A21396\n",
      "A21397\n",
      "A21398\n",
      "A21399\n",
      "A21401\n",
      "A21402\n",
      "A21403\n",
      "A21404\n",
      "A21405\n",
      "A21406\n",
      "A21407\n",
      "A21408\n",
      "A21409\n",
      "A21410\n",
      "A21411\n",
      "A21412\n",
      "A21414\n",
      "A21416\n",
      "A21417\n",
      "A21418\n",
      "A21419\n",
      "A21420\n",
      "A21421\n",
      "A21422\n",
      "A21423\n",
      "A21425\n",
      "A21426\n",
      "A21428\n",
      "A21429\n",
      "A21430\n",
      "A21432\n",
      "A21433\n",
      "A21434\n",
      "A21435\n",
      "A21436\n",
      "A21437\n",
      "A21438\n",
      "A21439\n",
      "A21440\n",
      "A21441\n",
      "A21442\n",
      "A21443\n",
      "A21445\n",
      "A21446\n",
      "A21447\n",
      "A21449\n",
      "A21450\n",
      "A21451\n",
      "A21452\n",
      "A21453\n",
      "A21454\n",
      "A21455\n",
      "A21456\n",
      "A21457\n",
      "A21458\n",
      "A21461\n",
      "A21462\n",
      "A21464\n",
      "A21465\n",
      "A21466\n",
      "A21467\n",
      "A21468\n",
      "A21469\n",
      "A21470\n",
      "A21471\n",
      "A21473\n",
      "A21474\n",
      "A21475\n",
      "A21476\n",
      "A21478\n",
      "A21480\n",
      "A21481\n",
      "A21482\n",
      "A21483\n",
      "A21484\n",
      "A21485\n",
      "A21486\n",
      "A21487\n",
      "A21488\n",
      "A21489\n",
      "A21490\n",
      "A21491\n",
      "A21492\n",
      "A21493\n",
      "A21494\n",
      "A21495\n",
      "A21496\n",
      "A21497\n",
      "A21498\n",
      "A21499\n",
      "A21500\n",
      "A22001\n",
      "A22002\n",
      "A22003\n",
      "A22004\n",
      "A22005\n",
      "A22006\n",
      "A22007\n",
      "A22008\n",
      "A22009\n",
      "A22010\n",
      "A22011\n",
      "A22017\n",
      "A22018\n",
      "A22019\n",
      "A22020\n",
      "A22021\n",
      "A22022\n",
      "A22024\n",
      "A22025\n",
      "A22026\n",
      "A22027\n",
      "A22028\n",
      "A22029\n",
      "A22030\n",
      "A22031\n",
      "A22032\n",
      "A22033\n",
      "A22034\n",
      "A22036\n",
      "A22038\n",
      "A22039\n",
      "A22040\n",
      "A22041\n",
      "A22044\n",
      "A22045\n",
      "A22046\n",
      "A22047\n",
      "A22048\n",
      "A22049\n",
      "A22052\n",
      "A22053\n",
      "A22054\n",
      "A22055\n",
      "A22056\n",
      "A22057\n",
      "A22058\n",
      "A22059\n",
      "A22060\n",
      "A22062\n",
      "A22063\n",
      "A22064\n",
      "A22065\n",
      "A22066\n",
      "A22067\n",
      "A22068\n",
      "A22069\n",
      "A22070\n",
      "A22071\n",
      "A22072\n",
      "A22073\n",
      "A22074\n",
      "A22075\n",
      "A22076\n",
      "A22077\n",
      "A22078\n",
      "A22079\n",
      "A22081\n",
      "A22082\n",
      "A22083\n",
      "A22085\n",
      "A22086\n",
      "A22087\n",
      "A22088\n",
      "A22089\n",
      "A22090\n",
      "A22091\n",
      "A22092\n",
      "A22095\n",
      "A22096\n",
      "A22098\n",
      "A22099\n",
      "A22100\n",
      "A22101\n",
      "A22102\n",
      "A22103\n",
      "A22104\n",
      "A22105\n",
      "A22107\n",
      "A22108\n",
      "A22109\n",
      "A22110\n",
      "A22111\n",
      "A22112\n",
      "A22114\n",
      "A22115\n",
      "A22116\n",
      "A22117\n",
      "A22118\n",
      "A22119\n",
      "A22120\n",
      "A22121\n",
      "A22122\n",
      "A22123\n",
      "A22124\n",
      "A22125\n",
      "A22126\n",
      "A22127\n",
      "A22128\n",
      "A22130\n",
      "A22131\n",
      "A22132\n",
      "A22133\n",
      "A22134\n",
      "A22135\n",
      "A22136\n",
      "A22137\n",
      "A22138\n",
      "A22140\n",
      "A22141\n",
      "A22142\n",
      "A22143\n",
      "A22145\n",
      "A22146\n",
      "A22147\n",
      "A22149\n",
      "A22150\n",
      "A22151\n",
      "A22152\n",
      "A22153\n",
      "A22154\n",
      "A22155\n",
      "A22157\n",
      "A22158\n",
      "A22161\n",
      "A22163\n",
      "A22166\n",
      "A22167\n",
      "A22168\n",
      "A22171\n",
      "A22172\n",
      "A22173\n",
      "A22174\n",
      "A22175\n",
      "A22178\n",
      "A22179\n",
      "A22181\n",
      "A22182\n",
      "A22183\n",
      "A22184\n",
      "A22185\n",
      "A22186\n",
      "A22187\n",
      "A22188\n",
      "A22189\n",
      "A22190\n",
      "A22191\n",
      "A22192\n",
      "A22193\n",
      "A22194\n",
      "A22195\n",
      "A22196\n",
      "A22197\n",
      "A22198\n",
      "A22199\n",
      "A22202\n",
      "A22203\n",
      "A22204\n",
      "A22205\n",
      "A22206\n",
      "A22207\n",
      "A22208\n",
      "A22209\n",
      "A22210\n",
      "A22211\n",
      "A22212\n",
      "A22213\n",
      "A22214\n",
      "A22215\n",
      "A22216\n",
      "A22217\n",
      "A22218\n",
      "A22219\n",
      "A22220\n",
      "A22221\n",
      "A22222\n",
      "A22223\n",
      "A22224\n",
      "A22225\n",
      "A22226\n",
      "A22227\n",
      "A22229\n",
      "A22230\n",
      "A22231\n",
      "A22233\n",
      "A22235\n",
      "A22237\n",
      "A22238\n",
      "A22239\n",
      "A22240\n",
      "A22242\n",
      "A22243\n",
      "A22244\n",
      "A22245\n",
      "A22246\n",
      "A22247\n",
      "A22248\n",
      "A22249\n",
      "A22250\n",
      "A22252\n",
      "A22253\n",
      "A22254\n",
      "A22255\n",
      "A22256\n",
      "A22257\n",
      "A22258\n",
      "A22260\n",
      "A22261\n",
      "A22262\n",
      "A22263\n",
      "A22264\n",
      "A22265\n",
      "A22266\n",
      "A22267\n",
      "A22268\n",
      "A22269\n",
      "A22270\n",
      "A22272\n",
      "A22273\n",
      "A22274\n",
      "A22275\n",
      "A22276\n",
      "A22277\n",
      "A22278\n",
      "A22279\n",
      "A22281\n",
      "A22282\n",
      "A22283\n",
      "A22284\n",
      "A22285\n",
      "A22286\n",
      "A22287\n",
      "A22288\n",
      "A22289\n",
      "A22290\n",
      "A22291\n",
      "A22292\n",
      "A22293\n",
      "A22294\n",
      "A22295\n",
      "A22297\n",
      "A22298\n",
      "A22299\n",
      "A22300\n",
      "A22301\n",
      "A22302\n",
      "A22304\n",
      "A22305\n",
      "A22306\n",
      "A22307\n",
      "A22308\n",
      "A22309\n",
      "A22310\n",
      "A22311\n",
      "A22312\n",
      "A22313\n",
      "A22314\n",
      "A22315\n",
      "A22316\n",
      "A22317\n",
      "A22318\n",
      "A22319\n",
      "A22321\n",
      "A22323\n",
      "A22324\n",
      "A22325\n",
      "A22326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A22327\n",
      "A22328\n",
      "A22329\n",
      "A22330\n",
      "A22331\n",
      "A22332\n",
      "A22335\n",
      "A22336\n",
      "A22337\n",
      "A22338\n",
      "A22339\n",
      "A22340\n",
      "A22341\n",
      "A22342\n",
      "A22343\n",
      "A22345\n",
      "A22347\n",
      "A22348\n",
      "A22349\n",
      "A22350\n",
      "A22351\n",
      "A22353\n",
      "A22354\n",
      "A22355\n",
      "A22356\n",
      "A22357\n",
      "A22358\n",
      "A22359\n",
      "A22360\n",
      "A22361\n",
      "A22362\n",
      "A22363\n",
      "A22364\n",
      "A22365\n",
      "A22367\n",
      "A22368\n",
      "A22370\n",
      "A22371\n",
      "A22372\n",
      "A22374\n",
      "A22375\n",
      "A22376\n",
      "A22377\n",
      "A22378\n",
      "A22379\n",
      "A22380\n",
      "A22381\n",
      "A22382\n",
      "A22383\n",
      "A22384\n",
      "A22385\n",
      "A22386\n",
      "A22387\n",
      "A22388\n",
      "A22389\n",
      "A22390\n",
      "A22391\n",
      "A22392\n",
      "A22393\n",
      "A22394\n",
      "A22396\n",
      "A22397\n",
      "A22398\n",
      "A22400\n",
      "A22401\n",
      "A22402\n",
      "A22404\n",
      "A22405\n",
      "A22408\n",
      "A22409\n",
      "A22410\n",
      "A22411\n",
      "A22412\n",
      "A22413\n",
      "A22414\n",
      "A22415\n",
      "A22416\n",
      "A22417\n",
      "A22418\n",
      "A22419\n",
      "A22420\n",
      "A22421\n",
      "A22423\n",
      "A22424\n",
      "A22425\n",
      "A22426\n",
      "A22427\n",
      "A22428\n",
      "A22429\n",
      "A22430\n",
      "A22431\n",
      "A22432\n",
      "A22433\n",
      "A22434\n",
      "A22435\n",
      "A22436\n",
      "A22437\n",
      "A22439\n",
      "A22440\n",
      "A22443\n",
      "A22444\n",
      "A22445\n",
      "A22446\n",
      "A22447\n",
      "A22448\n",
      "A22449\n",
      "A22450\n",
      "A22453\n",
      "A22455\n",
      "A22457\n",
      "A22458\n",
      "A22459\n",
      "A22460\n",
      "A22461\n",
      "A22463\n",
      "A22464\n",
      "A22467\n",
      "A22468\n",
      "A22469\n",
      "A22470\n",
      "A22471\n",
      "A22472\n",
      "A22473\n",
      "A22474\n",
      "A22475\n",
      "A22477\n",
      "A22480\n",
      "A22481\n",
      "A22482\n",
      "A22484\n",
      "A22485\n",
      "A22486\n",
      "A22487\n",
      "A22488\n",
      "A22489\n",
      "A22490\n",
      "A22491\n",
      "A22492\n",
      "A22493\n",
      "A22494\n",
      "A22495\n",
      "A22496\n",
      "A22497\n",
      "A22498\n",
      "A22499\n",
      "A22500\n",
      "A23001\n",
      "A23002\n",
      "A23003\n",
      "A23004\n",
      "A23005\n",
      "A23006\n",
      "A23008\n",
      "A23009\n",
      "A23010\n",
      "A23011\n",
      "A23012\n",
      "A23013\n",
      "A23014\n",
      "A23015\n",
      "A23016\n",
      "A23017\n",
      "A23018\n",
      "A23019\n",
      "A23023\n",
      "A23024\n",
      "A23025\n",
      "A23026\n",
      "A23027\n",
      "A23028\n",
      "A23029\n",
      "A23030\n",
      "A23031\n",
      "A23032\n",
      "A23033\n",
      "A23034\n",
      "A23035\n",
      "A23036\n",
      "A23037\n",
      "A23039\n",
      "A23040\n",
      "A23041\n",
      "A23043\n",
      "A23044\n",
      "A23045\n",
      "A23046\n",
      "A23047\n",
      "A23048\n",
      "A23050\n",
      "A23051\n",
      "A23052\n",
      "A23053\n",
      "A23054\n",
      "A23055\n",
      "A23056\n",
      "A23058\n",
      "A23060\n",
      "A23061\n",
      "A23062\n",
      "A23063\n",
      "A23064\n",
      "A23065\n",
      "A23066\n",
      "A23067\n",
      "A23068\n",
      "A23069\n",
      "A23070\n",
      "A23071\n",
      "A23072\n",
      "A23074\n",
      "A23076\n",
      "A23077\n",
      "A23078\n",
      "A23079\n",
      "A23080\n",
      "A23081\n",
      "A23082\n",
      "A23083\n",
      "A23084\n",
      "A23085\n",
      "A23086\n",
      "A23087\n",
      "A23088\n",
      "A23090\n",
      "A23091\n",
      "A23092\n",
      "A23093\n",
      "A23094\n",
      "A23095\n",
      "A23096\n",
      "A23097\n",
      "A23098\n",
      "A23099\n",
      "A23100\n",
      "A23101\n",
      "A23102\n",
      "A23103\n",
      "A23104\n",
      "A23105\n",
      "A23107\n",
      "A23108\n",
      "A23110\n",
      "A23113\n",
      "A23114\n",
      "A23115\n",
      "A23117\n",
      "A23120\n",
      "A23121\n",
      "A23122\n",
      "A23123\n",
      "A23124\n",
      "A23125\n",
      "A23126\n",
      "A23127\n",
      "A23128\n",
      "A23129\n",
      "A23130\n",
      "A23131\n",
      "A23132\n",
      "A23133\n",
      "A23134\n",
      "A23135\n",
      "A23136\n",
      "A23137\n",
      "A23138\n",
      "A23139\n",
      "A23142\n",
      "A23144\n",
      "A23145\n",
      "A23146\n",
      "A23147\n",
      "A23148\n",
      "A23149\n",
      "A23150\n",
      "A23151\n",
      "A23152\n",
      "A23153\n",
      "A23154\n",
      "A23155\n",
      "A23156\n",
      "A23157\n",
      "A23158\n",
      "A23159\n",
      "A23160\n",
      "A23161\n",
      "A23164\n",
      "A23165\n",
      "A23166\n",
      "A23167\n",
      "A23168\n",
      "A23169\n",
      "A23170\n",
      "A23172\n",
      "A23173\n",
      "A23175\n",
      "A23177\n",
      "A23178\n",
      "A23180\n",
      "A23181\n",
      "A23182\n",
      "A23183\n",
      "A23184\n",
      "A23185\n",
      "A23186\n",
      "A23187\n",
      "A23188\n",
      "A23190\n",
      "A23192\n",
      "A23193\n",
      "A23194\n",
      "A23195\n",
      "A23196\n",
      "A23197\n",
      "A23198\n",
      "A23199\n",
      "A23200\n",
      "A23202\n",
      "A23203\n",
      "A23204\n",
      "A23205\n",
      "A23206\n",
      "A23208\n",
      "A23209\n",
      "A23212\n",
      "A23213\n",
      "A23214\n",
      "A23215\n",
      "A23216\n",
      "A23217\n",
      "A23218\n",
      "A23220\n",
      "A23221\n",
      "A23223\n",
      "A23224\n",
      "A23226\n",
      "A23227\n",
      "A23228\n",
      "A23229\n",
      "A23230\n",
      "A23231\n",
      "A23232\n",
      "A23233\n",
      "A23234\n",
      "A23235\n",
      "A23236\n",
      "A23237\n",
      "A23238\n",
      "A23239\n",
      "A23242\n",
      "A23243\n",
      "A23246\n",
      "A23247\n",
      "A23248\n",
      "A23250\n",
      "A23252\n",
      "A23254\n",
      "A23255\n",
      "A23256\n",
      "A23257\n",
      "A23258\n",
      "A23259\n",
      "A23260\n",
      "A23261\n",
      "A23262\n",
      "A23263\n",
      "A23264\n",
      "A23265\n",
      "A23266\n",
      "A23268\n",
      "A23270\n",
      "A23271\n",
      "A23272\n",
      "A23273\n",
      "A23274\n",
      "A23275\n",
      "A23276\n",
      "A23277\n",
      "A23278\n",
      "A23279\n",
      "A23280\n",
      "A23281\n",
      "A23282\n",
      "A23283\n",
      "A23284\n",
      "A23285\n",
      "A23286\n",
      "A23287\n",
      "A23288\n",
      "A23289\n",
      "A23290\n",
      "A23291\n",
      "A23292\n",
      "A23293\n",
      "A23294\n",
      "A23295\n",
      "A23296\n",
      "A23297\n",
      "A23298\n",
      "A23300\n",
      "A23301\n",
      "A23303\n",
      "A23305\n",
      "A23306\n",
      "A23307\n",
      "A23308\n",
      "A23309\n",
      "A23310\n",
      "A23311\n",
      "A23312\n",
      "A23313\n",
      "A23314\n",
      "A23315\n",
      "A23317\n",
      "A23318\n",
      "A23319\n",
      "A23320\n",
      "A23322\n",
      "A23323\n",
      "A23324\n",
      "A23326\n",
      "A23327\n",
      "A23328\n",
      "A23329\n",
      "A23330\n",
      "A23332\n",
      "A23333\n",
      "A23334\n",
      "A23335\n",
      "A23336\n",
      "A23337\n",
      "A23338\n",
      "A23339\n",
      "A23340\n",
      "A23342\n",
      "A23343\n",
      "A23345\n",
      "A23346\n",
      "A23347\n",
      "A23348\n",
      "A23349\n",
      "A23350\n",
      "A23351\n",
      "A23352\n",
      "A23353\n",
      "A23354\n",
      "A23357\n",
      "A23358\n",
      "A23359\n",
      "A23360\n",
      "A23362\n",
      "A23363\n",
      "A23364\n",
      "A23365\n",
      "A23366\n",
      "A23367\n",
      "A23368\n",
      "A23369\n",
      "A23372\n",
      "A23373\n",
      "A23374\n",
      "A23375\n",
      "A23376\n",
      "A23377\n",
      "A23379\n",
      "A23380\n",
      "A23381\n",
      "A23382\n",
      "A23383\n",
      "A23384\n",
      "A23385\n",
      "A23386\n",
      "A23387\n",
      "A23389\n",
      "A23390\n",
      "A23391\n",
      "A23392\n",
      "A23393\n",
      "A23394\n",
      "A23396\n",
      "A23397\n",
      "A23398\n",
      "A23399\n",
      "A23400\n",
      "A23401\n",
      "A23402\n",
      "A23403\n",
      "A23404\n",
      "A23405\n",
      "A23406\n",
      "A23407\n",
      "A23409\n",
      "A23410\n",
      "A23411\n",
      "A23412\n",
      "A23413\n",
      "A23414\n",
      "A23415\n",
      "A23416\n",
      "A23417\n",
      "A23418\n",
      "A23419\n",
      "A23421\n",
      "A23422\n",
      "A23425\n",
      "A23426\n",
      "A23427\n",
      "A23429\n",
      "A23430\n",
      "A23431\n",
      "A23432\n",
      "A23433\n",
      "A23435\n",
      "A23436\n",
      "A23437\n",
      "A23438\n",
      "A23439\n",
      "A23440\n",
      "A23441\n",
      "A23442\n",
      "A23443\n",
      "A23444\n",
      "A23445\n",
      "A23446\n",
      "A23447\n",
      "A23448\n",
      "A23449\n",
      "A23450\n",
      "A23451\n",
      "A23453\n",
      "A23454\n",
      "A23455\n",
      "A23456\n",
      "A23458\n",
      "A23459\n",
      "A23460\n",
      "A23461\n",
      "A23462\n",
      "A23463\n",
      "A23465\n",
      "A23466\n",
      "A23467\n",
      "A23468\n",
      "A23470\n",
      "A23471\n",
      "A23472\n",
      "A23473\n",
      "A23474\n",
      "A23475\n",
      "A23476\n",
      "A23477\n",
      "A23478\n",
      "A23479\n",
      "A23481\n",
      "A23482\n",
      "A23483\n",
      "A23484\n",
      "A23485\n",
      "A23486\n",
      "A23488\n",
      "A23489\n",
      "A23490\n",
      "A23491\n",
      "A23492\n",
      "A23493\n",
      "A23494\n",
      "A23495\n",
      "A23496\n",
      "A23497\n",
      "A23498\n",
      "A23499\n",
      "A23500\n",
      "A24001\n",
      "A24002\n",
      "A24003\n",
      "A24004\n",
      "A24005\n",
      "A24006\n",
      "A24007\n",
      "A24008\n",
      "A24009\n",
      "A24011\n",
      "A24013\n",
      "A24014\n",
      "A24016\n",
      "A24018\n",
      "A24019\n",
      "A24020\n",
      "A24021\n",
      "A24022\n",
      "A24023\n",
      "A24024\n",
      "A24025\n",
      "A24026\n",
      "A24027\n",
      "A24029\n",
      "A24030\n",
      "A24031\n",
      "A24032\n",
      "A24033\n",
      "A24034\n",
      "A24035\n",
      "A24036\n",
      "A24037\n",
      "A24038\n",
      "A24039\n",
      "A24040\n",
      "A24041\n",
      "A24042\n",
      "A24043\n",
      "A24044\n",
      "A24045\n",
      "A24046\n",
      "A24047\n",
      "A24049\n",
      "A24050\n",
      "A24051\n",
      "A24052\n",
      "A24053\n",
      "A24054\n",
      "A24055\n",
      "A24056\n",
      "A24057\n",
      "A24058\n",
      "A24059\n",
      "A24062\n",
      "A24063\n",
      "A24064\n",
      "A24065\n",
      "A24066\n",
      "A24067\n",
      "A24068\n",
      "A24069\n",
      "A24070\n",
      "A24071\n",
      "A24073\n",
      "A24074\n",
      "A24075\n",
      "A24077\n",
      "A24078\n",
      "A24079\n",
      "A24080\n",
      "A24081\n",
      "A24082\n",
      "A24083\n",
      "A24084\n",
      "A24085\n",
      "A24086\n",
      "A24087\n",
      "A24088\n",
      "A24089\n",
      "A24091\n",
      "A24092\n",
      "A24093\n",
      "A24094\n",
      "A24095\n",
      "A24096\n",
      "A24097\n",
      "A24098\n",
      "A24099\n",
      "A24100\n",
      "A24101\n",
      "A24102\n",
      "A24103\n",
      "A24104\n",
      "A24105\n",
      "A24106\n",
      "A24108\n",
      "A24109\n",
      "A24110\n",
      "A24112\n",
      "A24113\n",
      "A24114\n",
      "A24115\n",
      "A24117\n",
      "A24118\n",
      "A24119\n",
      "A24120\n",
      "A24121\n",
      "A24122\n",
      "A24123\n",
      "A24124\n",
      "A24126\n",
      "A24127\n",
      "A24128\n",
      "A24129\n",
      "A24130\n",
      "A24131\n",
      "A24132\n",
      "A24133\n",
      "A24134\n",
      "A24135\n",
      "A24136\n",
      "A24138\n",
      "A24139\n",
      "A24140\n",
      "A24142\n",
      "A24143\n",
      "A24145\n",
      "A24146\n",
      "A24147\n",
      "A24148\n",
      "A24149\n",
      "A24150\n",
      "A24151\n",
      "A24153\n",
      "A24154\n",
      "A24156\n",
      "A24157\n",
      "A24158\n",
      "A24160\n",
      "A24162\n",
      "A24163\n",
      "A24164\n",
      "A24165\n",
      "A24167\n",
      "A24168\n",
      "A24169\n",
      "A24171\n",
      "A24172\n",
      "A24173\n",
      "A24174\n",
      "A24175\n",
      "A24176\n",
      "A24177\n",
      "A24178\n",
      "A24179\n",
      "A24180\n",
      "A24182\n",
      "A24183\n",
      "A24184\n",
      "A24185\n",
      "A24186\n",
      "A24187\n",
      "A24188\n",
      "A24189\n",
      "A24190\n",
      "A24191\n",
      "A24192\n",
      "A24193\n",
      "A24194\n",
      "A24195\n",
      "A24196\n",
      "A24197\n",
      "A24198\n",
      "A24199\n",
      "A24200\n",
      "A24201\n",
      "A24202\n",
      "A24204\n",
      "A24205\n",
      "A24206\n",
      "A24207\n",
      "A24209\n",
      "A24210\n",
      "A24211\n",
      "A24213\n",
      "A24214\n",
      "A24215\n",
      "A24216\n",
      "A24217\n",
      "A24218\n",
      "A24219\n",
      "A24220\n",
      "A24221\n",
      "A24222\n",
      "A24223\n",
      "A24224\n",
      "A24225\n",
      "A24226\n",
      "A24227\n",
      "A24228\n",
      "A24229\n",
      "A24230\n",
      "A24231\n",
      "A24232\n",
      "A24234\n",
      "A24235\n",
      "A24236\n",
      "A24237\n",
      "A24238\n",
      "A24240\n",
      "A24241\n",
      "A24243\n",
      "A24244\n",
      "A24245\n",
      "A24247\n",
      "A24249\n",
      "A24250\n",
      "A24251\n",
      "A24252\n",
      "A24253\n",
      "A24254\n",
      "A24255\n",
      "A24257\n",
      "A24258\n",
      "A24260\n",
      "A24261\n",
      "A24262\n",
      "A24263\n",
      "A24264\n",
      "A24265\n",
      "A24266\n",
      "A24267\n",
      "A24269\n",
      "A24270\n",
      "A24271\n",
      "A24273\n",
      "A24274\n",
      "A24277\n",
      "A24278\n",
      "A24279\n",
      "A24280\n",
      "A24283\n",
      "A24285\n",
      "A24286\n",
      "A24287\n",
      "A24288\n",
      "A24289\n",
      "A24290\n",
      "A24291\n",
      "A24292\n",
      "A24293\n",
      "A24294\n",
      "A24295\n",
      "A24297\n",
      "A24298\n",
      "A24300\n",
      "A24301\n",
      "A24302\n",
      "A24304\n",
      "A24305\n",
      "A24306\n",
      "A24307\n",
      "A24308\n",
      "A24309\n",
      "A24311\n",
      "A24314\n",
      "A24315\n",
      "A24316\n",
      "A24318\n",
      "A24320\n",
      "A24321\n",
      "A24322\n",
      "A24324\n",
      "A24326\n",
      "A24327\n",
      "A24328\n",
      "A24329\n",
      "A24330\n",
      "A24331\n",
      "A24332\n",
      "A24333\n",
      "A24334\n",
      "A24335\n",
      "A24336\n",
      "A24338\n",
      "A24339\n",
      "A24340\n",
      "A24341\n",
      "A24343\n",
      "A24344\n",
      "A24345\n",
      "A24346\n",
      "A24349\n",
      "A24350\n",
      "A24352\n",
      "A24353\n",
      "A24354\n",
      "A24356\n",
      "A24357\n",
      "A24358\n",
      "A24359\n",
      "A24362\n",
      "A24363\n",
      "A24364\n",
      "A24365\n",
      "A24366\n",
      "A24367\n",
      "A24368\n",
      "A24369\n",
      "A24370\n",
      "A24371\n",
      "A24372\n",
      "A24373\n",
      "A24374\n",
      "A24375\n",
      "A24378\n",
      "A24379\n",
      "A24380\n",
      "A24381\n",
      "A24382\n",
      "A24383\n",
      "A24384\n",
      "A24385\n",
      "A24386\n",
      "A24387\n",
      "A24390\n",
      "A24391\n",
      "A24392\n",
      "A24393\n",
      "A24395\n",
      "A24396\n",
      "A24397\n",
      "A24398\n",
      "A24399\n",
      "A24400\n",
      "A24401\n",
      "A24402\n",
      "A24403\n",
      "A24404\n",
      "A24405\n",
      "A24406\n",
      "A24407\n",
      "A24408\n",
      "A24409\n",
      "A24410\n",
      "A24411\n",
      "A24412\n",
      "A24414\n",
      "A24415\n",
      "A24416\n",
      "A24418\n",
      "A24419\n",
      "A24420\n",
      "A24421\n",
      "A24423\n",
      "A24424\n",
      "A24425\n",
      "A24426\n",
      "A24427\n",
      "A24430\n",
      "A24431\n",
      "A24432\n",
      "A24434\n",
      "A24435\n",
      "A24436\n",
      "A24437\n",
      "A24438\n",
      "A24439\n",
      "A24441\n",
      "A24442\n",
      "A24443\n",
      "A24444\n",
      "A24445\n",
      "A24446\n",
      "A24447\n",
      "A24448\n",
      "A24451\n",
      "A24452\n",
      "A24453\n",
      "A24454\n",
      "A24455\n",
      "A24456\n",
      "A24457\n",
      "A24458\n",
      "A24460\n",
      "A24461\n",
      "A24462\n",
      "A24463\n",
      "A24464\n",
      "A24465\n",
      "A24466\n",
      "A24467\n",
      "A24468\n",
      "A24469\n",
      "A24470\n",
      "A24472\n",
      "A24474\n",
      "A24475\n",
      "A24477\n",
      "A24478\n",
      "A24479\n",
      "A24480\n",
      "A24481\n",
      "A24482\n",
      "A24483\n",
      "A24485\n",
      "A24486\n",
      "A24487\n",
      "A24488\n",
      "A24489\n",
      "A24490\n",
      "A24491\n",
      "A24492\n",
      "A24493\n",
      "A24494\n",
      "A24496\n",
      "A24497\n",
      "A24498\n",
      "A24499\n",
      "A25001\n",
      "A25002\n",
      "A25003\n",
      "A25004\n",
      "A25005\n",
      "A25006\n",
      "A25007\n",
      "A25008\n",
      "A25010\n",
      "A25011\n",
      "A25012\n",
      "A25014\n",
      "A25015\n",
      "A25016\n",
      "A25017\n",
      "A25018\n",
      "A25020\n",
      "A25021\n",
      "A25022\n",
      "A25023\n",
      "A25025\n",
      "A25026\n",
      "A25027\n",
      "A25028\n",
      "A25029\n",
      "A25030\n",
      "A25031\n",
      "A25032\n",
      "A25033\n",
      "A25034\n",
      "A25035\n",
      "A25036\n",
      "A25038\n",
      "A25039\n",
      "A25040\n",
      "A25041\n",
      "A25042\n",
      "A25043\n",
      "A25044\n",
      "A25045\n",
      "A25047\n",
      "A25048\n",
      "A25050\n",
      "A25051\n",
      "A25052\n",
      "A25054\n",
      "A25055\n",
      "A25056\n",
      "A25057\n",
      "A25058\n",
      "A25059\n",
      "A25060\n",
      "A25062\n",
      "A25063\n",
      "A25064\n",
      "A25065\n",
      "A25066\n",
      "A25067\n",
      "A25069\n",
      "A25070\n",
      "A25072\n",
      "A25073\n",
      "A25074\n",
      "A25075\n",
      "A25076\n",
      "A25077\n",
      "A25078\n",
      "A25079\n",
      "A25080\n",
      "A25081\n",
      "A25082\n",
      "A25083\n",
      "A25085\n",
      "A25086\n",
      "A25087\n",
      "A25090\n",
      "A25092\n",
      "A25093\n",
      "A25094\n",
      "A25096\n",
      "A25097\n",
      "A25098\n",
      "A25099\n",
      "A25100\n",
      "A25101\n",
      "A25102\n",
      "A25105\n",
      "A25106\n",
      "A25107\n",
      "A25108\n",
      "A25109\n",
      "A25110\n",
      "A25111\n",
      "A25112\n",
      "A25113\n",
      "A25114\n",
      "A25115\n",
      "A25116\n",
      "A25117\n",
      "A25118\n",
      "A25120\n",
      "A25121\n",
      "A25122\n",
      "A25123\n",
      "A25124\n",
      "A25125\n",
      "A25126\n",
      "A25127\n",
      "A25128\n",
      "A25129\n",
      "A25130\n",
      "A25131\n",
      "A25132\n",
      "A25133\n",
      "A25134\n",
      "A25135\n",
      "A25137\n",
      "A25139\n",
      "A25141\n",
      "A25142\n",
      "A25143\n",
      "A25144\n",
      "A25145\n",
      "A25147\n",
      "A25149\n",
      "A25150\n",
      "A25151\n",
      "A25152\n",
      "A25153\n",
      "A25154\n",
      "A25155\n",
      "A25156\n",
      "A25158\n",
      "A25159\n",
      "A25160\n",
      "A25161\n",
      "A25162\n",
      "A25164\n",
      "A25165\n",
      "A25166\n",
      "A25167\n",
      "A25168\n",
      "A25170\n",
      "A25171\n",
      "A25172\n",
      "A25173\n",
      "A25174\n",
      "A25175\n",
      "A25176\n",
      "A25177\n",
      "A25179\n",
      "A25180\n",
      "A25181\n",
      "A25182\n",
      "A25183\n",
      "A25184\n",
      "A25185\n",
      "A25186\n",
      "A25188\n",
      "A25189\n",
      "A25191\n",
      "A25193\n",
      "A25196\n",
      "A25198\n",
      "A25199\n",
      "A25200\n",
      "A25202\n",
      "A25203\n",
      "A25204\n",
      "A25205\n",
      "A25206\n",
      "A25208\n",
      "A25209\n",
      "A25210\n",
      "A25212\n",
      "A25213\n",
      "A25215\n",
      "A25216\n",
      "A25217\n",
      "A25218\n",
      "A25219\n",
      "A25220\n",
      "A25221\n",
      "A25222\n",
      "A25223\n",
      "A25224\n",
      "A25225\n",
      "A25227\n",
      "A25228\n",
      "A25229\n",
      "A25230\n",
      "A25231\n",
      "A25232\n",
      "A25233\n",
      "A25234\n",
      "A25236\n",
      "A25237\n",
      "A25238\n",
      "A25240\n",
      "A25241\n",
      "A25242\n",
      "A25243\n",
      "A25244\n",
      "A25245\n",
      "A25246\n",
      "A25247\n",
      "A25248\n",
      "A25249\n",
      "A25251\n",
      "A25252\n",
      "A25253\n",
      "A25254\n",
      "A25255\n",
      "A25256\n",
      "A25257\n",
      "A25258\n",
      "A25259\n",
      "A25260\n",
      "A25261\n",
      "A25262\n",
      "A25263\n",
      "A25264\n",
      "A25265\n",
      "A25266\n",
      "A25267\n",
      "A25268\n",
      "A25269\n",
      "A25270\n",
      "A25271\n",
      "A25272\n",
      "A25273\n",
      "A25274\n",
      "A25275\n",
      "A25276\n",
      "A25277\n",
      "A25278\n",
      "A25279\n",
      "A25280\n",
      "A25281\n",
      "A25282\n",
      "A25283\n",
      "A25284\n",
      "A25285\n",
      "A25286\n",
      "A25288\n",
      "A25289\n",
      "A25290\n",
      "A25292\n",
      "A25293\n",
      "A25295\n",
      "A25296\n",
      "A25298\n",
      "A25299\n",
      "A25300\n",
      "A25302\n",
      "A25303\n",
      "A25306\n",
      "A25307\n",
      "A25308\n",
      "A25310\n",
      "A25311\n",
      "A25312\n",
      "A25313\n",
      "A25314\n",
      "A25315\n",
      "A25316\n",
      "A25317\n",
      "A25318\n",
      "A25319\n",
      "A25320\n",
      "A25321\n",
      "A25322\n",
      "A25324\n",
      "A25326\n",
      "A25327\n",
      "A25328\n",
      "A25329\n",
      "A25331\n",
      "A25332\n",
      "A25333\n",
      "A25334\n",
      "A25335\n",
      "A25336\n",
      "A25338\n",
      "A25339\n",
      "A25340\n",
      "A25341\n",
      "A25342\n",
      "A25343\n",
      "A25344\n",
      "A25345\n",
      "A25346\n",
      "A25347\n",
      "A25348\n",
      "A25349\n",
      "A25350\n",
      "A25351\n",
      "A25352\n",
      "A25353\n",
      "A25354\n",
      "A25357\n",
      "A25358\n",
      "A25359\n",
      "A25360\n",
      "A25361\n",
      "A25363\n",
      "A25364\n",
      "A25366\n",
      "A25367\n",
      "A25368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A25369\n",
      "A25370\n",
      "A25371\n",
      "A25372\n",
      "A25373\n",
      "A25374\n",
      "A25375\n",
      "A25377\n",
      "A25378\n",
      "A25379\n",
      "A25380\n",
      "A25381\n",
      "A25382\n",
      "A25383\n",
      "A25384\n",
      "A25386\n",
      "A25387\n",
      "A25388\n",
      "A25389\n",
      "A25391\n",
      "A25392\n",
      "A25393\n",
      "A25394\n",
      "A25395\n",
      "A25396\n",
      "A25397\n",
      "A25399\n",
      "A25400\n",
      "A25401\n",
      "A25402\n",
      "A25403\n",
      "A25404\n",
      "A25405\n",
      "A25406\n",
      "A25407\n",
      "A25408\n",
      "A25409\n",
      "A25410\n",
      "A25411\n",
      "A25412\n",
      "A25413\n",
      "A25414\n",
      "A25415\n",
      "A25416\n",
      "A25417\n",
      "A25418\n",
      "A25420\n",
      "A25421\n",
      "A25422\n",
      "A25423\n",
      "A25424\n",
      "A25425\n",
      "A25427\n",
      "A25428\n",
      "A25429\n",
      "A25431\n",
      "A25433\n",
      "A25434\n",
      "A25435\n",
      "A25438\n",
      "A25439\n",
      "A25440\n",
      "A25441\n",
      "A25442\n",
      "A25443\n",
      "A25444\n",
      "A25445\n",
      "A25446\n",
      "A25447\n",
      "A25448\n",
      "A25449\n",
      "A25450\n",
      "A25451\n",
      "A25452\n",
      "A25453\n",
      "A25454\n",
      "A25455\n",
      "A25456\n",
      "A25457\n",
      "A25458\n",
      "A25459\n",
      "A25460\n",
      "A25461\n",
      "A25462\n",
      "A25463\n",
      "A25464\n",
      "A25467\n",
      "A25468\n",
      "A25470\n",
      "A25471\n",
      "A25472\n",
      "A25473\n",
      "A25474\n",
      "A25475\n",
      "A25477\n",
      "A25478\n",
      "A25479\n",
      "A25481\n",
      "A25482\n",
      "A25483\n",
      "A25484\n",
      "A25485\n",
      "A25487\n",
      "A25488\n",
      "A25490\n",
      "A25491\n",
      "A25492\n",
      "A25495\n",
      "A25496\n",
      "A25497\n",
      "A25498\n",
      "A25499\n",
      "A25500\n",
      "A05060\n",
      "A05061\n",
      "A05068\n",
      "A05070\n",
      "A06018\n",
      "A07005\n",
      "A07007\n",
      "A07064\n",
      "A07091\n",
      "A08015\n",
      "A08017\n",
      "A09018\n",
      "A09061\n",
      "A09088\n",
      "A09098\n",
      "A09099\n",
      "A09100\n",
      "A12012\n",
      "A12018\n",
      "A12044\n",
      "A12061\n",
      "A12079\n",
      "A12149\n",
      "A12154\n",
      "A12186\n",
      "A12196\n",
      "A12199\n",
      "A12200\n",
      "A12203\n",
      "A12207\n",
      "A12233\n",
      "A12245\n",
      "A12264\n",
      "A12272\n",
      "A12294\n",
      "A12346\n",
      "A12350\n",
      "A12362\n",
      "A12382\n",
      "A12383\n",
      "A12384\n",
      "A12395\n",
      "A12399\n",
      "A12430\n",
      "A12463\n",
      "A12482\n",
      "A12483\n",
      "A12486\n",
      "A13016\n",
      "A14004\n",
      "A15018\n",
      "A17010\n",
      "A18048\n",
      "A18063\n",
      "A18119\n",
      "A18121\n",
      "A18161\n",
      "A18193\n",
      "A18213\n",
      "A18215\n",
      "A18228\n",
      "A18244\n",
      "A18263\n",
      "A18264\n",
      "A18271\n",
      "A18275\n",
      "A18303\n",
      "A18307\n",
      "A18319\n",
      "A18323\n",
      "A18332\n",
      "A18333\n",
      "A18338\n",
      "A18347\n",
      "A18411\n",
      "A18413\n",
      "A18475\n",
      "A18476\n",
      "A18488\n",
      "A19030\n",
      "A19044\n",
      "A19051\n",
      "A19073\n",
      "A19079\n",
      "A19087\n",
      "A19112\n",
      "A19144\n",
      "A19172\n",
      "A19191\n",
      "A19223\n",
      "A19224\n",
      "A19226\n",
      "A19329\n",
      "A19340\n",
      "A19360\n",
      "A19364\n",
      "A19374\n",
      "A19380\n",
      "A19381\n",
      "A19382\n",
      "A19402\n",
      "A19404\n",
      "A19412\n",
      "A19450\n",
      "A19477\n",
      "A19479\n",
      "A20017\n",
      "A20027\n",
      "A20044\n",
      "A20103\n",
      "A20107\n",
      "A20128\n",
      "A20130\n",
      "A20136\n",
      "A20159\n",
      "A20219\n",
      "A20224\n",
      "A20230\n",
      "A20253\n",
      "A20263\n",
      "A20284\n",
      "A20286\n",
      "A20295\n",
      "A20315\n",
      "A20339\n",
      "A20348\n",
      "A20387\n",
      "A20393\n",
      "A20418\n",
      "A20421\n",
      "A20427\n",
      "A20439\n",
      "A20453\n",
      "A20467\n",
      "A20480\n",
      "A20488\n",
      "A21056\n",
      "A21073\n",
      "A21084\n",
      "A21088\n",
      "A21091\n",
      "A21119\n",
      "A21147\n",
      "A21148\n",
      "A21163\n",
      "A21177\n",
      "A21178\n",
      "A21201\n",
      "A21217\n",
      "A21232\n",
      "A21243\n",
      "A21270\n",
      "A21274\n",
      "A21298\n",
      "A21334\n",
      "A21364\n",
      "A21380\n",
      "A21381\n",
      "A21387\n",
      "A21395\n",
      "A21400\n",
      "A21415\n",
      "A21427\n",
      "A21431\n",
      "A21459\n",
      "A21460\n",
      "A22013\n",
      "A22014\n",
      "A22015\n",
      "A22043\n",
      "A22148\n",
      "A22162\n",
      "A22164\n",
      "A22170\n",
      "A22180\n",
      "A22200\n",
      "A22234\n",
      "A22236\n",
      "A22241\n",
      "A22259\n",
      "A22271\n",
      "A22303\n",
      "A22334\n",
      "A22344\n",
      "A22352\n",
      "A22366\n",
      "A22395\n",
      "A22399\n",
      "A22422\n",
      "A22441\n",
      "A22454\n",
      "A22479\n",
      "A22483\n",
      "A23020\n",
      "A23022\n",
      "A23049\n",
      "A23059\n",
      "A23073\n",
      "A23089\n",
      "A23111\n",
      "A23141\n",
      "A23143\n",
      "A23171\n",
      "A23176\n",
      "A23191\n",
      "A23207\n",
      "A23211\n",
      "A23219\n",
      "A23225\n",
      "A23241\n",
      "A23249\n",
      "A23269\n",
      "A23302\n",
      "A23321\n",
      "A23344\n",
      "A23355\n",
      "A23361\n",
      "A23371\n",
      "A23408\n",
      "A23423\n",
      "A23452\n",
      "A23469\n",
      "A24015\n",
      "A24017\n",
      "A24048\n",
      "A24161\n",
      "A24170\n",
      "A24203\n",
      "A24208\n",
      "A24233\n",
      "A24242\n",
      "A24248\n",
      "A24259\n",
      "A24268\n",
      "A24272\n",
      "A24284\n",
      "A24303\n",
      "A24312\n",
      "A24313\n",
      "A24323\n",
      "A24337\n",
      "A24355\n",
      "A24394\n",
      "A24413\n",
      "A24429\n",
      "A24440\n",
      "A24449\n",
      "A24450\n",
      "A24459\n",
      "A24471\n",
      "A24473\n",
      "A24495\n",
      "A25009\n",
      "A25013\n",
      "A25046\n",
      "A25084\n",
      "A25095\n",
      "A25136\n",
      "A25140\n",
      "A25148\n",
      "A25163\n",
      "A25169\n",
      "A25195\n",
      "A25207\n",
      "A25235\n",
      "A25287\n",
      "A25294\n",
      "A25301\n",
      "A25304\n",
      "A25325\n",
      "A25330\n",
      "A25337\n",
      "A25365\n",
      "A25385\n",
      "A25419\n",
      "A25426\n",
      "A25489\n",
      "A05039\n",
      "A05040\n",
      "A05041\n",
      "A05042\n",
      "A05044\n",
      "A05046\n",
      "A05047\n",
      "A05051\n",
      "A05085\n",
      "A05089\n",
      "A05094\n",
      "A06009\n",
      "A06017\n",
      "A07006\n",
      "A07017\n",
      "A07036\n",
      "A07039\n",
      "A07041\n",
      "A07047\n",
      "A07057\n",
      "A07067\n",
      "A07072\n",
      "A07083\n",
      "A07095\n",
      "A08006\n",
      "A08010\n",
      "A09010\n",
      "A09014\n",
      "A09025\n",
      "A09033\n",
      "A09034\n",
      "A09039\n",
      "A09062\n",
      "A09069\n",
      "A09077\n",
      "A09081\n",
      "A10011\n",
      "A10016\n",
      "A12001\n",
      "A12003\n",
      "A12022\n",
      "A12023\n",
      "A12040\n",
      "A12052\n",
      "A12068\n",
      "A12069\n",
      "A12077\n",
      "A12085\n",
      "A12090\n",
      "A12108\n",
      "A12115\n",
      "A12121\n",
      "A12138\n",
      "A12143\n",
      "A12145\n",
      "A12150\n",
      "A12151\n",
      "A12152\n",
      "A12169\n",
      "A12172\n",
      "A12183\n",
      "A12189\n",
      "A12213\n",
      "A12216\n",
      "A12227\n",
      "A12234\n",
      "A12235\n",
      "A12242\n",
      "A12250\n",
      "A12285\n",
      "A12291\n",
      "A12312\n",
      "A12314\n",
      "A12331\n",
      "A12339\n",
      "A12342\n",
      "A12361\n",
      "A12371\n",
      "A12373\n",
      "A12375\n",
      "A12378\n",
      "A12401\n",
      "A12449\n",
      "A12455\n",
      "A12471\n",
      "A12480\n",
      "A12493\n",
      "A12495\n",
      "A13010\n",
      "A13015\n",
      "A14009\n",
      "A14012\n",
      "A14016\n",
      "A15005\n",
      "A15012\n",
      "A15016\n",
      "A17001\n",
      "A17005\n",
      "A17012\n",
      "A17020\n",
      "A18031\n",
      "A18035\n",
      "A18038\n",
      "A18055\n",
      "A18068\n",
      "A18084\n",
      "A18100\n",
      "A18114\n",
      "A18115\n",
      "A18123\n",
      "A18145\n",
      "A18154\n",
      "A18158\n",
      "A18159\n",
      "A18183\n",
      "A18186\n",
      "A18199\n",
      "A18203\n",
      "A18206\n",
      "A18209\n",
      "A18227\n",
      "A18231\n",
      "A18253\n",
      "A18254\n",
      "A18256\n",
      "A18258\n",
      "A18261\n",
      "A18283\n",
      "A18312\n",
      "A18342\n",
      "A18352\n",
      "A18363\n",
      "A18366\n",
      "A18375\n",
      "A18384\n",
      "A18392\n",
      "A18406\n",
      "A18409\n",
      "A18434\n",
      "A18438\n",
      "A18446\n",
      "A18447\n",
      "A18457\n",
      "A18459\n",
      "A18464\n",
      "A18480\n",
      "A18482\n",
      "A18494\n",
      "A18495\n",
      "A19002\n",
      "A19004\n",
      "A19005\n",
      "A19006\n",
      "A19012\n",
      "A19017\n",
      "A19029\n",
      "A19049\n",
      "A19053\n",
      "A19070\n",
      "A19082\n",
      "A19096\n",
      "A19119\n",
      "A19125\n",
      "A19130\n",
      "A19136\n",
      "A19142\n",
      "A19146\n",
      "A19147\n",
      "A19152\n",
      "A19175\n",
      "A19177\n",
      "A19184\n",
      "A19189\n",
      "A19193\n",
      "A19205\n",
      "A19227\n",
      "A19237\n",
      "A19240\n",
      "A19249\n",
      "A19251\n",
      "A19257\n",
      "A19260\n",
      "A19275\n",
      "A19283\n",
      "A19286\n",
      "A19300\n",
      "A19327\n",
      "A19330\n",
      "A19337\n",
      "A19341\n",
      "A19354\n",
      "A19357\n",
      "A19361\n",
      "A19368\n",
      "A19377\n",
      "A19407\n",
      "A19420\n",
      "A19459\n",
      "A19461\n",
      "A19466\n",
      "A20020\n",
      "A20026\n",
      "A20028\n",
      "A20047\n",
      "A20049\n",
      "A20050\n",
      "A20071\n",
      "A20074\n",
      "A20079\n",
      "A20084\n",
      "A20094\n",
      "A20108\n",
      "A20141\n",
      "A20168\n",
      "A20176\n",
      "A20181\n",
      "A20184\n",
      "A20185\n",
      "A20194\n",
      "A20195\n",
      "A20201\n",
      "A20203\n",
      "A20206\n",
      "A20222\n",
      "A20226\n",
      "A20237\n",
      "A20250\n",
      "A20268\n",
      "A20271\n",
      "A20279\n",
      "A20330\n",
      "A20331\n",
      "A20338\n",
      "A20342\n",
      "A20349\n",
      "A20350\n",
      "A20352\n",
      "A20362\n",
      "A20374\n",
      "A20386\n",
      "A20390\n",
      "A20392\n",
      "A20399\n",
      "A20435\n",
      "A20441\n",
      "A20443\n",
      "A20444\n",
      "A20447\n",
      "A20452\n",
      "A20461\n",
      "A20462\n",
      "A20481\n",
      "A20483\n",
      "A20490\n",
      "A21007\n",
      "A21009\n",
      "A21013\n",
      "A21014\n",
      "A21019\n",
      "A21024\n",
      "A21035\n",
      "A21039\n",
      "A21040\n",
      "A21058\n",
      "A21074\n",
      "A21075\n",
      "A21094\n",
      "A21127\n",
      "A21135\n",
      "A21150\n",
      "A21156\n",
      "A21159\n",
      "A21160\n",
      "A21172\n",
      "A21175\n",
      "A21191\n",
      "A21196\n",
      "A21198\n",
      "A21245\n",
      "A21269\n",
      "A21282\n",
      "A21293\n",
      "A21300\n",
      "A21304\n",
      "A21305\n",
      "A21314\n",
      "A21315\n",
      "A21325\n",
      "A21332\n",
      "A21333\n",
      "A21346\n",
      "A21355\n",
      "A21366\n",
      "A21376\n",
      "A21384\n",
      "A21413\n",
      "A21424\n",
      "A21444\n",
      "A21448\n",
      "A21463\n",
      "A21472\n",
      "A21477\n",
      "A21479\n",
      "A22012\n",
      "A22016\n",
      "A22023\n",
      "A22035\n",
      "A22037\n",
      "A22042\n",
      "A22050\n",
      "A22051\n",
      "A22061\n",
      "A22080\n",
      "A22084\n",
      "A22093\n",
      "A22094\n",
      "A22097\n",
      "A22106\n",
      "A22113\n",
      "A22129\n",
      "A22139\n",
      "A22144\n",
      "A22156\n",
      "A22159\n",
      "A22160\n",
      "A22165\n",
      "A22169\n",
      "A22176\n",
      "A22177\n",
      "A22201\n",
      "A22228\n",
      "A22232\n",
      "A22251\n",
      "A22280\n",
      "A22296\n",
      "A22320\n",
      "A22322\n",
      "A22333\n",
      "A22346\n",
      "A22369\n",
      "A22373\n",
      "A22403\n",
      "A22406\n",
      "A22407\n",
      "A22438\n",
      "A22442\n",
      "A22451\n",
      "A22452\n",
      "A22456\n",
      "A22462\n",
      "A22465\n",
      "A22466\n",
      "A22476\n",
      "A22478\n",
      "A23007\n",
      "A23021\n",
      "A23038\n",
      "A23042\n",
      "A23057\n",
      "A23075\n",
      "A23106\n",
      "A23109\n",
      "A23112\n",
      "A23116\n",
      "A23118\n",
      "A23119\n",
      "A23140\n",
      "A23162\n",
      "A23163\n",
      "A23174\n",
      "A23179\n",
      "A23189\n",
      "A23201\n",
      "A23210\n",
      "A23222\n",
      "A23240\n",
      "A23244\n",
      "A23245\n",
      "A23251\n",
      "A23253\n",
      "A23267\n",
      "A23299\n",
      "A23304\n",
      "A23316\n",
      "A23325\n",
      "A23331\n",
      "A23341\n",
      "A23356\n",
      "A23370\n",
      "A23378\n",
      "A23388\n",
      "A23395\n",
      "A23420\n",
      "A23424\n",
      "A23428\n",
      "A23434\n",
      "A23457\n",
      "A23464\n",
      "A23480\n",
      "A23487\n",
      "A24010\n",
      "A24012\n",
      "A24028\n",
      "A24060\n",
      "A24061\n",
      "A24072\n",
      "A24076\n",
      "A24090\n",
      "A24107\n",
      "A24111\n",
      "A24116\n",
      "A24125\n",
      "A24137\n",
      "A24141\n",
      "A24144\n",
      "A24152\n",
      "A24155\n",
      "A24159\n",
      "A24166\n",
      "A24181\n",
      "A24212\n",
      "A24239\n",
      "A24246\n",
      "A24256\n",
      "A24275\n",
      "A24276\n",
      "A24281\n",
      "A24282\n",
      "A24296\n",
      "A24299\n",
      "A24310\n",
      "A24317\n",
      "A24319\n",
      "A24325\n",
      "A24342\n",
      "A24347\n",
      "A24348\n",
      "A24351\n",
      "A24360\n",
      "A24361\n",
      "A24376\n",
      "A24377\n",
      "A24388\n",
      "A24389\n",
      "A24417\n",
      "A24422\n",
      "A24428\n",
      "A24433\n",
      "A24476\n",
      "A24484\n",
      "A24500\n",
      "A25019\n",
      "A25024\n",
      "A25037\n",
      "A25049\n",
      "A25053\n",
      "A25061\n",
      "A25068\n",
      "A25071\n",
      "A25088\n",
      "A25089\n",
      "A25091\n",
      "A25103\n",
      "A25104\n",
      "A25119\n",
      "A25138\n",
      "A25146\n",
      "A25157\n",
      "A25178\n",
      "A25187\n",
      "A25190\n",
      "A25192\n",
      "A25194\n",
      "A25197\n",
      "A25201\n",
      "A25211\n",
      "A25214\n",
      "A25226\n",
      "A25239\n",
      "A25250\n",
      "A25291\n",
      "A25297\n",
      "A25305\n",
      "A25309\n",
      "A25323\n",
      "A25355\n",
      "A25356\n",
      "A25362\n",
      "A25376\n",
      "A25390\n",
      "A25398\n",
      "A25430\n",
      "A25432\n",
      "A25436\n",
      "A25437\n",
      "A25465\n",
      "A25466\n",
      "A25469\n",
      "A25476\n",
      "A25480\n",
      "A25486\n",
      "A25493\n",
      "A25494\n",
      "B28001\n",
      "B28002\n",
      "B28003\n",
      "B28004\n",
      "B28005\n",
      "B28006\n",
      "B28007\n",
      "B28008\n",
      "B28009\n",
      "B28010\n",
      "B28011\n",
      "B28012\n",
      "B28013\n",
      "B28014\n",
      "B28015\n",
      "B28016\n",
      "B28017\n",
      "B28018\n",
      "B28019\n",
      "B28020\n",
      "B28021\n",
      "B28022\n",
      "B28023\n",
      "B28024\n",
      "B28025\n",
      "B28026\n",
      "B28027\n",
      "B28028\n",
      "B28029\n",
      "B28030\n",
      "B28031\n",
      "B28032\n",
      "B28033\n",
      "B28034\n",
      "B28035\n",
      "B28036\n",
      "B28037\n",
      "B28038\n",
      "B28039\n",
      "B28040\n",
      "B28041\n",
      "B28042\n",
      "B28043\n",
      "B28044\n",
      "B28045\n",
      "B28046\n",
      "B28047\n",
      "B28048\n",
      "B28049\n",
      "B28050\n",
      "C26001\n",
      "C26002\n",
      "C26003\n",
      "C26004\n",
      "C26005\n",
      "C26006\n",
      "C26007\n",
      "C26008\n",
      "C26009\n",
      "C26010\n",
      "C26011\n",
      "C26012\n",
      "C26013\n",
      "C26014\n",
      "C26015\n",
      "C26016\n",
      "C26017\n",
      "C26018\n",
      "C26019\n",
      "C26020\n",
      "C26021\n",
      "C26022\n",
      "C26023\n",
      "C26024\n",
      "C26025\n",
      "C26026\n",
      "C26027\n",
      "C26028\n",
      "C26029\n",
      "C26030\n",
      "C26031\n",
      "C26032\n",
      "C26033\n",
      "C26034\n",
      "C26035\n",
      "C26036\n",
      "C26037\n",
      "C26038\n",
      "C26039\n",
      "C26040\n",
      "C26041\n",
      "C26042\n",
      "C26043\n",
      "C26044\n",
      "C26045\n",
      "C26046\n",
      "C26047\n",
      "C26048\n",
      "C26049\n",
      "C26050\n",
      "C26051\n",
      "C26052\n",
      "C26053\n",
      "C26054\n",
      "C26055\n",
      "C26056\n",
      "C26057\n",
      "C26058\n",
      "C26059\n",
      "C26060\n",
      "C26061\n",
      "C26062\n",
      "C26063\n",
      "C26064\n",
      "C26065\n",
      "C26066\n",
      "C26067\n",
      "C26068\n",
      "C26069\n",
      "C26070\n",
      "C26071\n",
      "C26072\n",
      "C26073\n",
      "C26074\n",
      "C26075\n",
      "C26076\n",
      "C26077\n",
      "C26078\n",
      "C26079\n",
      "C26080\n",
      "C26081\n",
      "C26082\n",
      "C26083\n",
      "C26084\n",
      "C26085\n",
      "C26086\n",
      "C26087\n",
      "C26088\n",
      "C26089\n",
      "C26090\n",
      "C26091\n",
      "C26092\n",
      "C26093\n",
      "C26094\n",
      "C26095\n",
      "C26096\n",
      "C26097\n",
      "C26098\n",
      "C26099\n",
      "C26100\n",
      "D27001\n",
      "D27002\n",
      "D27003\n",
      "D27004\n",
      "D27005\n",
      "D27006\n",
      "D27007\n",
      "D27008\n",
      "D27009\n",
      "D27010\n",
      "D27011\n",
      "D27012\n",
      "D27013\n",
      "D27014\n",
      "D27015\n",
      "D27016\n",
      "D27017\n",
      "D27018\n",
      "D27019\n",
      "D27020\n",
      "D27021\n",
      "D27022\n",
      "D27023\n",
      "D27024\n",
      "D27025\n",
      "D27026\n",
      "D27027\n",
      "D27028\n",
      "D27029\n",
      "D27030\n",
      "D27031\n",
      "D27032\n",
      "D27033\n",
      "D27034\n",
      "D27035\n",
      "D27036\n",
      "D27037\n",
      "D27038\n",
      "D27039\n",
      "D27040\n",
      "D27041\n",
      "D27042\n",
      "D27043\n",
      "D27044\n",
      "D27045\n",
      "D27046\n",
      "D27047\n",
      "D27048\n",
      "D27049\n",
      "D27050\n",
      "D27051\n",
      "D27052\n",
      "D27053\n",
      "D27054\n",
      "D27055\n",
      "D27056\n",
      "D27057\n",
      "D27058\n",
      "D27059\n",
      "D27060\n",
      "D27061\n",
      "D27062\n",
      "D27063\n",
      "D27064\n",
      "D27065\n",
      "D27066\n",
      "D27067\n",
      "D27068\n",
      "D27069\n",
      "D27070\n",
      "D27071\n",
      "D27072\n",
      "D27073\n",
      "D27074\n",
      "D27075\n",
      "D27076\n",
      "D27077\n",
      "D27078\n",
      "D27079\n",
      "D27080\n",
      "D27081\n",
      "D27082\n",
      "D27083\n",
      "D27084\n",
      "D27085\n",
      "D27086\n",
      "D27087\n",
      "D27088\n",
      "D27089\n",
      "D27090\n",
      "D27091\n",
      "D27092\n",
      "D27093\n",
      "D27094\n",
      "D27095\n",
      "D27096\n",
      "D27097\n",
      "D27098\n",
      "D27099\n",
      "D27100\n"
     ]
    }
   ],
   "source": [
    "for ip in df_arguments['Argument ID']:\n",
    "  #print(df_arguments['Stance'][ip])\n",
    "  print(ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "b-L7fgEjnXGK"
   },
   "outputs": [],
   "source": [
    "level =2\n",
    "label_filepath = os.path.join(data_dir, 'labels-level{}.tsv'.format(str(level)))\n",
    "df_labels = load_labels_from_tsv(label_filepath, values[str(level)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WIBMeZIfntMM",
    "outputId": "29ce8ed1-6595-4056-8319-9565949ec44c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5270 Argument ID\n",
      "5270 Achievement\n",
      "5270 Benevolence: caring\n",
      "5270 Benevolence: dependability\n",
      "5270 Conformity: interpersonal\n",
      "5270 Conformity: rules\n",
      "5270 Face\n",
      "5270 Hedonism\n",
      "5270 Humility\n",
      "5270 Power: dominance\n",
      "5270 Power: resources\n",
      "5270 Security: personal\n",
      "5270 Security: societal\n",
      "5270 Self-direction: action\n",
      "5270 Self-direction: thought\n",
      "5270 Stimulation\n",
      "5270 Tradition\n",
      "5270 Universalism: concern\n",
      "5270 Universalism: nature\n",
      "5270 Universalism: objectivity\n",
      "5270 Universalism: tolerance\n"
     ]
    }
   ],
   "source": [
    "a = df_labels.keys()\n",
    "for key in df_labels.keys():\n",
    "  print(len(df_labels[key]),key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h7ONfVdGtsQ5",
    "outputId": "62e06eb4-919c-48a1-ffc5-848efe4c905c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels['Achievement'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "MurNX18XjWIw"
   },
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "#def generate_pairwise_input(dataset: Dict[List], labels: Dict[List]) -> (List[str], List[str], List[str], List[int]):\n",
    "def generate_pairwise_input(dataset, labels):\n",
    "    \"\"\"\n",
    "    TODO: group all premises and corresponding hypotheses and labels of the datapoints\n",
    "    a datapoint as seen earlier is a dict of premis, hypothesis and label\n",
    "    \"\"\"\n",
    "    #raise NotImplementedError\n",
    "    premise=[]\n",
    "    conclusion=[]\n",
    "    stance=[]\n",
    "    n_labels =labels.keys()\n",
    "    n_labels = n_labels[1:]\n",
    "    print(n_labels)\n",
    "    label=[]\n",
    "    \n",
    "    n = len(dataset['Argument ID'])\n",
    "    m = len(labels['Argument ID'])\n",
    "    print(n,m)\n",
    "    for i in range(n):\n",
    "        premise.append(dataset['Premise'][i])\n",
    "        conclusion.append(dataset['Conclusion'][i])\n",
    "        stance.append(dataset['Stance'][i])\n",
    "    for i in range(m):\n",
    "        sent_label = []\n",
    "        #print(i)\n",
    "        for l in range(len(n_labels)):\n",
    "            #print(n_labels[l])\n",
    "            sent_label.append(int(labels[n_labels[l]][i]))\n",
    "        label.append(sent_label)\n",
    "\n",
    "    return premise, conclusion, stance, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FBU9bpZwjvH9",
    "outputId": "b1c03888-9426-452b-b5a7-f809622e8847"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Achievement', 'Benevolence: caring', 'Benevolence: dependability',\n",
      "       'Conformity: interpersonal', 'Conformity: rules', 'Face', 'Hedonism',\n",
      "       'Humility', 'Power: dominance', 'Power: resources',\n",
      "       'Security: personal', 'Security: societal', 'Self-direction: action',\n",
      "       'Self-direction: thought', 'Stimulation', 'Tradition',\n",
      "       'Universalism: concern', 'Universalism: nature',\n",
      "       'Universalism: objectivity', 'Universalism: tolerance'],\n",
      "      dtype='object')\n",
      "5270 5270\n"
     ]
    }
   ],
   "source": [
    "#Randomize them first\n",
    "train_premises, train_conclusion, train_stance, train_labels = generate_pairwise_input(df_arguments, df_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nKP166RxYrGw"
   },
   "outputs": [],
   "source": [
    "import random \n",
    "random.seed(42)\n",
    "def randomize_data(premises, conclusion, stance, labels):\n",
    "  n = len(premises)\n",
    "  data = random.shuffle(range(n))\n",
    "  train_premises = []\n",
    "  train_conclusion = []\n",
    "  train_stance = []\n",
    "  train_labels = []\n",
    "  for i in data:\n",
    "    train_premises.append(premises[i])\n",
    "    train_conclusion.append(conclusion[i])\n",
    "    train_stance.append(stance[i])\n",
    "    train_labels.append(labels[:][i])\n",
    "  return train_premises, train_conclusion, train_stance, train_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Ye8wftgaawi"
   },
   "outputs": [],
   "source": [
    "train_premises, train_conclusion, train_stance, train_labels = randomize_data(train_premises, train_conclusion, train_stance, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "o3ygsKZZzBhs"
   },
   "outputs": [],
   "source": [
    "val_premises = train_premises[-500:]\n",
    "val_conclusion = train_conclusion[-500:]\n",
    "val_stance = train_stance[-500:]\n",
    "val_labels = train_labels[:][-500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "KveGMjWxzpFF"
   },
   "outputs": [],
   "source": [
    "train_premises = train_premises[:-500]\n",
    "train_conclusion = train_conclusion[:-500]\n",
    "train_stance = train_stance[:-500]\n",
    "train_labels = train_labels[:][:-500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XhW38nWHv2tj",
    "outputId": "42c4879a-ebe9-4737-8b64-e577c218b3ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  2023,  2003,  1996, 18458,  1012,   102,  1999,  7927,  1997,\n",
      "          2023,  2003,  1996, 10744,   102],\n",
      "        [  101,  2023,  2003,  2036,  1037, 18458,   102,  2114,  2023,  2003,\n",
      "          1037,  2117, 10744,   102,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['[CLS] this is the premise. [SEP] in favour of this is the hypothesis [SEP]',\n",
       " '[CLS] this is also a premise [SEP] against this is a second hypothesis [SEP] [PAD]']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nothing to do for this class!\n",
    "import torch\n",
    "from transformers import BertModel\n",
    "from transformers import AutoTokenizer\n",
    "from typing import Dict, List\n",
    "\n",
    "class BatchTokenizer:\n",
    "    \"\"\"Tokenizes and pads a batch of input sentences.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initializes the tokenizer\n",
    "\n",
    "        Args:\n",
    "            pad_symbol (Optional[str], optional): The symbol for a pad. Defaults to \"<P>\".\n",
    "        \"\"\"\n",
    "        self.hf_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    \n",
    "    def get_sep_token(self,):\n",
    "        return self.hf_tokenizer.sep_token\n",
    "    \n",
    "    def __call__(self, prem_batch: List[str], hyp_batch: List[str], stance_batch: List[str]) -> List[List[str]]:\n",
    "        \"\"\"Uses the huggingface tokenizer to tokenize and pad a batch.\n",
    "\n",
    "        We return a dictionary of tensors per the huggingface model specification.\n",
    "\n",
    "        Args:\n",
    "            batch (List[str]): A List of sentence strings\n",
    "\n",
    "        Returns:\n",
    "            Dict: The dictionary of token specifications provided by HuggingFace\n",
    "        \"\"\"\n",
    "        # The HF tokenizer will PAD for us, and additionally combine \n",
    "        # The two sentences deimited by the [SEP] token.\n",
    "        batch_len = len(prem_batch)\n",
    "        #spaces = [\" \"]*batch_len\n",
    "        conc_batch = [stance_batch[i]+\" \"+hyp_batch[i] for i in range(batch_len)]\n",
    "        enc = self.hf_tokenizer(\n",
    "            prem_batch,\n",
    "            conc_batch,\n",
    "            padding=True,\n",
    "            return_token_type_ids=False,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return enc\n",
    "    \n",
    "\n",
    "# HERE IS AN EXAMPLE OF HOW TO USE THE BATCH TOKENIZER\n",
    "tokenizer = BatchTokenizer()\n",
    "a = [[\"this is the premise.\", \"This is also a premise\"], [\"this is the hypothesis\", \"This is a second hypothesis\"],[\"in favour of\", \"against\"]]\n",
    "x = tokenizer(*a)\n",
    "print(x)\n",
    "tokenizer.hf_tokenizer.batch_decode(x[\"input_ids\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "FQWwRKXgrYRY"
   },
   "outputs": [],
   "source": [
    "def chunk(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[:][i:i + n]\n",
    "\n",
    "def chunk_multi(lst1, lst2, lst3, n):\n",
    "    for i in range(0, len(lst1), n):\n",
    "        yield lst1[i: i + n], lst2[i: i + n], lst3[i: i + n]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tCdddSnCwwmA",
    "outputId": "44745da1-3f89-4f5f-b88d-847a3b901fbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16563\n"
     ]
    }
   ],
   "source": [
    "sum=0\n",
    "import numpy as np\n",
    "# for i in range(5270):\n",
    "#   sum += np.sum(np.array(train_labels[:][i]))\n",
    "print(np.sum(np.array(train_labels)))\n",
    "#print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "nchPyT3yAtW3"
   },
   "outputs": [],
   "source": [
    "against=0\n",
    "infavour = 0\n",
    "for i in range(4770):\n",
    "  if(train_stance[i]=='against'):\n",
    "    against +=1\n",
    "  elif(train_stance[i]=='in favor of'):\n",
    "    infavour += 1\n",
    "  else:\n",
    "    print(train_stance[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "v-COBdmXv1Gf"
   },
   "outputs": [],
   "source": [
    "# Notice that since we use huggingface, we tokenize and\n",
    "# encode in all at once!\n",
    "batch_size=64\n",
    "tokenizer = BatchTokenizer()\n",
    "train_input_batches = [b for b in chunk_multi(train_premises, train_conclusion, train_stance, batch_size)]\n",
    "# Tokenize + encode\n",
    "train_input_batches = [tokenizer(*batch) for batch in train_input_batches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "E-H-JWr6-snT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "W_ta_vSAx4oz"
   },
   "outputs": [],
   "source": [
    "val_input_batches = [b for b in chunk_multi(val_premises, val_conclusion, val_stance, batch_size)]\n",
    "# Tokenize + encode\n",
    "val_input_batches = [tokenizer(*batch) for batch in val_input_batches]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3VwgQMkk1ZxW",
    "outputId": "9e4c4346-2f7a-4117-a5da-425878d59ca4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_labels[:][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "XgY4RO1-05Tz"
   },
   "outputs": [],
   "source": [
    "def encode_labels(labels: List[List[int]]) -> torch.FloatTensor:\n",
    "    \"\"\"Turns the batch of labels into a tensor\n",
    "\n",
    "    Args:\n",
    "        labels (List[List[int]]): List of all labels in the batch\n",
    "\n",
    "    Returns:\n",
    "        torch.FloatTensor: Tensor of all labels in the batch\n",
    "    \"\"\"\n",
    "    \n",
    "    return torch.LongTensor(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "cw7wSXAk19YY"
   },
   "outputs": [],
   "source": [
    "train_label_batches = [b for b in chunk(train_labels, batch_size)]\n",
    "train_label_batches = [encode_labels(batch) for batch in train_label_batches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "s2Jl56Mg2HdF"
   },
   "outputs": [],
   "source": [
    "val_label_batches = [b for b in chunk(val_labels, batch_size)]\n",
    "val_label_batches = [encode_labels(batch) for batch in val_label_batches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a9i5nn1qT244",
    "outputId": "24758a25-0efd-40c4-d483-3841c934a54c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_label_batches[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "qsgi7io72ewY"
   },
   "outputs": [],
   "source": [
    "class NLIClassifier(torch.nn.Module):\n",
    "    def __init__(self, output_size: int, hidden_size: int):\n",
    "        super().__init__()\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        # Initialize BERT, which we use instead of a single embedding layer.\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        # TODO [OPTIONAL]: Updating all BERT parameters can be slow and memory intensive. \n",
    "        # Freeze them if training is too slow. Notice that the learning\n",
    "        # rate should probably be smaller in this case.\n",
    "        # Uncommenting out the below 2 lines means only our classification layer will be updated.\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.bert_hidden_dimension = self.bert.config.hidden_size\n",
    "        print(self.bert_hidden_dimension)\n",
    "        # TODO: Add an extra hidden layer in the classifier, projecting\n",
    "        #      from the BERT hidden dimension to hidden size.\n",
    "        # TODO: Add a relu nonlinearity to be used in the forward method\n",
    "        #      https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html\n",
    "        self.hidden_layer1 = torch.nn.Linear(self.bert_hidden_dimension, 32)\n",
    "        self.hidden_layers = [torch.nn.Linear(self.bert_hidden_dimension, 32).to(device) for i in range(self.output_size)]\n",
    "        self.classifiers = [torch.nn.Linear(32, 1).to(device) for i in range(self.output_size)]\n",
    "        #self.hidden_layer2 = torch.nn.Linear(self.hidden_size, 32)\n",
    "        #self.hidden_layer3 = torch.nn.Linear(128, 32)\n",
    "        #self.hidden_layer4 = torch.nn.Linear(32, 8)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.classifier = torch.nn.Linear(32, self.output_size)\n",
    "        #self.classifier = torch.nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.log_softmax = torch.nn.LogSoftmax(dim=2)\n",
    "\n",
    "    def encode_text(\n",
    "        self,\n",
    "        symbols: Dict\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Encode the (batch of) sequence(s) of token symbols with an LSTM.\n",
    "            Then, get the last (non-padded) hidden state for each symbol and return that.\n",
    "\n",
    "        Args:\n",
    "            symbols (Dict): The Dict of token specifications provided by the HuggingFace tokenizer\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The final hiddens tate of the LSTM, which represents an encoding of\n",
    "                the entire sentence\n",
    "        \"\"\"\n",
    "        # First we get the contextualized embedding for each input symbol\n",
    "        # We no longer need an LSTM, since BERT encodes context and \n",
    "        # gives us a single vector describing the sequence in the form of the [CLS] token.\n",
    "        embedded = self.bert(**symbols)\n",
    "        #print(embedded)\n",
    "        #print(\"Embedded\", embedded.pooler_output.shape, embedded.last_hidden_state.shape)\n",
    "        # TODO: Get the [CLS] token using the `pooler_output` from \n",
    "        #      The BertModel output. See here: https://huggingface.co/docs/transformers/model_doc/bert#transformers.BertModel\n",
    "        #      and check the returns for the forward method.\n",
    "        # We want to return a tensor of the form batch_size x 1 x bert_hidden_dimension\n",
    "        #raise NotImplementedError\n",
    "        \n",
    "        #pool_output_shape = embedded.pooler_output.shape\n",
    "        #return torch.reshape(embedded.pooler_output,(pool_output_shape[0],1,pool_output_shape[1]) )\n",
    "        last_hidden_state = embedded.last_hidden_state[:,0,:]\n",
    "        hidden_shape = last_hidden_state.shape\n",
    "        return torch.reshape(last_hidden_state,(hidden_shape[0],1,hidden_shape[1]) )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        symbols: Dict,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            symbols (Dict): The Dict of token specifications provided by the HuggingFace tokenizer\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: _description_\n",
    "        \"\"\"\n",
    "        encoded_sents = self.encode_text(symbols)\n",
    "        #output = self.hidden_layer1(encoded_sents)\n",
    "        #output = self.relu(output)\n",
    "        outputs = [self.hidden_layers[i](encoded_sents) for i in range(self.output_size)]\n",
    "        outputs = [self.relu(outputs[i].to(device)) for i in range(self.output_size)]\n",
    "        outputs = [self.classifiers[i](outputs[i].to(device)) for i in range(self.output_size)]\n",
    "        #output = self.hidden_layer2(output)\n",
    "        #output = self.relu(output)\n",
    "        #output = self.hidden_layer3(output)\n",
    "        #output = self.relu(output)\n",
    "        #output = self.hidden_layer4(output)\n",
    "        #output = self.relu(output)\n",
    "        #output = self.classifier(output)\n",
    "        #return self.log_softmax(output)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "id": "w56Kynj22y80"
   },
   "outputs": [],
   "source": [
    "# For making predictions at test time TODO: Multi-label\n",
    "def predict(model: torch.nn.Module, sents: torch.Tensor) -> List:\n",
    "    sents = sents.to(device)\n",
    "    logits = model(sents)\n",
    "    res = []\n",
    "    logitslen = logits[0].shape[0]\n",
    "    for i in range(logitslen):\n",
    "        datares = []\n",
    "        for j in range(len(logits)):\n",
    "            datares.append(logits[j][i][0][0] > 0.5)\n",
    "        res.append(datares)\n",
    "    return res\n",
    "    #return list(torch.argmax(logits, axis=2).squeeze().numpy())\n",
    "    #print(torch.max(logits), torch.min(logits))\n",
    "    #return list((logits>0).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "cnSswFRd3WzN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from numpy import logical_and, sum as t_sum\n",
    "def precision(predicted_labels, true_labels, which_label=1):\n",
    "    \"\"\"\n",
    "    Precision is True Positives / All Positives Predictions\n",
    "    \"\"\"\n",
    "    pred_which = np.array([pred == which_label for pred in predicted_labels])\n",
    "    true_which = np.array([lab == which_label for lab in true_labels])\n",
    "    denominator = t_sum(pred_which)\n",
    "    if denominator:\n",
    "        return t_sum(logical_and(pred_which, true_which))/denominator\n",
    "    else:\n",
    "        return 0.\n",
    "\n",
    "\n",
    "def recall(predicted_labels, true_labels, which_label=1):\n",
    "    \"\"\"\n",
    "    Recall is True Positives / All Positive Labels\n",
    "    \"\"\"\n",
    "    pred_which = np.array([pred == which_label for pred in predicted_labels])\n",
    "    true_which = np.array([lab == which_label for lab in true_labels])\n",
    "    denominator = t_sum(true_which)\n",
    "    if denominator:\n",
    "        return t_sum(logical_and(pred_which, true_which))/denominator\n",
    "    else:\n",
    "        return 0.\n",
    "\n",
    "\n",
    "def f1_score(\n",
    "    predicted_labels: List[int],\n",
    "    true_labels: List[int],\n",
    "    which_label: int\n",
    "):\n",
    "    \"\"\"\n",
    "    F1 score is the harmonic mean of precision and recall\n",
    "    \"\"\"\n",
    "    P = precision(predicted_labels, true_labels, which_label=which_label)\n",
    "    R = recall(predicted_labels, true_labels, which_label=which_label)\n",
    "    if P and R:\n",
    "        return 2*P*R/(P+R)\n",
    "    else:\n",
    "        return 0.\n",
    "\n",
    "\n",
    "def macro_f1(\n",
    "    predicted_labels: List[int],\n",
    "    true_labels: List[int],\n",
    "    possible_labels: List[int]\n",
    "):\n",
    "    scores = [f1_score(predicted_labels, true_labels, l) for l in possible_labels]\n",
    "    # Macro, so we take the uniform avg.\n",
    "    print(scores)\n",
    "    return sum(scores) / len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "lVZr4mEb81_f"
   },
   "outputs": [],
   "source": [
    "def f1Score_multiLabel(preds, labels):\n",
    "    nLabels = 20\n",
    "    relevants = [0]*20\n",
    "    positives = [0]*20\n",
    "    truePositives = [0]*20\n",
    "    for i in range(len(preds)):\n",
    "        for j in range(nLabels):\n",
    "            if(preds[i][j]==1):\n",
    "                positives[j] += 1\n",
    "                if(labels[i][j]==1):\n",
    "                    truePositives[j] += 1\n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "        for j in range(nLabels):\n",
    "            if(labels[i][j]==1):\n",
    "                relevants[j] += 1\n",
    "    \n",
    "    precisions = []*nLabels\n",
    "    recalls = []*nLabels\n",
    "    f1Scores = []*nLabels\n",
    "    precision =0\n",
    "    recall = 0\n",
    "    f1 = 0\n",
    "    #print(truePositives, positives, relevants)\n",
    "    for i in range(nLabels):\n",
    "        if(positives[i]>0):\n",
    "            precision = truePositives[i]/positives[i]\n",
    "        precisions.append(precision)\n",
    "        if(relevants[i]>0):\n",
    "            recall = truePositives[i]/relevants[i]\n",
    "        recalls.append(recall)\n",
    "        #print(precision,recall,i)\n",
    "        if(precision>0 and recall>0):\n",
    "            f1 = 2 * precision * recall / (precision + recall)\n",
    "        f1Scores.append(f1)\n",
    "    precision_mean = np.mean(precisions)\n",
    "    recall_mean = np.mean(recalls)\n",
    "    f1_mean = np.mean(recalls)\n",
    "    return f1_mean, precision_mean, recall_mean\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "IyE6cJhM3i9M"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "def training_loop(\n",
    "    num_epochs,\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    dev_sents,\n",
    "    dev_labels,\n",
    "    optimizer,\n",
    "    #scheduler,\n",
    "    model,\n",
    "):\n",
    "    print(\"Training...\")\n",
    "    loss_func = torch.nn.CrossEntropyLoss()\n",
    "    batches = list(zip(train_features, train_labels))\n",
    "    random.shuffle(batches)\n",
    "    for i in range(num_epochs):\n",
    "        losses = []\n",
    "        for features, labels in tqdm(batches):\n",
    "            # Empty the dynamic computation graph\n",
    "            features = features.to(device)\n",
    "            labels = labels.float()\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(features)\n",
    "            #print(preds[0].shape)\n",
    "            featlen = preds[0].shape[0]\n",
    "            preds_temp = torch.empty((featlen, 20), dtype=torch.float)\n",
    "            for k in range(featlen):\n",
    "                for j in range(20):\n",
    "                    preds_temp[k][j] = preds[j][k][0][0]\n",
    "            #preds = preds.squeeze(1)\n",
    "            #print(\"Preds \",preds.shape)\n",
    "            #print(\"Labels \", labels.shape)\n",
    "            preds_temp = preds_temp.to(device)\n",
    "            #print(preds_temp.is_cuda, labels.is_cuda)\n",
    "            #print(preds_temp.shape, labels.shape)\n",
    "            loss = loss_func(preds_temp, labels)\n",
    "            # Backpropogate the loss through our model\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "        \n",
    "        print(f\"epoch {i}, loss: {np.sum(losses)/len(losses)}\")\n",
    "        # Estimate the f1 score for the development set\n",
    "        print(\"Evaluating dev...\")\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        for sents, labels in tqdm(zip(dev_sents, dev_labels), total=len(dev_sents)):\n",
    "            sents = sents.to(device)\n",
    "            pred = predict(model, sents)\n",
    "            all_preds.extend(pred)\n",
    "            all_labels.extend(list(labels))\n",
    "        # #print(range(len(set(train_labels))))\n",
    "\n",
    "        dev_f1, dev_P, dev_R = f1Score_multiLabel(all_preds, all_labels)\n",
    "        print(f\"Dev F1 {dev_f1},  Dev Precision {dev_P}, Dev Recall {dev_R}\")\n",
    "        # #scheduler.step()\n",
    "        #print(optimizer)\n",
    "    # Return the trained model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "liqb8oDn4fNx",
    "outputId": "545aceed-d042-453f-a525-fae13e9a5c21",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "# TODO: Find a good learning rate\n",
    "LR = 1e-5\n",
    "\n",
    "possible_labels = 20\n",
    "model = NLIClassifier(output_size=possible_labels, hidden_size=512)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), LR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481,
     "referenced_widgets": [
      "b2afef0410e5441fba9117d8245446ff",
      "814bd0ad4e934352bb834eafc9349d71",
      "6b0d8aad7b3f43e999bfb3232aa2704d",
      "c8115c479b604992bc5f78e42d32b62b",
      "3b58593efb444e85a6f3eb6b3a3d07eb",
      "4feb2531a2ed48bb8cbc10f111c2ee0a",
      "59602ba94d004b7d8e442ff47a2258f6",
      "4c0055c1e7af401490e9dea75c555893",
      "374c8f24d524433ab716ca6cac675641",
      "19fc153fe74c4948883d369a38f54e91",
      "ee26fe94d70c4191b4120e226ed8ba4a"
     ]
    },
    "id": "Y0ThGzo64w64",
    "outputId": "023f87b5-d67e-4b36-a04c-172a7e70aa00",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heman\\AppData\\Local\\Temp\\ipykernel_4560\\817256930.py:19: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for features, labels in tqdm(batches):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74134ffd9dc44ab686a3ab13fea4089c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 63, loss: 10.399799480438233\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heman\\AppData\\Local\\Temp\\ipykernel_4560\\817256930.py:49: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for sents, labels in tqdm(zip(dev_sents, dev_labels), total=len(dev_sents)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b9360b98e974ada91bca0648f351718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.0,  Dev Precision 0.0, Dev Recall 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1523f13b4db144c38a023fdc14e0d941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 63, loss: 10.399799480438233\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1839f01411dc4a53ade4e151235b665a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.0,  Dev Precision 0.0, Dev Recall 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5804b85089df4976891c0dd5e61bf507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 63, loss: 10.399799480438233\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3887152c84c488db21a2f5b7b3aaaef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.0,  Dev Precision 0.0, Dev Recall 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f1c6105446940168c6e2f996eca0604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 63, loss: 10.399799480438233\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22402cc20eab4b4b82f921bfb7d15860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.0,  Dev Precision 0.0, Dev Recall 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e328a1f3b7494f99bff2cdfa0f1a3764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model =training_loop(\n",
    "    epochs,\n",
    "    train_input_batches,\n",
    "    train_label_batches,\n",
    "    val_input_batches,\n",
    "    val_label_batches,\n",
    "    optimizer,\n",
    "    #scheduler,\n",
    "    model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520,
     "referenced_widgets": [
      "ee66bd0ea5e44abe8547960d2b953dfd",
      "6794b7344ca74ea79e27d62cc2b731e7",
      "46e9ef759c5a4076af228ca215de5f8a",
      "cab1a59fad4042279965587e565d316a",
      "be051014d67743fbb9d84f7079ef0cd2",
      "7e9aaae0e19745f2ac45d9d45bdf21c0",
      "ab3d4f183f6443e88b4a4b78e5bbe1e2",
      "ad16b7f28a1a45e689ec8389b1713bd4",
      "d775d856f78f429fb3235667a49d23e2",
      "3d49b2fe098646e6b8dd092a1e254e4f",
      "9ba695ce3a904eb2a3e602c5cf5e538a"
     ]
    },
    "id": "_4203j4811Mw",
    "outputId": "2e954a67-aa63-41c2-8880-0f849bb20b35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-124-ee7ac79b3e67>:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for sents, labels in tqdm(zip(val_input_batches, val_label_batches), total=len(val_input_batches)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee66bd0ea5e44abe8547960d2b953dfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[140, 114, 2, 0, 34, 0, 5, 34, 31, 37, 185, 0, 91, 0, 13, 0, 0, 0, 10, 50] [500, 500, 12, 9, 153, 0, 500, 500, 500, 500, 500, 0, 394, 0, 493, 0, 1, 0, 82, 482] [140, 114, 53, 6, 108, 22, 5, 34, 31, 37, 185, 145, 105, 62, 13, 39, 171, 26, 99, 52]\n",
      "0.28 1.0 0\n",
      "0.228 1.0 1\n",
      "0.16666666666666666 0.03773584905660377 2\n",
      "0.0 0.0 3\n",
      "0.2222222222222222 0.3148148148148148 4\n",
      "0.2222222222222222 0.0 5\n",
      "0.01 1.0 6\n",
      "0.068 1.0 7\n",
      "0.062 1.0 8\n",
      "0.074 1.0 9\n",
      "0.37 1.0 10\n",
      "0.37 0.0 11\n",
      "0.23096446700507614 0.8666666666666667 12\n",
      "0.23096446700507614 0.0 13\n",
      "0.02636916835699797 1.0 14\n",
      "0.02636916835699797 0.0 15\n",
      "0.0 0.0 16\n",
      "0.0 0.0 17\n",
      "0.12195121951219512 0.10101010101010101 18\n",
      "0.1037344398340249 0.9615384615384616 19\n",
      "Dev F1 0.5140882946543324,  Dev Precision 0.140673202059074, Dev Recall 0.5140882946543324\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating dev...\")\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "for sents, labels in tqdm(zip(val_input_batches, val_label_batches), total=len(val_input_batches)):\n",
    "    pred = predict(model, sents)\n",
    "    all_preds.extend(pred)\n",
    "    all_labels.extend(list(labels.numpy()))\n",
    "# #print(range(len(set(train_labels))))\n",
    "\n",
    "dev_f1, dev_P, dev_R = f1Score_multiLabel(all_preds, all_labels)\n",
    "print(f\"Dev F1 {dev_f1},  Dev Precision {dev_P}, Dev Recall {dev_R}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JNtkjU5-49vL",
    "outputId": "48a3cf8c-a04f-4a12-8343-2362f1c02844"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "GeRlExU2w8Lp"
   },
   "outputs": [],
   "source": [
    "def f1Score_multiLabel(preds, labels):\n",
    "    nLabels = 20\n",
    "    relevants = [0]*20\n",
    "    positives = [0]*20\n",
    "    truePositives = [0]*20\n",
    "    for i in range(len(preds)):\n",
    "        for j in range(nLabels):\n",
    "            if(preds[i][j]==1):\n",
    "                positives[j] += 1\n",
    "                if(labels[i][j]==1):\n",
    "                    truePositives[j] += 1\n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "        for j in range(nLabels):\n",
    "            if(labels[i][j]==1):\n",
    "                relevants[j] += 1\n",
    "    \n",
    "    precisions = []*nLabels\n",
    "    recalls = []*nLabels\n",
    "    f1Scores = []*nLabels\n",
    "    precision =0\n",
    "    recall = 0\n",
    "    f1 = 0\n",
    "    print(truePositives, positives, relevants)\n",
    "    for i in range(nLabels):\n",
    "        if(positives[i]>0):\n",
    "            precision = truePositives[i]/positives[i]\n",
    "        precisions.append(precision)\n",
    "        if(relevants[i]>0):\n",
    "            recall = truePositives[i]/relevants[i]\n",
    "        recalls.append(recall)\n",
    "        print(precision,recall,i)\n",
    "        if(positives[i]>0 and relevants[i]>0):\n",
    "            f1 = 2 * precision * recall / (precision + recall)\n",
    "        f1Scores.append(f1)\n",
    "    precision_mean = np.mean(precisions)\n",
    "    recall_mean = np.mean(recalls)\n",
    "    f1_mean = np.mean(recalls)\n",
    "    return f1_mean, precision_mean, recall_mean\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sxPeUYO6xlip",
    "outputId": "796fcdcf-7394-4e6c-9b2c-8c0950de84b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_batches[0][0][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0B57iw_741yk",
    "outputId": "726f5863-c97b-44c5-9989-332b11604f5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9030,  1.0262, -0.0431,  0.4149,  1.3941]], requires_grad=True) tensor([[0.5257, 0.1721, 0.2647, 0.0207, 0.0167]])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(1, 5, requires_grad=True)\n",
    "#target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "target = torch.randn(1, 5).softmax(dim=1)\n",
    "print(input, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uXnrg3Ph5QRW",
    "outputId": "ef76dc5e-6fa3-4ea0-afcc-b2c3751faf9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7929, grad_fn=<DivBackward1>)\n"
     ]
    }
   ],
   "source": [
    "output = loss(input, target)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dRrI3eptcFJd",
    "outputId": "a949b623-97ad-43b1-892f-e8be417181c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1021,  0.0259,     nan, -0.8798,  0.3323]], grad_fn=<LogBackward0>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.log(input)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nWA-g2dDch-j",
    "outputId": "f6767fcf-20c9-4d59-96f3-bdd7e0ba8d61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0537,  0.0045,     nan, -0.0182,  0.0056]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a*target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mMUDSzOFctdG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BwDuG-5pWVVs",
    "outputId": "142e8a75-a001-4973-978f-0e8444b5bd35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5930, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "target = torch.empty(1, dtype=torch.long)\n",
    "target[0] = 1\n",
    "output = loss(input, target)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-4XKS621WmjX",
    "outputId": "6326ce58-1ee0-4e31-f68f-2c3793ab7e34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss: 10.0\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "losses=[10]\n",
    "print(f\"epoch {i}, loss: {np.sum(losses)/len(losses)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DIzpG6eFW6pb",
    "outputId": "399968fe-b790-4094-c9ac-efe21a044665"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WDPOLhR_XAdC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "19fc153fe74c4948883d369a38f54e91": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "374c8f24d524433ab716ca6cac675641": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3b58593efb444e85a6f3eb6b3a3d07eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d49b2fe098646e6b8dd092a1e254e4f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46e9ef759c5a4076af228ca215de5f8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ad16b7f28a1a45e689ec8389b1713bd4",
      "max": 8,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d775d856f78f429fb3235667a49d23e2",
      "value": 8
     }
    },
    "4c0055c1e7af401490e9dea75c555893": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4feb2531a2ed48bb8cbc10f111c2ee0a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "59602ba94d004b7d8e442ff47a2258f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6794b7344ca74ea79e27d62cc2b731e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e9aaae0e19745f2ac45d9d45bdf21c0",
      "placeholder": "​",
      "style": "IPY_MODEL_ab3d4f183f6443e88b4a4b78e5bbe1e2",
      "value": "100%"
     }
    },
    "6b0d8aad7b3f43e999bfb3232aa2704d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c0055c1e7af401490e9dea75c555893",
      "max": 75,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_374c8f24d524433ab716ca6cac675641",
      "value": 20
     }
    },
    "7e9aaae0e19745f2ac45d9d45bdf21c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "814bd0ad4e934352bb834eafc9349d71": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4feb2531a2ed48bb8cbc10f111c2ee0a",
      "placeholder": "​",
      "style": "IPY_MODEL_59602ba94d004b7d8e442ff47a2258f6",
      "value": " 27%"
     }
    },
    "9ba695ce3a904eb2a3e602c5cf5e538a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ab3d4f183f6443e88b4a4b78e5bbe1e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ad16b7f28a1a45e689ec8389b1713bd4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b2afef0410e5441fba9117d8245446ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_814bd0ad4e934352bb834eafc9349d71",
       "IPY_MODEL_6b0d8aad7b3f43e999bfb3232aa2704d",
       "IPY_MODEL_c8115c479b604992bc5f78e42d32b62b"
      ],
      "layout": "IPY_MODEL_3b58593efb444e85a6f3eb6b3a3d07eb"
     }
    },
    "be051014d67743fbb9d84f7079ef0cd2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c8115c479b604992bc5f78e42d32b62b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_19fc153fe74c4948883d369a38f54e91",
      "placeholder": "​",
      "style": "IPY_MODEL_ee26fe94d70c4191b4120e226ed8ba4a",
      "value": " 20/75 [03:49&lt;09:12, 10.04s/it]"
     }
    },
    "cab1a59fad4042279965587e565d316a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d49b2fe098646e6b8dd092a1e254e4f",
      "placeholder": "​",
      "style": "IPY_MODEL_9ba695ce3a904eb2a3e602c5cf5e538a",
      "value": " 8/8 [02:22&lt;00:00, 22.09s/it]"
     }
    },
    "d775d856f78f429fb3235667a49d23e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ee26fe94d70c4191b4120e226ed8ba4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ee66bd0ea5e44abe8547960d2b953dfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6794b7344ca74ea79e27d62cc2b731e7",
       "IPY_MODEL_46e9ef759c5a4076af228ca215de5f8a",
       "IPY_MODEL_cab1a59fad4042279965587e565d316a"
      ],
      "layout": "IPY_MODEL_be051014d67743fbb9d84f7079ef0cd2"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
